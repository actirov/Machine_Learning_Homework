{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Import Dependencies"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from gym.wrappers import FrameStack\n",
    "from Preprocessing import *\n",
    "from Agents import *"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Gym Environment"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "env = gym.make('SpaceInvaders-v0')\n",
    "height, width, channel = env.observation_space.shape\n",
    "actions = env.action_space.n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "6"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.unwrapped.get_action_meanings()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "(210, 160, 3)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random play (This will crash the kernel if in render_mode='human')\n",
    "@OpenAi pls fix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:0   Score:355.0\n",
      "Episode:1   Score:135.0\n",
      "Episode:2   Score:560.0\n"
     ]
    }
   ],
   "source": [
    "episodes = 3\n",
    "\n",
    "for episode in range(episodes):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        #env.render()\n",
    "        action = random.choice(range(6))\n",
    "        n_state,reward,done,info = env.step(action)\n",
    "        score+=reward\n",
    "\n",
    "    print(\"Episode:{}   Score:{}\".format(episode,score))\n",
    "env.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Apply Transformations to the Environment"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Apply Wrappers to environment\n",
    "frame_lag = 4 #We won't record every frame to save on resources\n",
    "env_2 = SkipFrame(env, skip=frame_lag) #Game is repetitive. Only analyze every 4th frame\n",
    "env_2 = GrayScaleObservation(env) #Graysacale conversion\n",
    "env_2 = ResizeObservation(env_2, shape=84) #Make it a smaller square\n",
    "env_2 = FrameStack(env_2,num_stack=frame_lag) #Stack the last 4 frames into one observation (the ones we skipped)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "(4, 84, 84)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_2.observation_space.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import deque"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initialize the look-up table"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "look_up_table = np.zeros(shape=(0,actions))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train and report the results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: True\n",
      "\n",
      "Episode:    10\n",
      "% of CUDA memory used:  4.264209066666667%\n",
      "    Epsilon:    0.9822494088388295\n",
      "    Rolling avg. 20 reward:     161.0\n",
      "    Step:   7164\n",
      "    Q value:    None\n",
      "    Loss:   0\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    20\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.9666246265168593\n",
      "    Rolling avg. 20 reward:     136.5\n",
      "    Step:   13578\n",
      "    Q value:    0.010846961289644241\n",
      "    Loss:   0.0004864314687438309\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    30\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.9531980686676939\n",
      "    Rolling avg. 20 reward:     107.25\n",
      "    Step:   19173\n",
      "    Q value:    0.012801839038729668\n",
      "    Loss:   0.0004418774042278528\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    40\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.9356534814855343\n",
      "    Rolling avg. 20 reward:     143.75\n",
      "    Step:   26604\n",
      "    Q value:    -0.03719250112771988\n",
      "    Loss:   0.005575081799179316\n",
      "    Look-up table:\n",
      "[[-0.00421372 -0.07509209 -0.0473879   0.02012784 -0.01256128  0.00650504]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    50\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.9185581136237798\n",
      "    Rolling avg. 20 reward:     173.25\n",
      "    Step:   33980\n",
      "    Q value:    0.008967968635261059\n",
      "    Loss:   0.0006268289289437234\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    60\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.9042945647074806\n",
      "    Rolling avg. 20 reward:     138.75\n",
      "    Step:   40240\n",
      "    Q value:    0.17440031468868256\n",
      "    Loss:   0.40977010130882263\n",
      "    Look-up table:\n",
      "[[ 0.00518557  0.00801829  0.01143056 -0.0060532  -0.00707974  0.00648386]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    70\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.8899098212794334\n",
      "    Rolling avg. 20 reward:     131.5\n",
      "    Step:   46654\n",
      "    Q value:    0.08063777536153793\n",
      "    Loss:   0.5999833941459656\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [0.06713225 0.27541462 0.094449   0.19813251 0.10782182 0.03906978]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    80\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.8737332387593483\n",
      "    Rolling avg. 20 reward:     139.75\n",
      "    Step:   53992\n",
      "    Q value:    0.03502578288316727\n",
      "    Loss:   0.0026839994825422764\n",
      "    Look-up table:\n",
      "[[ 0.01402647  0.02110957 -0.01405212  0.02363051 -0.01884186 -0.00186042]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.01491423  0.01938728 -0.00970776  0.02036803 -0.01204121 -0.00292663]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.08112649  0.08539767  0.06366231  0.09830077  0.06458833  0.06969303]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    90\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.8554071750963055\n",
      "    Rolling avg. 20 reward:     213.25\n",
      "    Step:   62471\n",
      "    Q value:    0.13280245661735535\n",
      "    Loss:   0.8551570177078247\n",
      "    Look-up table:\n",
      "[[ 0.01590848  0.01553405  0.00249431  0.0053324  -0.0039729  -0.00833182]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.02540172  0.02426948  0.01047213 -0.00119927  0.00199924 -0.01447098]\n",
      " ...\n",
      " [ 0.09334005 -0.02619956  0.05652966  0.24774456  0.01611854 -0.07423475]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    100\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.8399732625216467\n",
      "    Rolling avg. 20 reward:     251.75\n",
      "    Step:   69754\n",
      "    Q value:    0.11830383539199829\n",
      "    Loss:   0.0203862264752388\n",
      "    Look-up table:\n",
      "[[-2.93438137e-03 -4.50001657e-03 -2.41853222e-02 -9.58830118e-04\n",
      "   1.01218373e-03 -3.47599760e-03]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " ...\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]]\n",
      "Episode:    110\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.8274656056731015\n",
      "    Rolling avg. 20 reward:     162.75\n",
      "    Step:   75755\n",
      "    Q value:    0.04817938804626465\n",
      "    Loss:   0.010513551533222198\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [0.03191077 0.03193195 0.03100552 0.04908554 0.03791707 0.02159942]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    120\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.8133223461500476\n",
      "    Rolling avg. 20 reward:     134.5\n",
      "    Step:   82651\n",
      "    Q value:    0.08894793689250946\n",
      "    Loss:   1.200514316558838\n",
      "    Look-up table:\n",
      "[[ 0.0350572   0.02793229 -0.01908196  0.03189244  0.01218092 -0.00376017]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    130\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.7988933826051592\n",
      "    Rolling avg. 20 reward:     179.0\n",
      "    Step:   89811\n",
      "    Q value:    0.03076903522014618\n",
      "    Loss:   0.003406841540709138\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    140\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.7830233159327973\n",
      "    Rolling avg. 20 reward:     203.25\n",
      "    Step:   97837\n",
      "    Q value:    0.1971374750137329\n",
      "    Loss:   0.0924702137708664\n",
      "    Look-up table:\n",
      "[[ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 3.03943753e-02  4.77091856e-02 -8.45029950e-04  2.75952816e-02\n",
      "   3.53673398e-02  4.32280861e-02]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " ...\n",
      " [ 1.04663044e-01  1.34197250e-02  8.74236673e-02  1.06416732e-01\n",
      "   8.11903030e-02  1.88634679e-01]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.02115974e-01  1.30564459e-02  7.34519213e-02  1.04840994e-01\n",
      "   6.24655858e-02  1.79971576e-01]]\n",
      "Episode:    150\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.7700496184791372\n",
      "    Rolling avg. 20 reward:     165.25\n",
      "    Step:   104520\n",
      "    Q value:    0.09123149514198303\n",
      "    Loss:   0.7674001455307007\n",
      "    Look-up table:\n",
      "[[0.04170383 0.04640719 0.03059912 0.04129443 0.00495058 0.04748268]\n",
      " [0.04108426 0.04537012 0.02084155 0.03678487 0.00160793 0.04056477]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.05666255 0.05308075 0.04788364 0.04850479 0.01169706 0.02220563]]\n",
      "Episode:    160\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.758452318090922\n",
      "    Rolling avg. 20 reward:     121.75\n",
      "    Step:   110590\n",
      "    Q value:    0.08418141305446625\n",
      "    Loss:   0.001167332287877798\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [0.03284138 0.04071768 0.06399197 0.03217062 0.01766738 0.04613903]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.03997392 0.09281193 0.08264379 0.0836053  0.0461064  0.09682158]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    170\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.7454401965622005\n",
      "    Rolling avg. 20 reward:     134.75\n",
      "    Step:   117512\n",
      "    Q value:    0.024308528751134872\n",
      "    Loss:   0.0035150893963873386\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    180\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.7335695347722923\n",
      "    Rolling avg. 20 reward:     158.75\n",
      "    Step:   123933\n",
      "    Q value:    0.0736016035079956\n",
      "    Loss:   0.005168410018086433\n",
      "    Look-up table:\n",
      "[[ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.05711478  0.01836007  0.13610771  0.05445521  0.16512997 -0.03470089]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    190\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.7214062057397967\n",
      "    Rolling avg. 20 reward:     146.5\n",
      "    Step:   130621\n",
      "    Q value:    0.10392581671476364\n",
      "    Loss:   0.7678037285804749\n",
      "    Look-up table:\n",
      "[[ 0.04037905  0.04733086  0.0676759   0.03657776  0.02319325  0.06185772]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [-0.00335521 -0.0052843  -0.0048198  -0.06450388 -0.03504151  0.02122281]\n",
      " [-0.00219551 -0.00227366 -0.00552703 -0.06346953 -0.03509261  0.02029069]\n",
      " [ 0.00722996  0.06734936  0.05904511  0.01536167  0.02436303  0.09282064]]\n",
      "Episode:    200\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.707846560019646\n",
      "    Rolling avg. 20 reward:     160.5\n",
      "    Step:   138211\n",
      "    Q value:    0.09930084645748138\n",
      "    Loss:   0.6092139482498169\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.00566733 0.04177644 0.03607549 0.08776937 0.04634633 0.05591387]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    210\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.6954383213437803\n",
      "    Rolling avg. 20 reward:     167.25\n",
      "    Step:   145285\n",
      "    Q value:    0.07791461795568466\n",
      "    Loss:   0.004738140851259232\n",
      "    Look-up table:\n",
      "[[ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.13075639 -0.00369342 -0.10187318 -0.00548601 -0.09508809  0.02416559]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    220\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.6819489491881117\n",
      "    Rolling avg. 20 reward:     167.0\n",
      "    Step:   153120\n",
      "    Q value:    0.16272005438804626\n",
      "    Loss:   0.08281004428863525\n",
      "    Look-up table:\n",
      "[[0.04048189 0.04654633 0.03509007 0.04036533 0.01253137 0.0575287 ]\n",
      " [0.03427661 0.04285318 0.03827888 0.03557638 0.00692859 0.05382718]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.18705457 0.11465649 0.15705642 0.14801855 0.23962864 0.12953164]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    230\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.671517301586017\n",
      "    Rolling avg. 20 reward:     160.75\n",
      "    Step:   159286\n",
      "    Q value:    0.13992153108119965\n",
      "    Loss:   0.0015426775207743049\n",
      "    Look-up table:\n",
      "[[ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " ...\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [-6.56339005e-02 -1.29625410e-01 -5.21850586e-02 -2.37681568e-02\n",
      "  -1.09809488e-01  8.42534006e-04]]\n",
      "Episode:    240\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.6587158495032026\n",
      "    Rolling avg. 20 reward:     159.5\n",
      "    Step:   166985\n",
      "    Q value:    0.03620949387550354\n",
      "    Loss:   0.1380564123392105\n",
      "    Look-up table:\n",
      "[[ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 0.01865926 -0.01595439  0.01978661  0.00168724  0.01106031  0.01223043]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    250\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.6475281294122264\n",
      "    Rolling avg. 20 reward:     174.25\n",
      "    Step:   173837\n",
      "    Q value:    0.12720727920532227\n",
      "    Loss:   0.0032574301585555077\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [0.01561754 0.0130372  0.01836352 0.00657296 0.01829346 0.04655261]\n",
      " [0.01117332 0.01390492 0.0192135  0.00761165 0.01792053 0.04681222]\n",
      " ...\n",
      " [0.19106892 0.24070533 0.17311102 0.11886799 0.15343378 0.25714445]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    260\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.6350998378613112\n",
      "    Rolling avg. 20 reward:     159.75\n",
      "    Step:   181589\n",
      "    Q value:    0.09527052938938141\n",
      "    Loss:   0.0010791689855977893\n",
      "    Look-up table:\n",
      "[[ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.39792487e-02 -2.37480402e-02 -5.67838550e-04 -4.34183627e-02\n",
      "  -2.99123079e-02 -2.59617642e-02]\n",
      " [ 7.77693838e-03 -1.77608728e-02  4.54849005e-03 -4.37863171e-02\n",
      "  -3.23446393e-02 -2.41716877e-02]\n",
      " ...\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 4.17397916e-02 -6.82010502e-02 -3.47511470e-03  2.04333961e-02\n",
      "   9.41531360e-03 -8.98293108e-02]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]]\n",
      "Episode:    270\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.6248972219092791\n",
      "    Rolling avg. 20 reward:     152.5\n",
      "    Step:   188067\n",
      "    Q value:    0.03470076620578766\n",
      "    Loss:   0.6073123216629028\n",
      "    Look-up table:\n",
      "[[ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [-2.51473486e-02  1.00978017e-02  4.54083085e-04  1.19289309e-02\n",
      "  -6.07136637e-03 -1.40118971e-02]\n",
      " ...\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]]\n",
      "Episode:    280\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.6139108174204486\n",
      "    Rolling avg. 20 reward:     170.75\n",
      "    Step:   195162\n",
      "    Q value:    0.21386146545410156\n",
      "    Loss:   0.0024466521572321653\n",
      "    Look-up table:\n",
      "[[-0.05384121 -0.03414121  0.0016368  -0.01075576 -0.01215743 -0.03139862]\n",
      " [-0.06283638 -0.03934039 -0.00845748 -0.01548481 -0.01533881 -0.03674594]\n",
      " [-0.06595393 -0.03794365 -0.00912148 -0.01577523 -0.01630168 -0.03744533]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    290\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.6030949499155371\n",
      "    Rolling avg. 20 reward:     174.0\n",
      "    Step:   202272\n",
      "    Q value:    0.15600243210792542\n",
      "    Loss:   0.001018165028654039\n",
      "    Look-up table:\n",
      "[[-0.04018896 -0.00789134 -0.03104332  0.00441994  0.03061726 -0.02257769]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.0382782   0.00870204 -0.01609483  0.01203413  0.03212693 -0.01350258]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.29481536  0.28704301  0.19632754  0.28124255  0.29492581  0.28164077]\n",
      " [ 0.28067291  0.26126504  0.19111238  0.26045108  0.27230629  0.2622174 ]]\n",
      "Episode:    300\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.5927674273085926\n",
      "    Rolling avg. 20 reward:     143.0\n",
      "    Step:   209181\n",
      "    Q value:    0.16635647416114807\n",
      "    Loss:   0.0270068496465683\n",
      "    Look-up table:\n",
      "[[ 0.08759449  0.02326092  0.03327764 -0.02744295  0.07082983  0.06645423]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 0.13446707  0.13719736  0.08112542  0.06658378  0.02915692  0.16197908]\n",
      " [ 0.14273712  0.13711883  0.08515702  0.07645151  0.0309649   0.16676305]\n",
      " [ 0.08196158  0.09126182  0.04902256 -0.00322479 -0.01867852  0.12415341]]\n",
      "Episode:    310\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.5824274354179071\n",
      "    Rolling avg. 20 reward:     155.0\n",
      "    Step:   216220\n",
      "    Q value:    0.03814590349793434\n",
      "    Loss:   0.001493681687861681\n",
      "    Look-up table:\n",
      "[[-0.05802341 -0.02402411 -0.02255394 -0.00898793 -0.03037456 -0.01282965]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    320\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.5723078703039015\n",
      "    Rolling avg. 20 reward:     164.5\n",
      "    Step:   223231\n",
      "    Q value:    0.15795379877090454\n",
      "    Loss:   0.4494746923446655\n",
      "    Look-up table:\n",
      "[[ 0.02782818  0.0214282   0.0037262  -0.0252679  -0.04053396 -0.0034451 ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.02150299  0.01648861  0.00289838 -0.04182887 -0.05428886 -0.01128763]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.11424239  0.10957389  0.09030005  0.08325431  0.09655306  0.12555371]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    330\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.5625638056513329\n",
      "    Rolling avg. 20 reward:     135.5\n",
      "    Step:   230100\n",
      "    Q value:    0.3593270778656006\n",
      "    Loss:   0.004234699998050928\n",
      "    Look-up table:\n",
      "[[-0.01655462 -0.01964077 -0.04065445  0.0061141  -0.05150197 -0.02005166]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.00463548 -0.0041337  -0.02131958  0.00996512 -0.04876952 -0.01157275]\n",
      " ...\n",
      " [ 0.48165485  0.49639785  0.47147122  0.42203808  0.41928911  0.46479532]\n",
      " [ 0.47983289  0.49338013  0.47022909  0.42045152  0.41814971  0.4622325 ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    340\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.5536911498482724\n",
      "    Rolling avg. 20 reward:     120.75\n",
      "    Step:   236459\n",
      "    Q value:    0.1994001269340515\n",
      "    Loss:   0.001232697395607829\n",
      "    Look-up table:\n",
      "[[ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 3.74072939e-02 -6.60598278e-04  7.34079629e-03  8.34216177e-03\n",
      "   5.47934026e-02 -3.28843296e-03]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " ...\n",
      " [ 9.67957079e-02  1.55557334e-01  1.15828976e-01  1.08485892e-01\n",
      "   1.01308584e-01  1.23166412e-01]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 3.88859510e-02  1.17258132e-01  6.80073649e-02  5.79283088e-02\n",
      "   4.37031388e-02  7.42728412e-02]]\n",
      "Episode:    350\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.5449025765403853\n",
      "    Rolling avg. 20 reward:     145.0\n",
      "    Step:   242859\n",
      "    Q value:    0.23991991579532623\n",
      "    Loss:   0.004636933095753193\n",
      "    Look-up table:\n",
      "[[ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.02077956 -0.00588953  0.04624484  0.01798932  0.03577977  0.01922822]\n",
      " [ 0.0216488  -0.00556414  0.04849158  0.02257341  0.04167527  0.02004746]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    360\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.5363822180634086\n",
      "    Rolling avg. 20 reward:     154.75\n",
      "    Step:   249163\n",
      "    Q value:    0.2375844120979309\n",
      "    Loss:   0.13750258088111877\n",
      "    Look-up table:\n",
      "[[0.01806493 0.04393573 0.01931024 0.00908098 0.05298643 0.04350244]\n",
      " [0.02005422 0.04137099 0.01803296 0.00869958 0.05407238 0.04366513]\n",
      " [0.02205308 0.04042059 0.01713007 0.0077419  0.05406737 0.04416841]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.06972128 0.12306671 0.09908549 0.13718803 0.17449807 0.12228371]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    370\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.5272814564585976\n",
      "    Rolling avg. 20 reward:     138.75\n",
      "    Step:   256008\n",
      "    Q value:    0.28245577216148376\n",
      "    Loss:   0.0029188161715865135\n",
      "    Look-up table:\n",
      "[[0.02450163 0.01014626 0.02424046 0.07294357 0.0190075  0.05891262]\n",
      " [0.0284247  0.00744727 0.02265081 0.07498702 0.02397329 0.06025614]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [0.23650788 0.20860195 0.19804969 0.25223053 0.26933882 0.19264105]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    380\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.517347323820294\n",
      "    Rolling avg. 20 reward:     154.25\n",
      "    Step:   263616\n",
      "    Q value:    0.3175183832645416\n",
      "    Loss:   0.2972925901412964\n",
      "    Look-up table:\n",
      "[[ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.06776039  0.03640367 -0.00761999  0.04425891  0.05824897  0.02687973]\n",
      " [ 0.07341099  0.03717402 -0.00384115  0.05007941  0.06597716  0.03129874]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    390\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.5055638931289737\n",
      "    Rolling avg. 20 reward:     238.0\n",
      "    Step:   272832\n",
      "    Q value:    0.2478787899017334\n",
      "    Loss:   0.13266153633594513\n",
      "    Look-up table:\n",
      "[[ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.01308094  0.01915729  0.00461224  0.02527842 -0.00641134  0.01812865]\n",
      " [ 0.01855105  0.02583301  0.01018241  0.02962615 -0.00504261  0.02052271]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.27466795  0.30271855  0.12534441  0.30105418  0.23363596  0.24451789]\n",
      " [ 0.18635774  0.17779449  0.05129917  0.17882764  0.10584543  0.13476229]]\n",
      "Episode:    400\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.49629072952124687\n",
      "    Rolling avg. 20 reward:     249.75\n",
      "    Step:   280237\n",
      "    Q value:    0.32813525199890137\n",
      "    Loss:   0.8980379104614258\n",
      "    Look-up table:\n",
      "[[ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 9.45494995e-02  6.26928806e-02  7.19221756e-02  5.48568517e-02\n",
      "  -1.22949481e-04  5.96040636e-02]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " ...\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]]\n",
      "Episode:    410\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.48882858411983665\n",
      "    Rolling avg. 20 reward:     170.75\n",
      "    Step:   286297\n",
      "    Q value:    0.245802104473114\n",
      "    Loss:   0.004719138611108065\n",
      "    Look-up table:\n",
      "[[0.0947874  0.06106034 0.08225922 0.01338623 0.05085005 0.08927581]\n",
      " [0.10718885 0.07386775 0.09567361 0.01723683 0.05922507 0.09511684]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.15804192 0.1594511  0.1694026  0.17042349 0.17753217 0.12306814]\n",
      " [0.05680368 0.07109819 0.01340255 0.05520782 0.09764507 0.03542432]]\n",
      "Episode:    420\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.48145937951920054\n",
      "    Rolling avg. 20 reward:     127.25\n",
      "    Step:   292373\n",
      "    Q value:    0.1605522632598877\n",
      "    Loss:   0.020750747993588448\n",
      "    Look-up table:\n",
      "[[0.08283958 0.08127932 0.04666488 0.08561073 0.08162271 0.09662867]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    430\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.47352245954004657\n",
      "    Rolling avg. 20 reward:     135.5\n",
      "    Step:   299022\n",
      "    Q value:    0.27934667468070984\n",
      "    Loss:   0.005346506834030151\n",
      "    Look-up table:\n",
      "[[ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 0.08625814  0.11062121  0.1264236   0.05474101  0.02964582  0.07797217]\n",
      " [ 0.08573763  0.1087639   0.12568088  0.05504559  0.02842462  0.0771852 ]\n",
      " [-0.05884004 -0.05058703 -0.07211462 -0.14114726 -0.09326214 -0.05514064]]\n",
      "Episode:    440\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.46599938972093197\n",
      "    Rolling avg. 20 reward:     142.0\n",
      "    Step:   305428\n",
      "    Q value:    0.28920847177505493\n",
      "    Loss:   0.004882793873548508\n",
      "    Look-up table:\n",
      "[[ 2.61968821e-02  6.90460205e-04  1.05976015e-02  2.80617177e-03\n",
      "   7.77894258e-03  2.06907243e-02]\n",
      " [ 2.35870332e-02 -5.41949272e-03  2.59488449e-02  1.13747418e-02\n",
      "   2.14648694e-02  1.61370486e-02]\n",
      " [ 2.38703191e-02 -8.05795193e-04  3.85932475e-02  1.32860988e-02\n",
      "   2.36573070e-02  1.16366595e-02]\n",
      " ...\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.50397673e-01  1.52611762e-01  1.28381789e-01  1.76843077e-01\n",
      "   2.13443652e-01  1.89985439e-01]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]]\n",
      "Episode:    450\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.45830128882205584\n",
      "    Rolling avg. 20 reward:     125.5\n",
      "    Step:   312091\n",
      "    Q value:    0.42469513416290283\n",
      "    Loss:   0.1479964554309845\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [0.06137653 0.03803258 0.08438078 0.07683684 0.03130868 0.05481562]\n",
      " [0.06980571 0.05467258 0.10193806 0.08680797 0.04533838 0.06244463]\n",
      " ...\n",
      " [0.30867118 0.19665426 0.15205118 0.30956408 0.32989305 0.46812209]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    460\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.45108657521213064\n",
      "    Rolling avg. 20 reward:     134.0\n",
      "    Step:   318438\n",
      "    Q value:    0.3404722809791565\n",
      "    Loss:   0.21351933479309082\n",
      "    Look-up table:\n",
      "[[ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.07665642  0.11827016  0.08525591  0.05520093  0.05637977  0.006447  ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 0.15616634  0.27182186  0.18762454  0.26187015  0.32421377  0.20438561]\n",
      " [ 0.1568303   0.27059624  0.1872541   0.25774336  0.32386529  0.20322815]\n",
      " [-0.02361313  0.13494521 -0.03733011  0.05801985  0.09954263  0.06763014]]\n",
      "Episode:    470\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.4439321626221241\n",
      "    Rolling avg. 20 reward:     145.0\n",
      "    Step:   324833\n",
      "    Q value:    0.4419982433319092\n",
      "    Loss:   0.06429541110992432\n",
      "    Look-up table:\n",
      "[[ 8.44350234e-02 -1.35840178e-02  6.33815527e-02  4.67070937e-03\n",
      "   2.77463943e-02  1.07605524e-01]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 6.55987412e-02 -3.05777639e-02  5.18633425e-02 -6.80105388e-03\n",
      "   1.47993416e-02  8.85431021e-02]\n",
      " ...\n",
      " [ 7.61151314e-05 -7.42606223e-02  1.01271331e-01 -6.30938858e-02\n",
      "  -2.00768396e-01  1.74594969e-02]\n",
      " [ 1.79977715e-03 -7.87483156e-02  9.83653367e-02 -6.42471015e-02\n",
      "  -2.00223655e-01  1.83787346e-02]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]]\n",
      "Episode:    480\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.43620474943877596\n",
      "    Rolling avg. 20 reward:     180.5\n",
      "    Step:   331857\n",
      "    Q value:    0.4512963891029358\n",
      "    Loss:   0.3193180561065674\n",
      "    Look-up table:\n",
      "[[ 0.01889886 -0.02644163 -0.00623699 -0.01920594 -0.01605392 -0.00563818]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.00212048 -0.04744825 -0.03730947 -0.06178845 -0.02735631 -0.02715017]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.21197337  0.15469678  0.15672407  0.18774085  0.18774605  0.26354921]\n",
      " [-0.02244848 -0.1292406  -0.12799343 -0.11497705 -0.12992838  0.03051494]]\n",
      "Episode:    490\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.4290074227066505\n",
      "    Rolling avg. 20 reward:     164.75\n",
      "    Step:   338512\n",
      "    Q value:    0.24549734592437744\n",
      "    Loss:   0.003598631825298071\n",
      "    Look-up table:\n",
      "[[ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.06226584 -0.03591633  0.02570512 -0.02310635 -0.00154543  0.0049729 ]\n",
      " ...\n",
      " [ 0.34028685  0.47661686  0.42528701  0.5142737   0.38421148  0.24693081]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.02455896  0.18671288  0.10721694  0.12501626 -0.01220778 -0.05385891]]\n",
      "Episode:    500\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.4195317436327407\n",
      "    Rolling avg. 20 reward:     183.75\n",
      "    Step:   347446\n",
      "    Q value:    0.33496588468551636\n",
      "    Loss:   0.14699256420135498\n",
      "    Look-up table:\n",
      "[[0.10646468 0.06477261 0.03626853 0.06855752 0.05771241 0.10484856]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    510\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.4117552707468672\n",
      "    Rolling avg. 20 reward:     221.0\n",
      "    Step:   354930\n",
      "    Q value:    0.45388123393058777\n",
      "    Loss:   0.04004672169685364\n",
      "    Look-up table:\n",
      "[[-5.67853451e-04  2.69625485e-02 -1.82305276e-02  2.34586298e-02\n",
      "  -1.20126456e-02 -2.89248973e-02]\n",
      " [ 1.98376179e-03  1.72610730e-02 -9.44133103e-03  1.72808915e-02\n",
      "   2.01016665e-04 -4.36948091e-02]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " ...\n",
      " [ 3.61860275e-01  2.36344084e-01  2.49561220e-01  3.00589383e-01\n",
      "   2.49132335e-01  3.94968987e-01]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.79157197e-01  7.44132474e-02  6.81787282e-02  9.82906595e-02\n",
      "  -7.31100142e-03  1.70181990e-01]]\n",
      "Episode:    520\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.40524493006261436\n",
      "    Rolling avg. 20 reward:     159.25\n",
      "    Step:   361305\n",
      "    Q value:    0.3652825951576233\n",
      "    Loss:   0.023621974512934685\n",
      "    Look-up table:\n",
      "[[ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.01820515 -0.00426523 -0.01477182 -0.03104386 -0.01269986 -0.02054846]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    530\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.39951512810889017\n",
      "    Rolling avg. 20 reward:     103.0\n",
      "    Step:   367001\n",
      "    Q value:    0.41519972681999207\n",
      "    Loss:   0.007666633930057287\n",
      "    Look-up table:\n",
      "[[-0.04095928 -0.05707096 -0.03164862 -0.053028   -0.03279135 -0.00155571]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.03790264 -0.05456497 -0.03138521 -0.05575475 -0.03392819 -0.00290123]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.3222093   0.29253203  0.23206137  0.32996154  0.30243611  0.33877385]\n",
      " [ 0.07747528  0.06134601 -0.10699883  0.09192583 -0.03565572  0.12101465]]\n",
      "Episode:    540\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.392543205978248\n",
      "    Rolling avg. 20 reward:     110.25\n",
      "    Step:   374043\n",
      "    Q value:    0.34645384550094604\n",
      "    Loss:   1.0133029222488403\n",
      "    Look-up table:\n",
      "[[-0.04554713 -0.05086954 -0.00676973  0.05115575 -0.02262791 -0.02079459]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.04299939 -0.04782334  0.01208003  0.04982014 -0.02712943 -0.02676992]\n",
      " ...\n",
      " [ 0.25324559  0.22809751  0.2759285   0.20287205  0.25309163  0.19614452]\n",
      " [ 0.2600441   0.23449725  0.2803461   0.2060284   0.25637609  0.20256355]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    550\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.38481553332148694\n",
      "    Rolling avg. 20 reward:     172.0\n",
      "    Step:   381996\n",
      "    Q value:    0.2943649888038635\n",
      "    Loss:   0.6980021595954895\n",
      "    Look-up table:\n",
      "[[-0.02440369  0.00698981 -0.03737842 -0.04887432 -0.02095306 -0.01260096]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.012849    0.00499944 -0.0189597  -0.03639394 -0.02751811 -0.01577263]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    560\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.37719189385708335\n",
      "    Rolling avg. 20 reward:     206.5\n",
      "    Step:   390000\n",
      "    Q value:    0.2023758888244629\n",
      "    Loss:   0.006720656529068947\n",
      "    Look-up table:\n",
      "[[-0.06455301 -0.02253859 -0.03871438  0.00929682  0.05958544  0.02473636]\n",
      " [-0.04770592 -0.00588951 -0.01653765  0.0047528   0.03531107  0.01482189]\n",
      " [-0.0451654  -0.00390737 -0.00733915 -0.00187142  0.03397058  0.00760669]\n",
      " ...\n",
      " [ 0.26708502  0.27112457  0.23299637  0.4136745   0.18618359  0.0926933 ]\n",
      " [ 0.27527076  0.27420861  0.24186823  0.41494513  0.20011936  0.10104039]\n",
      " [-0.15231115 -0.05110604 -0.23334818  0.12345661 -0.26569498 -0.66845948]]\n",
      "Episode:    570\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.37090150389356485\n",
      "    Rolling avg. 20 reward:     179.75\n",
      "    Step:   396727\n",
      "    Q value:    0.19277188181877136\n",
      "    Loss:   0.005127768963575363\n",
      "    Look-up table:\n",
      "[[-0.0307637   0.02049066 -0.11004823 -0.06264682 -0.10575531 -0.06298326]\n",
      " [-0.01485433  0.02243073 -0.09155723 -0.0468028  -0.09450971 -0.0566234 ]\n",
      " [-0.01318887  0.01913098 -0.08054355 -0.0444099  -0.08322148 -0.05795258]\n",
      " ...\n",
      " [ 0.55310118  0.60215914  0.40263426  0.62897921  0.46016964  0.40892607]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.37319916  0.30443388  0.31038585  0.54101944  0.52732217  0.35903835]]\n",
      "Episode:    580\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.36304671318491233\n",
      "    Rolling avg. 20 reward:     198.75\n",
      "    Step:   405289\n",
      "    Q value:    0.363315224647522\n",
      "    Loss:   0.14188720285892487\n",
      "    Look-up table:\n",
      "[[ 2.19005346e-02  1.90143436e-02 -2.13499367e-02  2.50166655e-02\n",
      "  -3.23304534e-03 -9.91116464e-03]\n",
      " [ 1.55598521e-02  1.68288499e-02 -4.40496206e-03  2.81949639e-02\n",
      "   8.39273632e-03 -5.79357147e-05]\n",
      " [ 1.19784176e-02  1.83520913e-02 -3.46279144e-03  2.98497677e-02\n",
      "   1.81531608e-02 -3.04386020e-03]\n",
      " ...\n",
      " [ 2.63533920e-01  1.17349245e-01  3.33288521e-01  2.14554846e-01\n",
      "   1.04294226e-01  4.37731892e-02]\n",
      " [ 2.69898742e-01  1.20916292e-01  3.38450938e-01  2.13210553e-01\n",
      "   1.10283852e-01  4.24443483e-02]\n",
      " [-1.41465306e-01  9.68073308e-03 -2.39229202e-03 -9.65683162e-03\n",
      "  -1.35963336e-01 -1.48213804e-02]]\n",
      "Episode:    590\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.3565845897092459\n",
      "    Rolling avg. 20 reward:     226.75\n",
      "    Step:   412473\n",
      "    Q value:    0.41164690256118774\n",
      "    Loss:   0.342520147562027\n",
      "    Look-up table:\n",
      "[[-0.02279198  0.01158454  0.05412851 -0.00135443  0.11032784 -0.00394356]\n",
      " [-0.02591312  0.00546567  0.06843299 -0.00176316  0.10640687 -0.00265613]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 0.19471763  0.46205699  0.16694283  0.39205921  0.38213566  0.37426528]\n",
      " [ 0.20087421  0.46936035  0.16357669  0.38994804  0.38030338  0.38152343]\n",
      " [-0.43289831  0.10924858 -0.31900561 -0.06715906 -0.13324803  0.05564713]]\n",
      "Episode:    600\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.34927216618917534\n",
      "    Rolling avg. 20 reward:     219.5\n",
      "    Step:   420761\n",
      "    Q value:    0.28202134370803833\n",
      "    Loss:   0.2995762228965759\n",
      "    Look-up table:\n",
      "[[ 0.00686419 -0.04039307 -0.04635504 -0.00837587  0.08813375 -0.0044667 ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.00719668 -0.02917381 -0.0335993  -0.00118946  0.09899932 -0.01148155]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.28399897  0.27605948  0.26084077  0.35158694  0.17845717  0.14333059]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    610\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.34277660603709537\n",
      "    Rolling avg. 20 reward:     184.75\n",
      "    Step:   428270\n",
      "    Q value:    0.225336492061615\n",
      "    Loss:   0.010794430039823055\n",
      "    Look-up table:\n",
      "[[-0.00392881 -0.00493652 -0.00892334  0.00868903  0.01399022  0.0527025 ]\n",
      " [-0.0046324   0.00114909  0.01017959  0.01683533  0.00755969  0.05307382]\n",
      " [-0.00589091  0.0019519   0.01511629  0.01973571 -0.00259894  0.04634698]\n",
      " ...\n",
      " [ 0.23185658  0.11804727  0.27718186  0.07196811  0.13427857  0.16284573]\n",
      " [ 0.25145939  0.12405581  0.25768673  0.07377543  0.13481089  0.1615622 ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    620\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.3366071145097252\n",
      "    Rolling avg. 20 reward:     171.25\n",
      "    Step:   435535\n",
      "    Q value:    0.363386332988739\n",
      "    Loss:   0.03216765820980072\n",
      "    Look-up table:\n",
      "[[0.07264882 0.00962377 0.12255456 0.11256895 0.02047412 0.05894781]\n",
      " [0.08188627 0.010896   0.12260214 0.1225882  0.01719435 0.04655019]\n",
      " [0.0815165  0.01905069 0.11800753 0.12358335 0.01828593 0.05028167]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.5453108  0.78073806 0.11746232 0.42758161 0.23528159 0.26825017]\n",
      " [0.40803528 0.65385878 0.05889316 0.25516215 0.22937521 0.12037566]]\n",
      "Episode:    630\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.33046355962783946\n",
      "    Rolling avg. 20 reward:     185.0\n",
      "    Step:   442903\n",
      "    Q value:    0.5803843140602112\n",
      "    Loss:   0.22601079940795898\n",
      "    Look-up table:\n",
      "[[-6.26489520e-04  9.33470130e-02  8.97306204e-03  1.40372515e-02\n",
      "  -1.52666867e-03  1.53295994e-02]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " ...\n",
      " [ 2.86831379e-01  2.92439133e-01  4.07408029e-01  3.91590238e-01\n",
      "   2.06141040e-01  1.73746362e-01]\n",
      " [ 2.72085905e-01  2.83458233e-01  4.01013166e-01  3.81496638e-01\n",
      "   1.99354917e-01  1.66191995e-01]\n",
      " [ 4.72873449e-02 -3.10142636e-02  9.00721923e-02  1.93064123e-01\n",
      "  -1.47583708e-01 -2.57932305e-01]]\n",
      "Episode:    640\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.3254597753012702\n",
      "    Rolling avg. 20 reward:     138.0\n",
      "    Step:   449006\n",
      "    Q value:    0.364729106426239\n",
      "    Loss:   0.9521405696868896\n",
      "    Look-up table:\n",
      "[[ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.02417158  0.06224273  0.06871261  0.01534015  0.07819503  0.08529146]\n",
      " ...\n",
      " [ 0.08569294  0.09487942  0.16678751 -0.01167509  0.01687495  0.09658379]\n",
      " [ 0.06667419  0.08981082  0.15593958 -0.0197179   0.0204044   0.08751085]\n",
      " [-0.12329946 -0.11047554  0.02750471 -0.11082563 -0.10587576 -0.26651543]]\n",
      "Episode:    650\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.31954763432150946\n",
      "    Rolling avg. 20 reward:     135.5\n",
      "    Step:   456339\n",
      "    Q value:    0.21030913293361664\n",
      "    Loss:   0.008792906999588013\n",
      "    Look-up table:\n",
      "[[-0.02445586 -0.01309851 -0.00194684  0.00956117  0.01025467  0.01801641]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.00427416  0.02039877 -0.01952444  0.10261159  0.29676116  0.02962783]\n",
      " [ 0.00324994 -0.16218422  0.0916505  -0.12204316 -0.32009363 -0.05896296]]\n",
      "Episode:    660\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.31329769107021066\n",
      "    Rolling avg. 20 reward:     168.75\n",
      "    Step:   464240\n",
      "    Q value:    0.37439998984336853\n",
      "    Loss:   0.040624603629112244\n",
      "    Look-up table:\n",
      "[[ 0.02362867  0.05025513  0.04518116  0.05981319  0.01648128  0.06172573]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 0.08334143 -0.12812942 -0.02592407  0.07148542 -0.17893605 -0.10824047]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.30253947 -0.27879983 -0.10051028  0.17225678 -0.23052573 -0.15255447]]\n",
      "Episode:    670\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.3073282222032473\n",
      "    Rolling avg. 20 reward:     195.0\n",
      "    Step:   471935\n",
      "    Q value:    0.3410987854003906\n",
      "    Loss:   0.014366297982633114\n",
      "    Look-up table:\n",
      "[[ 0.09181248 -0.03451614  0.00778884  0.08002809  0.01573944 -0.00243066]\n",
      " [ 0.09682262 -0.03206638 -0.01236248  0.04318728  0.0126362  -0.00182706]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.2161746   1.26142216  1.52366388  1.51739621  1.19109905  1.43976045]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    680\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.3021168257480478\n",
      "    Rolling avg. 20 reward:     172.5\n",
      "    Step:   478776\n",
      "    Q value:    0.998575747013092\n",
      "    Loss:   1.0421559810638428\n",
      "    Look-up table:\n",
      "[[ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 0.46412194  0.3090145   0.37184417  0.40675867  0.21430402  0.28224689]\n",
      " [ 0.45163786  0.31074935  0.37631589  0.41758943  0.21319242  0.27707005]\n",
      " [-0.39395094 -0.2021261  -0.311324   -0.19703791 -0.19998705  0.02685009]]\n",
      "Episode:    690\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.29686463511268235\n",
      "    Rolling avg. 20 reward:     155.0\n",
      "    Step:   485791\n",
      "    Q value:    0.6008390188217163\n",
      "    Loss:   0.052882373332977295\n",
      "    Look-up table:\n",
      "[[ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 0.49339855  0.49752858  0.50346458  0.39569056  0.48789448  0.54956114]\n",
      " [ 0.5088132   0.49313971  0.51831514  0.40873188  0.50040674  0.55435914]\n",
      " [-0.4145335   0.06210548 -0.22195636 -0.10159464 -0.04516125  0.10407168]]\n",
      "Episode:    700\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.2920211526749248\n",
      "    Rolling avg. 20 reward:     142.5\n",
      "    Step:   492371\n",
      "    Q value:    0.2527405619621277\n",
      "    Loss:   0.009186990559101105\n",
      "    Look-up table:\n",
      "[[-1.97663903e-04 -3.45846266e-02  1.19705051e-02 -9.75751281e-02\n",
      "  -1.27783865e-02  3.13304812e-02]\n",
      " [ 7.24525750e-03  1.36678368e-02  1.68060511e-02 -5.44572175e-02\n",
      "  -1.45092607e-03  2.89964527e-02]\n",
      " [ 1.11106336e-02  2.75341570e-02  7.37452507e-03 -6.54355884e-02\n",
      "  -2.46223807e-03  2.30799168e-02]\n",
      " ...\n",
      " [ 1.21695668e-01  2.22388715e-01  3.62850130e-02  7.43263960e-02\n",
      "   1.28924787e-01  1.57775760e-01]\n",
      " [ 1.22470133e-01  2.23658025e-01  2.28143185e-02  5.27828336e-02\n",
      "   1.19650386e-01  1.66541874e-01]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]]\n",
      "Episode:    710\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.28701191158643835\n",
      "    Rolling avg. 20 reward:     139.0\n",
      "    Step:   499292\n",
      "    Q value:    0.3575308322906494\n",
      "    Loss:   0.01580042950809002\n",
      "    Look-up table:\n",
      "[[ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.39056295e-02 -1.06157362e-02 -2.70888209e-03  3.72375548e-03\n",
      "  -4.00105864e-02  4.18812037e-04]\n",
      " [ 1.16529614e-02 -8.49150121e-03 -7.19219446e-03 -7.40240514e-03\n",
      "  -4.84568924e-02 -7.41073489e-03]\n",
      " ...\n",
      " [ 2.07971260e-01  1.83754131e-01  1.63361967e-01  3.16759825e-01\n",
      "   1.91459522e-01  1.49539381e-01]\n",
      " [ 2.05275536e-01  1.74474120e-01  1.54804528e-01  3.08516502e-01\n",
      "   1.80085361e-01  1.45140141e-01]\n",
      " [-1.20088726e-01 -9.86633599e-02 -1.86430216e-01 -1.56782269e-02\n",
      "  -1.11474231e-01 -1.10314369e-01]]\n",
      "Episode:    720\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.2823440035335766\n",
      "    Rolling avg. 20 reward:     156.0\n",
      "    Step:   505851\n",
      "    Q value:    0.280407577753067\n",
      "    Loss:   0.3876568675041199\n",
      "    Look-up table:\n",
      "[[-0.00873283  0.00563072 -0.00129807 -0.01689036 -0.02154915 -0.0150242 ]\n",
      " [-0.01373486  0.00388734 -0.01313446 -0.01463814 -0.03224213 -0.02527396]\n",
      " [-0.0238062   0.00515257 -0.01600845 -0.01273437 -0.02929486 -0.02468775]\n",
      " ...\n",
      " [-0.0145174   0.02144797  0.05344896 -0.04911558 -0.02582367  0.12256601]\n",
      " [-0.01279846  0.02549101  0.04900672 -0.0525948  -0.02706338  0.12702288]\n",
      " [-0.06719431  0.01421253  0.06542534 -0.125542   -0.00101601  0.086236  ]]\n",
      "Episode:    730\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.27754030801235235\n",
      "    Rolling avg. 20 reward:     136.25\n",
      "    Step:   512715\n",
      "    Q value:    0.4809223711490631\n",
      "    Loss:   0.8912789225578308\n",
      "    Look-up table:\n",
      "[[ 0.00229363 -0.01924537 -0.00157659 -0.02594569 -0.01004538 -0.04105195]\n",
      " [-0.00300388 -0.02898358 -0.01631577 -0.03646187 -0.02316919 -0.04923263]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [-0.16639537  0.2081544  -0.1907454   0.08080125 -0.17720345 -0.00981297]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.24550807  0.17668776 -0.36995673 -0.08748302 -0.32995626 -0.18738385]]\n",
      "Episode:    740\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.27263220554987794\n",
      "    Rolling avg. 20 reward:     146.0\n",
      "    Step:   519852\n",
      "    Q value:    0.3063412606716156\n",
      "    Loss:   0.1500222384929657\n",
      "    Look-up table:\n",
      "[[-0.01118667 -0.08638293 -0.03415345 -0.01903169 -0.02412623 -0.00955233]\n",
      " [-0.00755811 -0.08649439 -0.03435405 -0.04764156 -0.0367111  -0.0291913 ]\n",
      " [-0.00477751 -0.07688224 -0.0308914  -0.06059439 -0.04062617 -0.04115583]\n",
      " ...\n",
      " [ 0.15170994  0.27432162  0.23200315  0.26051092  0.23966905  0.20381261]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.13888249  0.25860345  0.23805755  0.23351477  0.23829591  0.25424322]]\n",
      "Episode:    750\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.2676884037634266\n",
      "    Rolling avg. 20 reward:     167.5\n",
      "    Step:   527172\n",
      "    Q value:    0.25222015380859375\n",
      "    Loss:   0.03042718395590782\n",
      "    Look-up table:\n",
      "[[-0.06235132 -0.06289326 -0.04950634 -0.00907181 -0.01940125 -0.01321331]\n",
      " [-0.05420281 -0.10723133 -0.05573614 -0.04895259 -0.01554224 -0.03095806]\n",
      " [-0.05076201 -0.09601377 -0.05589409 -0.05977063 -0.02127153 -0.03522447]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.04000597  0.2367789   0.05736084  0.2217817   0.26934355  0.07727334]\n",
      " [-0.14299725 -0.0776733  -0.1161342  -0.07692148  0.11812398  0.01299241]]\n",
      "Episode:    760\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.26233993020260593\n",
      "    Rolling avg. 20 reward:     166.5\n",
      "    Step:   535245\n",
      "    Q value:    0.47163933515548706\n",
      "    Loss:   0.019106373190879822\n",
      "    Look-up table:\n",
      "[[-0.0558998  -0.05811374 -0.02394591 -0.02219842  0.01372221 -0.05009265]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.0614007  -0.08233388 -0.048784   -0.02427341 -0.00208828 -0.07912467]\n",
      " ...\n",
      " [-0.08826376 -0.10953563 -0.00397214 -0.05106887 -0.10515615 -0.15679967]\n",
      " [-0.09293641 -0.11643881 -0.00385579 -0.04810354 -0.1085785  -0.16411483]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    770\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.2574797517302813\n",
      "    Rolling avg. 20 reward:     152.75\n",
      "    Step:   542725\n",
      "    Q value:    0.3918890058994293\n",
      "    Loss:   0.005063324235379696\n",
      "    Look-up table:\n",
      "[[-0.05418366 -0.03191482 -0.08698918 -0.02963793 -0.02059773 -0.03314789]\n",
      " [-0.05910593 -0.04933019 -0.08391266 -0.02430612 -0.02520642 -0.05116208]\n",
      " [-0.05320337 -0.06084739 -0.08465631 -0.01831552 -0.03304911 -0.06787471]\n",
      " ...\n",
      " [ 0.09489638  0.08610521  0.11192906  0.3635416   0.10386509  0.22625172]\n",
      " [ 0.10063615  0.08166733  0.11977115  0.34551629  0.10480893  0.2224569 ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    780\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.2528454823000119\n",
      "    Rolling avg. 20 reward:     169.0\n",
      "    Step:   549990\n",
      "    Q value:    0.23683130741119385\n",
      "    Loss:   0.003246081992983818\n",
      "    Look-up table:\n",
      "[[-0.07643478 -0.01955916 -0.08534625 -0.07054764  0.00229913 -0.02366747]\n",
      " [-0.11507426 -0.04031613 -0.10285483 -0.08969066 -0.00946534 -0.04731247]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 0.11581266  0.11195944  0.07193112  0.09309781  0.14265636  0.11559421]\n",
      " [ 0.11765312  0.10806719  0.07078514  0.0914102   0.14241812  0.11542924]\n",
      " [ 0.06134126  0.04525651  0.03335962  0.0266515   0.06254056  0.05720097]]\n",
      "Episode:    790\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.2485598194952571\n",
      "    Rolling avg. 20 reward:     178.0\n",
      "    Step:   556828\n",
      "    Q value:    0.1636289805173874\n",
      "    Loss:   0.0031233367044478655\n",
      "    Look-up table:\n",
      "[[-0.0693576  -0.02966319 -0.00880687 -0.06804779 -0.04868647 -0.10312095]\n",
      " [-0.083722   -0.0420897  -0.01639271 -0.07307836 -0.0510717  -0.10786282]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.07591663 -0.12901847 -0.22791085 -0.11815435 -0.19594938 -0.09467639]]\n",
      "Episode:    800\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.2445429647722255\n",
      "    Rolling avg. 20 reward:     140.75\n",
      "    Step:   563345\n",
      "    Q value:    0.4655288755893707\n",
      "    Loss:   0.047086358070373535\n",
      "    Look-up table:\n",
      "[[-0.08099097  0.00200723 -0.06364566 -0.02231571 -0.01195693 -0.0217566 ]\n",
      " [-0.0995723  -0.01783393 -0.05848154 -0.02273491 -0.00946796 -0.03581914]\n",
      " [-0.08208606 -0.01339643 -0.04382589 -0.00779492  0.00387979 -0.02583846]\n",
      " ...\n",
      " [ 0.00606138  0.09793593  0.31225067  0.21731536  0.21624546  0.06505527]\n",
      " [ 0.0051425   0.08402915  0.30880299  0.20629829  0.2192435   0.06896691]\n",
      " [-0.45306516 -0.20458341  0.12075356  0.18201077  0.10208537 -0.33500165]]\n",
      "Episode:    810\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.24027305276850117\n",
      "    Rolling avg. 20 reward:     137.5\n",
      "    Step:   570391\n",
      "    Q value:    0.44940757751464844\n",
      "    Loss:   0.42108917236328125\n",
      "    Look-up table:\n",
      "[[-0.08144191 -0.07041685 -0.04947874 -0.06383929 -0.06209528 -0.04028359]\n",
      " [-0.09369159 -0.0795401  -0.0350658  -0.05519801 -0.04736647 -0.04415247]\n",
      " [-0.08860287 -0.07807198 -0.02815375 -0.0443188  -0.04510263 -0.04787296]\n",
      " ...\n",
      " [-0.05545175 -0.01557659 -0.02706113 -0.02794674 -0.05122545 -0.0377925 ]\n",
      " [-0.05728334 -0.02073087 -0.02943987 -0.02922902 -0.05562887 -0.04176629]\n",
      " [-0.12861533 -0.05462947 -0.07349771 -0.04137468 -0.10062101 -0.07000145]]\n",
      "Episode:    820\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.23576627940967676\n",
      "    Rolling avg. 20 reward:     152.25\n",
      "    Step:   577965\n",
      "    Q value:    0.2274138480424881\n",
      "    Loss:   0.025218728929758072\n",
      "    Look-up table:\n",
      "[[ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.05554819 -0.07228996 -0.03753248 -0.01834443 -0.05360666 -0.07079268]\n",
      " ...\n",
      " [ 0.46973145  0.76084149  0.53324878  0.63059413  0.42976969  0.53255033]\n",
      " [ 0.46426082  0.76552445  0.52649581  0.63343143  0.43357629  0.52772421]\n",
      " [ 0.2038772   0.57042611  0.18887383  0.37518203 -0.00508997  0.08291478]]\n",
      "Episode:    830\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.2314198167435109\n",
      "    Rolling avg. 20 reward:     155.5\n",
      "    Step:   585408\n",
      "    Q value:    0.35522007942199707\n",
      "    Loss:   0.004842541180551052\n",
      "    Look-up table:\n",
      "[[-0.0655013  -0.04148647 -0.10473457 -0.05560642 -0.07986847 -0.07988048]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.03105542 -0.04959217 -0.06562081 -0.03236869 -0.04743984 -0.05199769]\n",
      " ...\n",
      " [ 0.08768038  0.31419644  0.09178478  0.18085074  0.14898317  0.10571271]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.03934118  0.23827493  0.02788784  0.11271097  0.05222645  0.02631062]]\n",
      "Episode:    840\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.22781489380741668\n",
      "    Rolling avg. 20 reward:     133.0\n",
      "    Step:   591688\n",
      "    Q value:    0.7420077323913574\n",
      "    Loss:   0.015191094018518925\n",
      "    Look-up table:\n",
      "[[-0.0228917   0.02501038 -0.1082561  -0.06675103 -0.05140194 -0.00316751]\n",
      " [-0.00466093  0.00480208 -0.09408075 -0.05237582 -0.03425461  0.00915077]\n",
      " [ 0.00630531 -0.00851941 -0.07856908 -0.04056555 -0.02190271  0.01748487]\n",
      " ...\n",
      " [ 0.6161468   1.13414037  0.73715711  0.89054406  0.68102884  0.95888257]\n",
      " [ 0.62052381  1.13436604  0.74484146  0.89852417  0.68812984  0.96362865]\n",
      " [ 0.46626732  0.77711189  0.59891069  0.87233293  0.35095045  0.58822578]]\n",
      "Episode:    850\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.2231358779368279\n",
      "    Rolling avg. 20 reward:     137.0\n",
      "    Step:   599989\n",
      "    Q value:    0.24440179765224457\n",
      "    Loss:   0.14914193749427795\n",
      "    Look-up table:\n",
      "[[-0.03207165 -0.06105113 -0.02817065 -0.01763234 -0.04571888 -0.00718325]\n",
      " [-0.03912702 -0.07237896 -0.03194213 -0.02844265 -0.05185014 -0.01571488]\n",
      " [-0.0548816  -0.11003235 -0.04362255 -0.03800055 -0.06917596 -0.03939292]\n",
      " ...\n",
      " [ 0.09799716  0.33993417  0.15954539  0.4092578   0.00300133  0.412368  ]\n",
      " [ 0.09250294  0.34999251  0.16961391  0.39935303  0.00544024  0.41280842]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    860\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.21824720240061468\n",
      "    Rolling avg. 20 reward:     192.75\n",
      "    Step:   608850\n",
      "    Q value:    0.3664255738258362\n",
      "    Loss:   0.003953652456402779\n",
      "    Look-up table:\n",
      "[[-0.08907494 -0.11537465 -0.14207667 -0.08026692 -0.09545252 -0.09189245]\n",
      " [-0.10476008 -0.13720435 -0.14034331 -0.07046637 -0.09462923 -0.1114029 ]\n",
      " [-0.10631827 -0.16905746 -0.14691925 -0.08313885 -0.11046979 -0.12934849]\n",
      " ...\n",
      " [ 0.66501462  0.50964057  0.63376451  0.74953377  0.58672118  0.56612372]\n",
      " [ 0.66624272  0.51090741  0.63542795  0.75075632  0.5871473   0.56691533]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    870\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.2134618970518384\n",
      "    Rolling avg. 20 reward:     216.75\n",
      "    Step:   617718\n",
      "    Q value:    0.6237058043479919\n",
      "    Loss:   0.9712361693382263\n",
      "    Look-up table:\n",
      "[[-0.09361905 -0.10801682 -0.1427024  -0.06087464 -0.14947751 -0.08197454]\n",
      " [-0.08168608 -0.12712219 -0.12120456 -0.04666424 -0.12740883 -0.08144936]\n",
      " [-0.07635891 -0.1291934  -0.1117779  -0.0389508  -0.11838147 -0.08092895]\n",
      " ...\n",
      " [ 0.20849276  0.0492745   0.23872468  0.20929259  0.23492593  0.20064704]\n",
      " [ 0.20707574  0.039092    0.23846976  0.21537161  0.22782239  0.20140606]\n",
      " [ 0.20300153 -0.00258487  0.24223465  0.22712931  0.22283746  0.19861458]]\n",
      "Episode:    880\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.2094517337296802\n",
      "    Rolling avg. 20 reward:     186.5\n",
      "    Step:   625304\n",
      "    Q value:    0.44263511896133423\n",
      "    Loss:   0.2980366349220276\n",
      "    Look-up table:\n",
      "[[ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [-1.09177113e-01 -1.09169930e-01 -1.13732576e-01 -8.23943019e-02\n",
      "  -1.98550820e-02 -6.20708466e-02]\n",
      " [-1.02254689e-01 -1.10538900e-01 -1.01811290e-01 -7.28797019e-02\n",
      "  -8.11532140e-03 -6.46136701e-02]\n",
      " ...\n",
      " [ 3.88657749e-02 -6.84991479e-03 -1.71343982e-02  1.47879720e-02\n",
      "   3.31723690e-03  5.17308712e-04]\n",
      " [ 3.32629681e-02 -5.18858433e-04 -2.33978331e-02  9.59393382e-03\n",
      "  -3.72731686e-03 -2.02444196e-03]\n",
      " [ 7.09807873e-03 -2.90667653e-01 -1.43868059e-01 -1.78581864e-01\n",
      "  -5.10749221e-02 -6.96817338e-02]]\n",
      "Episode:    890\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.2062276808921294\n",
      "    Rolling avg. 20 reward:     133.5\n",
      "    Step:   631509\n",
      "    Q value:    0.14505857229232788\n",
      "    Loss:   0.002294725039973855\n",
      "    Look-up table:\n",
      "[[ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.08397278 -0.06802261 -0.09334862 -0.07235026 -0.08925268 -0.07537648]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 0.56290978  0.34543756  0.59720349  0.61102974  0.43058193  0.63436228]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.09407777 -0.01003268  0.2771787   0.25230613 -0.0046851   0.27342469]]\n",
      "Episode:    900\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.20257765270338393\n",
      "    Rolling avg. 20 reward:     121.5\n",
      "    Step:   638652\n",
      "    Q value:    0.32513779401779175\n",
      "    Loss:   0.004239588510245085\n",
      "    Look-up table:\n",
      "[[-0.06604829 -0.14567965 -0.05514514 -0.09052634 -0.08551896 -0.07037082]\n",
      " [-0.06745902 -0.15069729 -0.0499984  -0.09485894 -0.08213365 -0.07785508]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 0.40512779  0.33306268  0.35787076  0.33784842  0.36067852  0.34767014]\n",
      " [ 0.39964375  0.32829341  0.34866261  0.33132285  0.35408583  0.3403061 ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    910\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.19826921052182758\n",
      "    Rolling avg. 20 reward:     184.75\n",
      "    Step:   647251\n",
      "    Q value:    0.2640368342399597\n",
      "    Loss:   0.45546767115592957\n",
      "    Look-up table:\n",
      "[[-0.049393   -0.11583069 -0.09110576 -0.09817269 -0.13509169 -0.10443905]\n",
      " [-0.05249462 -0.11607692 -0.0939779  -0.10256207 -0.13600495 -0.10491288]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 0.01937103  0.03421301  0.01184911  0.02034253 -0.05222416  0.01988402]\n",
      " [ 0.02083662  0.03475243  0.01365557  0.02133912 -0.05035403  0.02192533]\n",
      " [-0.14197612 -0.18831632 -0.17270175 -0.20103574 -0.26112297 -0.16831362]]\n",
      "Episode:    920\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.19459991500005328\n",
      "    Rolling avg. 20 reward:     196.5\n",
      "    Step:   654723\n",
      "    Q value:    0.28621143102645874\n",
      "    Loss:   0.004425829276442528\n",
      "    Look-up table:\n",
      "[[-0.13622242 -0.07609683 -0.12877527 -0.11204523 -0.11331344 -0.14036804]\n",
      " [-0.13817161 -0.07818371 -0.12689605 -0.1165387  -0.11041021 -0.13816148]\n",
      " [-0.13599712 -0.07652324 -0.1242564  -0.114685   -0.10771275 -0.13564068]\n",
      " ...\n",
      " [ 0.04308914  0.04077786  0.08661273  0.06201705  0.07799843  0.08674997]\n",
      " [ 0.04347734  0.04107305  0.08697537  0.06239995  0.07838884  0.08706483]\n",
      " [-0.08950451 -0.11652622 -0.0274547  -0.08098522  0.00919104 -0.01004905]]\n",
      "Episode:    930\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.19062977709017515\n",
      "    Rolling avg. 20 reward:     175.25\n",
      "    Step:   662968\n",
      "    Q value:    0.24114303290843964\n",
      "    Loss:   0.2764436602592468\n",
      "    Look-up table:\n",
      "[[-0.05682197 -0.14376608 -0.03744072 -0.08220783 -0.06847477 -0.1059061 ]\n",
      " [-0.06250158 -0.13808337 -0.03256309 -0.08870789 -0.06289241 -0.09897313]\n",
      " [-0.04607564 -0.12337458 -0.01039484 -0.07418454 -0.04506528 -0.07737643]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.67674863  0.66333187  0.74154139  0.73714209  0.70543146  0.87873757]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    940\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.1872754794561003\n",
      "    Rolling avg. 20 reward:     189.5\n",
      "    Step:   670069\n",
      "    Q value:    0.35412463545799255\n",
      "    Loss:   0.5500935316085815\n",
      "    Look-up table:\n",
      "[[-0.13629687 -0.10367242 -0.08975074 -0.09163967 -0.0732843  -0.08206767]\n",
      " [-0.12806889 -0.09587309 -0.07193303 -0.08869699 -0.06472212 -0.06342033]\n",
      " [-0.13010743 -0.09665442 -0.07494166 -0.08923966 -0.06723192 -0.06775075]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.14542142  0.16866092  0.2251772   0.10411263  0.21541348  0.21414408]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    950\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.18342725512311717\n",
      "    Rolling avg. 20 reward:     187.25\n",
      "    Step:   678374\n",
      "    Q value:    0.2867695689201355\n",
      "    Loss:   0.7639529705047607\n",
      "    Look-up table:\n",
      "[[-0.04791686 -0.04496214 -0.11703342 -0.01773423 -0.04095525 -0.09012139]\n",
      " [-0.04396197 -0.03077149 -0.10852402 -0.01419505 -0.03339267 -0.08459008]\n",
      " [-0.04246077 -0.03113323 -0.10735625 -0.01254779 -0.03326982 -0.08418056]\n",
      " ...\n",
      " [ 0.58024639  0.51607543  0.58463156  0.53506649  0.54658544  0.58268547]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.28295106  0.08724524  0.28562105  0.26930532  0.27299798  0.26831132]]\n",
      "Episode:    960\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.17958670591283715\n",
      "    Rolling avg. 20 reward:     190.25\n",
      "    Step:   686838\n",
      "    Q value:    0.2960948348045349\n",
      "    Loss:   0.0024559595622122288\n",
      "    Look-up table:\n",
      "[[-0.03511241 -0.08359957 -0.03518456 -0.05722034 -0.09928975 -0.0698157 ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 0.66432476  0.63979888  0.63424778  0.67510939  0.63345593  0.66614008]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.29583791  0.1107484   0.27601758  0.30361313  0.25841767  0.21319658]]\n",
      "Episode:    970\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.17634778737976922\n",
      "    Rolling avg. 20 reward:     179.25\n",
      "    Step:   694118\n",
      "    Q value:    0.21125085651874542\n",
      "    Loss:   0.0062185013666749\n",
      "    Look-up table:\n",
      "[[-0.11644688 -0.09072191 -0.11416033 -0.06387237 -0.0036445  -0.07330629]\n",
      " [-0.12268952 -0.06522304 -0.10752222 -0.0599744   0.0056054  -0.08043292]\n",
      " [-0.11932173 -0.06207108 -0.10284933 -0.05689979  0.00745013 -0.07829493]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.08629224 -0.1817438  -0.08507234 -0.05378881 -0.14696336 -0.2507939 ]\n",
      " [-0.16586187 -0.35025424 -0.1921767  -0.13106602 -0.21476465 -0.35951266]]\n",
      "Episode:    980\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.17298858087348998\n",
      "    Rolling avg. 20 reward:     192.0\n",
      "    Step:   701811\n",
      "    Q value:    0.22005262970924377\n",
      "    Loss:   0.1439037322998047\n",
      "    Look-up table:\n",
      "[[ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [-1.44861937e-02 -1.21749997e-01 -1.33624673e-03 -6.88695908e-03\n",
      "  -7.91771710e-02 -7.42032230e-02]\n",
      " [-1.52504742e-02 -1.23589456e-01 -2.55331397e-03 -7.59333372e-03\n",
      "  -7.90204704e-02 -7.42671788e-02]\n",
      " ...\n",
      " [ 3.17183733e-02 -5.94176054e-02  7.96502829e-03  1.47002935e-03\n",
      "  -2.88177431e-02  2.16055810e-02]\n",
      " [ 3.02489996e-02 -5.53003550e-02  8.11821222e-03 -4.55379486e-05\n",
      "  -2.62972414e-02  2.22334266e-02]\n",
      " [ 2.39146352e-02 -1.41991913e-01 -1.52723789e-02 -5.33282757e-02\n",
      "  -2.56634653e-02  5.19420803e-02]]\n",
      "Episode:    990\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.16954409842245058\n",
      "    Rolling avg. 20 reward:     207.75\n",
      "    Step:   709856\n",
      "    Q value:    0.16011673212051392\n",
      "    Loss:   0.002664322964847088\n",
      "    Look-up table:\n",
      "[[-0.01545033 -0.06274819 -0.10331783 -0.05472302 -0.02929464 -0.05040133]\n",
      " [-0.01526821 -0.05644786 -0.10087055 -0.0561125  -0.02967036 -0.05712965]\n",
      " [-0.0113391  -0.0508981  -0.09616971 -0.05503526 -0.02428117 -0.05437204]\n",
      " ...\n",
      " [ 0.11786431  0.07908894  0.19954637  0.1379429   0.19120844  0.28409177]\n",
      " [ 0.11840197  0.07473944  0.19957638  0.13776223  0.18795198  0.28295821]\n",
      " [ 0.03982988 -0.06503737  0.13113666  0.04793841  0.05769327  0.16001348]]\n",
      "Episode:    1000\n",
      "% of CUDA memory used:  5.0331648%\n",
      "    Epsilon:    0.1661586467795777\n",
      "    Rolling avg. 20 reward:     195.75\n",
      "    Step:   717924\n",
      "    Q value:    0.37130606174468994\n",
      "    Loss:   0.1037706732749939\n",
      "    Look-up table:\n",
      "[[-0.20785832 -0.13108069 -0.19569334 -0.20646185 -0.10279161 -0.03024939]\n",
      " [-0.18400192 -0.09595883 -0.16256768 -0.18059    -0.08263987 -0.01405895]\n",
      " [-0.17896062 -0.08472592 -0.15427655 -0.17091945 -0.07552293 -0.00545865]\n",
      " ...\n",
      " [ 0.48814252  0.29018801  0.45783278  0.54533482  0.43575114  0.45610079]\n",
      " [ 0.48518348  0.28695565  0.45510274  0.54279006  0.43268681  0.45312083]\n",
      " [ 0.23803899 -0.04715306  0.14594023  0.30001181  0.10405195  0.1343233 ]]\n",
      "Training finished at 1000 episodes!\n",
      "    Final epsilon:  0.1661586467795777\n",
      "    Final Rolling avg. 20 reward:   195.75\n",
      "    Final look-up table\n",
      "[[-0.20785832 -0.13108069 -0.19569334 -0.20646185 -0.10279161 -0.03024939]\n",
      " [-0.18400192 -0.09595883 -0.16256768 -0.18059    -0.08263987 -0.01405895]\n",
      " [-0.17896062 -0.08472592 -0.15427655 -0.17091945 -0.07552293 -0.00545865]\n",
      " ...\n",
      " [ 0.48814252  0.29018801  0.45783278  0.54533482  0.43575114  0.45610079]\n",
      " [ 0.48518348  0.28695565  0.45510274  0.54279006  0.43268681  0.45312083]\n",
      " [ 0.23803899 -0.04715306  0.14594023  0.30001181  0.10405195  0.1343233 ]]\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "print(f\"Using CUDA: {use_cuda}\")\n",
    "print()\n",
    "\n",
    "look_up_table = np.zeros(shape=(0,actions)) # Initialize the look-up table\n",
    "\n",
    "save_dir = Path(\"checkpoints_space-invaders\") / \"last_test\"\n",
    "save_dir.mkdir(parents=True)\n",
    "\n",
    "ship = Ship(state_dim=(4, 84, 84),\n",
    "            action_dim=env_2.action_space.n,\n",
    "            save_dir=save_dir,\n",
    "            exploration_rate_decay=0.9999975,\n",
    "            exploration_rate_min=0.1)\n",
    "\n",
    "episodes = 1000\n",
    "e=1\n",
    "loop_condition = True\n",
    "episode_reward = deque(maxlen=20)\n",
    "\n",
    "while loop_condition:\n",
    "    memory_usage = torch.cuda.memory_reserved(0)/6e9\n",
    "    look_up_table = np.zeros(shape=(0,actions)) #Reset the value of the look-up table\n",
    "    state = env_2.reset()\n",
    "\n",
    "    sum_reward = 0\n",
    "    number_of_states = 1\n",
    "    # Play the game!\n",
    "    while True:\n",
    "\n",
    "        # Run agent on the state\n",
    "        action,action_values = ship.act(state)\n",
    "\n",
    "        # Agent performs action\n",
    "        next_state, reward, done, info = env_2.step(action)\n",
    "\n",
    "        # Remember\n",
    "        ship.push_to_memory_queue(state, next_state, action, reward, done)\n",
    "\n",
    "        # Learn\n",
    "        q, loss = ship.learn()\n",
    "\n",
    "        # Append q values to look-up table\n",
    "        look_up_table = np.append(look_up_table,action_values,axis=0)\n",
    "        sum_reward+=reward\n",
    "\n",
    "        # Update state\n",
    "        state = next_state\n",
    "\n",
    "        # Check if end of game\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    episode_reward.append(sum_reward)\n",
    "    if e % 10 == 0:\n",
    "        print(f\"Episode:    {e}\")\n",
    "        print(f\"% of CUDA memory used:  {memory_usage*100}%\\n\"\n",
    "              f\"    Epsilon:    {ship.exploration_rate}\\n\"\n",
    "              f\"    Rolling avg. 20 reward:     {sum(episode_reward)/len(episode_reward)}\\n\"\n",
    "              f\"    Step:   {ship.curr_step}\\n\"\n",
    "              f\"    Q value:    {ship.Q}\\n\"\n",
    "              f\"    Loss:   {ship.loss}\\n\"\n",
    "              f\"    Look-up table:\")\n",
    "        print(look_up_table)\n",
    "    e+=1\n",
    "\n",
    "    if e>episodes or ship.exploration_rate<=ship.exploration_rate_min:\n",
    "        loop_condition=False\n",
    "        print(f\"Training finished at {e-1} episodes!\\n\"\n",
    "              f\"    Final epsilon:  {ship.exploration_rate}\\n\"\n",
    "              f\"    Final Rolling avg. 20 reward:   {sum(episode_reward)/len(episode_reward)}\\n\"\n",
    "              f\"    Final look-up table\")\n",
    "        print(look_up_table)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualize the Look-up table on a heatmap"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "(1057, 6)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "look_up_table.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = env.unwrapped.get_action_meanings()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.matshow(look_up_table, fignum=1, aspect='auto')\n",
    "plt.xticks(ticks=range(actions),labels=labels,rotation ='horizontal')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save the model to a chkpt file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent saved to checkpoints_space-invaders\\last_test\\space-invaders_net_717924.chkpt at step 717924\n"
     ]
    }
   ],
   "source": [
    "best_model_path = ship.save()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Play the game (This will crash the kernel)\n",
    "@OpenAi pls fix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  1\n",
      "     Episode Reward:     515.0\n",
      "     Average Reward:     515.0\n",
      "Episode:  2\n",
      "     Episode Reward:     110.0\n",
      "     Average Reward:     312.5\n",
      "Episode:  3\n",
      "     Episode Reward:     125.0\n",
      "     Average Reward:     250.0\n"
     ]
    }
   ],
   "source": [
    "#ship = Ship(state_dim=(4, 84, 84), action_dim=env_2.action_space.n, save_dir=save_dir)\n",
    "#ship.load('checkpoints_space-invaders/best_model/space-invaders_net_860474.chkpt')\n",
    "back = ship.exploration_rate\n",
    "env_3 = gym.make('SpaceInvaders-v0',render_mode='human')\n",
    "env_3 = SkipFrame(env_3, skip=4)\n",
    "env_3 = GrayScaleObservation(env_3)\n",
    "env_3 = ResizeObservation(env_3, shape=84)\n",
    "env_3 = FrameStack(env_3, num_stack=4)\n",
    "\n",
    "reward_list=[]\n",
    "for e in range(1,4):\n",
    "\n",
    "    state = env_3.reset()\n",
    "    episode_reward=0\n",
    "    # Play the game!\n",
    "    while True:\n",
    "\n",
    "        # Run agent on the state\n",
    "        action,_ = ship.act(state)\n",
    "\n",
    "        # Agent performs action\n",
    "        next_state, reward, done, info = env_3.step(action)\n",
    "        episode_reward+=reward\n",
    "\n",
    "        if done:\n",
    "            reward_list.append(episode_reward)\n",
    "            break\n",
    "    print(\n",
    "        f\"Episode:  {e}\\n\"\n",
    "        f\"     Episode Reward:     {episode_reward}\\n\"\n",
    "        f\"     Average Reward:     {sum(reward_list)/len(reward_list)}\")\n",
    "env_3.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Optuna Optimizazion"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from tqdm.notebook import tnrange, tqdm\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "class Optimizer:\n",
    "    def __init__(self):\n",
    "        self.agent = None\n",
    "        self.avg_reward = 0\n",
    "\n",
    "    def define_model(self,trial):\n",
    "        exploration_rate_decay = trial.suggest_categorical(\"exploration_rate_decay\",[0.99999975,0.9999975,0.999975])\n",
    "        exploration_rate_min = trial.suggest_float(\"exploration_rate_min\",0.05,0.2,step=0.05)\n",
    "        batch_size = trial.suggest_int(\"batch_size\",8,64,step=8)\n",
    "        gamma = trial.suggest_float(\"gamma\",0.9,0.99,step=0.01)\n",
    "        lr = trial.suggest_float(\"lr\",0.0001,0.001,step=0.0001)\n",
    "        learn_every = trial.suggest_int('learn_every',1,5)\n",
    "        sync_every = trial.suggest_int('sync_every',5000,20000,step=5000)\n",
    "\n",
    "        return Ship(state_dim=(4, 84, 84),\n",
    "                    action_dim=env_2.action_space.n,\n",
    "                    save_dir=save_dir,\n",
    "                    exploration_rate_decay=exploration_rate_decay,\n",
    "                    exploration_rate_min=exploration_rate_min,\n",
    "                    batch_size= batch_size,\n",
    "                    gamma = gamma,\n",
    "                    lr = lr,\n",
    "                    learn_every=learn_every,\n",
    "                    sync_every = sync_every)\n",
    "\n",
    "    def objective(self,trial):\n",
    "        agent = self.define_model(trial)\n",
    "        avg_reward = 0\n",
    "        status = 'Current Params:\\n'\n",
    "        #print('Current Params:',end='\\r')\n",
    "        for key, value in trial.params.items():\n",
    "            status+=\"    {}: {}\".format(key, value) + '\\n'\n",
    "            #print(\"    {}: {}\".format(key, value),end='\\r')\n",
    "        print(status)\n",
    "\n",
    "        episodes = 1000\n",
    "        e=1\n",
    "        loop_condition = True\n",
    "        episode_reward = deque(maxlen=20)\n",
    "\n",
    "        while loop_condition:\n",
    "            memory_usage = torch.cuda.memory_reserved(0)/6e9\n",
    "            look_up_table = np.zeros(shape=(0,actions))\n",
    "            state = env_2.reset()\n",
    "\n",
    "            sum_reward = 0\n",
    "            # Play the game!\n",
    "            while True:\n",
    "\n",
    "                # Run agent on the state\n",
    "                action,action_values = agent.act(state)\n",
    "\n",
    "                # Agent performs action\n",
    "                next_state, reward, done, info = env_2.step(action)\n",
    "\n",
    "                # Remember\n",
    "                agent.push_to_memory_queue(state, next_state, action, reward, done)\n",
    "\n",
    "                # Learn\n",
    "                q, loss = agent.learn()\n",
    "                look_up_table = np.append(look_up_table,action_values,axis=0)\n",
    "                sum_reward+=reward\n",
    "\n",
    "                # Update state\n",
    "                state = next_state\n",
    "\n",
    "                # Check if end of game\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "            episode_reward.append(sum_reward)\n",
    "            avg_reward = sum(episode_reward)/len(episode_reward)\n",
    "            if e % 10 == 0:\n",
    "                print(f\"Episode:    {e}\")\n",
    "                print(f\"% of CUDA memory used:  {memory_usage*100}%\\n\"\n",
    "                      f\"    Epsilon:    {agent.exploration_rate}\\n\"\n",
    "                      f\"    Rolling avg. 20 reward:     {avg_reward}\\n\"\n",
    "                      f\"    Step:   {agent.curr_step}\\n\"\n",
    "                      f\"    Q value:    {agent.Q}\\n\"\n",
    "                      f\"    Loss:   {agent.loss}\\n\"\n",
    "                      f\"    Look-up table:\")\n",
    "                print(look_up_table)\n",
    "            trial.report(avg_reward,e)\n",
    "\n",
    "\n",
    "            if trial.should_prune():\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "            e+=1\n",
    "            if e>episodes:\n",
    "                loop_condition=False\n",
    "                print(f\"Training finished at {e-1} episodes!\\n\"\n",
    "                      f\"    Final epsilon:  {agent.exploration_rate}\\n\"\n",
    "                      f\"    Final Rolling avg. 20 reward:   {avg_reward}\\n\"\n",
    "                      f\"    Final look-up table\")\n",
    "                print(look_up_table)\n",
    "\n",
    "\n",
    "        if avg_reward > self.avg_reward:\n",
    "            self.avg_reward = avg_reward\n",
    "            self.agent = agent\n",
    "        return avg_reward"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-06-07 02:20:30,607]\u001B[0m A new study created in memory with name: no-name-98016654-ca81-4b7f-ba67-b4d695763c4b\u001B[0m\n",
      "C:\\ProgramData\\Anaconda3\\envs\\robo_shakespeare\\lib\\site-packages\\optuna\\progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4d7f8d7f3ee242dc8ec7c209ba0c4c87"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Params:\n",
      "    exploration_rate_decay: 0.9999975\n",
      "    exploration_rate_min: 0.2\n",
      "    batch_size: 64\n",
      "    gamma: 0.93\n",
      "    lr: 0.0008\n",
      "    learn_every: 2\n",
      "    sync_every: 10000\n",
      "\n",
      "Episode:    10\n",
      "% of CUDA memory used:  4.264209066666667%\n",
      "    Epsilon:    0.9840608739387163\n",
      "    Rolling avg. 20 reward:     108.5\n",
      "    Step:   6427\n",
      "    Q value:    None\n",
      "    Loss:   0\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    20\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9669243269768778\n",
      "    Rolling avg. 20 reward:     116.75\n",
      "    Step:   13454\n",
      "    Q value:    -0.000480805232655257\n",
      "    Loss:   0.14019611477851868\n",
      "    Look-up table:\n",
      "[[-1.29605187e-02 -8.80685635e-03 -1.09404651e-02  8.93962220e-04\n",
      "   1.07470155e-02 -1.15969023e-02]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " ...\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]]\n",
      "Episode:    30\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9487949571747091\n",
      "    Rolling avg. 20 reward:     149.25\n",
      "    Step:   21025\n",
      "    Q value:    0.004013511352241039\n",
      "    Loss:   0.7646970748901367\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    40\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9317226556092564\n",
      "    Rolling avg. 20 reward:     167.25\n",
      "    Step:   28288\n",
      "    Q value:    0.009857745841145515\n",
      "    Loss:   0.00010696523531805724\n",
      "    Look-up table:\n",
      "[[ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " ...\n",
      " [ 1.20138777e-02 -6.98481104e-04  8.37091298e-04  4.71745199e-03\n",
      "   4.09459323e-03  2.61366609e-02]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]]\n",
      "Episode:    50\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.915206907589222\n",
      "    Rolling avg. 20 reward:     162.5\n",
      "    Step:   35442\n",
      "    Q value:    0.036931537091732025\n",
      "    Loss:   0.4522709548473358\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    60\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8980808921698045\n",
      "    Rolling avg. 20 reward:     163.5\n",
      "    Step:   42998\n",
      "    Q value:    0.04463369399309158\n",
      "    Loss:   9.232357842847705e-05\n",
      "    Look-up table:\n",
      "[[0.01855119 0.03564907 0.03950638 0.03628977 0.02488302 0.04316326]\n",
      " [0.01855119 0.03564907 0.03950638 0.03628977 0.02488302 0.04316326]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    70\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8837706864641781\n",
      "    Rolling avg. 20 reward:     160.0\n",
      "    Step:   49423\n",
      "    Q value:    0.037306640297174454\n",
      "    Loss:   0.3827139437198639\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    80\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8703475419645705\n",
      "    Rolling avg. 20 reward:     150.0\n",
      "    Step:   55545\n",
      "    Q value:    0.04682115465402603\n",
      "    Loss:   0.00014300819020718336\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    90\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8581617381949941\n",
      "    Rolling avg. 20 reward:     123.0\n",
      "    Step:   61185\n",
      "    Q value:    0.048028603196144104\n",
      "    Loss:   0.0703154131770134\n",
      "    Look-up table:\n",
      "[[0.05710463 0.05346847 0.04772653 0.06076659 0.0452044  0.04344558]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.05721586 0.05348663 0.04768216 0.06158064 0.04509849 0.0435771 ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    100\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8444031678572088\n",
      "    Rolling avg. 20 reward:     130.75\n",
      "    Step:   67650\n",
      "    Q value:    0.0619293749332428\n",
      "    Loss:   0.30464857816696167\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [0.04802917 0.06561564 0.0413909  0.06571341 0.05084077 0.06138091]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    110\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8315363787108809\n",
      "    Rolling avg. 20 reward:     128.25\n",
      "    Step:   73792\n",
      "    Q value:    0.05538089945912361\n",
      "    Loss:   0.14842237532138824\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [0.05914376 0.04271941 0.06149118 0.04297854 0.05293268 0.07218408]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.05939618 0.0427247  0.0614459  0.04297771 0.05301014 0.07246156]]\n",
      "Episode:    120\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8161862080652873\n",
      "    Rolling avg. 20 reward:     119.25\n",
      "    Step:   81245\n",
      "    Q value:    0.07737612724304199\n",
      "    Loss:   0.22639822959899902\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.06528555 0.07708137 0.06972084 0.07219432 0.08272109 0.06848457]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    130\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8024764460963024\n",
      "    Rolling avg. 20 reward:     171.25\n",
      "    Step:   88021\n",
      "    Q value:    0.07494489848613739\n",
      "    Loss:   0.07021837681531906\n",
      "    Look-up table:\n",
      "[[0.06555232 0.07334571 0.07297187 0.06295427 0.09594104 0.06532474]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.07040233 0.0706126  0.08532576 0.07417346 0.07675421 0.06700401]\n",
      " [0.07078113 0.0704518  0.08574905 0.0741952  0.07715955 0.0670486 ]]\n",
      "Episode:    140\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.7874756742071135\n",
      "    Rolling avg. 20 reward:     175.25\n",
      "    Step:   95569\n",
      "    Q value:    0.07628212124109268\n",
      "    Loss:   8.061586413532495e-05\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    150\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.7710725394398938\n",
      "    Rolling avg. 20 reward:     210.5\n",
      "    Step:   103989\n",
      "    Q value:    0.094794362783432\n",
      "    Loss:   4.961314698448405e-05\n",
      "    Look-up table:\n",
      "[[0.08798973 0.08399409 0.1056158  0.10442616 0.09408113 0.0877772 ]\n",
      " [0.08798973 0.08399409 0.1056158  0.10442616 0.09408113 0.0877772 ]\n",
      " [0.08843232 0.08395769 0.1056684  0.10391102 0.09425262 0.08824559]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    160\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.757109150412152\n",
      "    Rolling avg. 20 reward:     215.0\n",
      "    Step:   111299\n",
      "    Q value:    0.09940211474895477\n",
      "    Loss:   0.0001152548793470487\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.09337644 0.09052902 0.11567812 0.09649297 0.0870522  0.10971121]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    170\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.7429787229411642\n",
      "    Rolling avg. 20 reward:     157.0\n",
      "    Step:   118835\n",
      "    Q value:    0.09349359571933746\n",
      "    Loss:   0.0003865905455313623\n",
      "    Look-up table:\n",
      "[[0.07864796 0.0938369  0.09480982 0.09764221 0.0803941  0.08068638]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    180\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.7274078913087142\n",
      "    Rolling avg. 20 reward:     173.25\n",
      "    Step:   127307\n",
      "    Q value:    0.08341138809919357\n",
      "    Loss:   5.981510184938088e-05\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [0.08685715 0.07564073 0.0728112  0.11082461 0.09172081 0.08008892]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [0.07490454 0.08369452 0.0948437  0.07591727 0.08676115 0.09022721]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    190\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.7106782900297399\n",
      "    Rolling avg. 20 reward:     245.5\n",
      "    Step:   136614\n",
      "    Q value:    0.09468793869018555\n",
      "    Loss:   0.14048296213150024\n",
      "    Look-up table:\n",
      "[[0.09445055 0.10616229 0.10636509 0.10959251 0.11604089 0.10793203]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.08452751 0.08796214 0.11063995 0.09051767 0.09508668 0.09482003]\n",
      " [0.08452751 0.08796214 0.11063995 0.09051767 0.09508668 0.09482003]]\n",
      "Episode:    200\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.6980546045082969\n",
      "    Rolling avg. 20 reward:     231.25\n",
      "    Step:   143783\n",
      "    Q value:    0.12422166764736176\n",
      "    Loss:   0.6868783235549927\n",
      "    Look-up table:\n",
      "[[0.11265453 0.1181787  0.11239314 0.12848264 0.12501357 0.11798606]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [0.1104916  0.1225255  0.10942488 0.13399388 0.11200359 0.11623178]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.11084592 0.12237509 0.10942488 0.13407443 0.11194336 0.11620328]]\n",
      "Episode:    210\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.6869642888929219\n",
      "    Rolling avg. 20 reward:     163.75\n",
      "    Step:   150189\n",
      "    Q value:    0.12783901393413544\n",
      "    Loss:   0.22660647332668304\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.1172728  0.12592363 0.12363731 0.12038049 0.12922746 0.13797487]]\n",
      "Episode:    220\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.6748512440502232\n",
      "    Rolling avg. 20 reward:     157.75\n",
      "    Step:   157305\n",
      "    Q value:    0.13142290711402893\n",
      "    Loss:   7.380579336313531e-05\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [0.1248984  0.11269552 0.14825134 0.13159262 0.13848212 0.12345046]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    230\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.6629501276835894\n",
      "    Rolling avg. 20 reward:     165.5\n",
      "    Step:   164422\n",
      "    Q value:    0.14384737610816956\n",
      "    Loss:   0.3044681251049042\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.12937304 0.12950696 0.14093111 0.16547778 0.12006477 0.14031817]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    240\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.6528352144773645\n",
      "    Rolling avg. 20 reward:     149.75\n",
      "    Step:   170572\n",
      "    Q value:    0.16156157851219177\n",
      "    Loss:   0.14030081033706665\n",
      "    Look-up table:\n",
      "[[0.14678386 0.14048442 0.16316757 0.16611634 0.15265113 0.16864061]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.1466925  0.14027771 0.16306137 0.16554584 0.15239407 0.16856129]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    250\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.6422128080226835\n",
      "    Rolling avg. 20 reward:     140.5\n",
      "    Step:   177134\n",
      "    Q value:    0.14449769258499146\n",
      "    Loss:   0.14818909764289856\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [0.13492103 0.14695624 0.145053   0.1237845  0.14016987 0.15011789]\n",
      " [0.13492103 0.14695624 0.145053   0.1237845  0.14016987 0.15011789]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    260\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.6306144759310526\n",
      "    Rolling avg. 20 reward:     175.25\n",
      "    Step:   184424\n",
      "    Q value:    0.13139447569847107\n",
      "    Loss:   0.00010725837637437508\n",
      "    Look-up table:\n",
      "[[0.14174436 0.14938237 0.1429106  0.12292734 0.13376607 0.12683238]\n",
      " [0.14174436 0.14938237 0.1429106  0.12292734 0.13376607 0.12683238]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.13754566 0.12296072 0.14177464 0.12020374 0.12651782 0.12139424]]\n",
      "Episode:    270\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.6183886715772007\n",
      "    Rolling avg. 20 reward:     166.25\n",
      "    Step:   192255\n",
      "    Q value:    0.14508074522018433\n",
      "    Loss:   0.1482735574245453\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    280\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.6063013583731652\n",
      "    Rolling avg. 20 reward:     174.25\n",
      "    Step:   200151\n",
      "    Q value:    0.13436545431613922\n",
      "    Loss:   0.46091148257255554\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.12355344 0.13874072 0.13282548 0.14341418 0.13162373 0.12794662]]\n",
      "Episode:    290\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.5954855546615134\n",
      "    Rolling avg. 20 reward:     197.5\n",
      "    Step:   207351\n",
      "    Q value:    0.14445656538009644\n",
      "    Loss:   0.3830745816230774\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [0.13850209 0.11406022 0.1235845  0.12333154 0.11396673 0.12618589]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    300\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.584403756329461\n",
      "    Rolling avg. 20 reward:     203.25\n",
      "    Step:   214865\n",
      "    Q value:    0.15484988689422607\n",
      "    Loss:   0.2264762669801712\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [0.14108853 0.1709511  0.16013934 0.14971586 0.17223892 0.1587594 ]\n",
      " [0.14108853 0.1709511  0.16013934 0.14971586 0.17223892 0.1587594 ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    310\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.5747870283926205\n",
      "    Rolling avg. 20 reward:     185.25\n",
      "    Step:   221502\n",
      "    Q value:    0.17612941563129425\n",
      "    Loss:   0.0006670120637863874\n",
      "    Look-up table:\n",
      "[[0.1740935  0.15780313 0.16948701 0.16059898 0.17474939 0.17314623]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [0.18344796 0.18605953 0.17068717 0.16177055 0.16403879 0.16481833]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.18313815 0.18617631 0.17076132 0.16162609 0.16395068 0.16464782]]\n",
      "Episode:    320\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.5632308397344659\n",
      "    Rolling avg. 20 reward:     190.75\n",
      "    Step:   229626\n",
      "    Q value:    0.18234345316886902\n",
      "    Loss:   0.3047225773334503\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [0.16355798 0.16117017 0.16612208 0.16229047 0.18652435 0.18100566]\n",
      " [0.16355798 0.16117017 0.16612208 0.16229047 0.18652435 0.18100566]\n",
      " ...\n",
      " [0.160824   0.18078193 0.18566425 0.1631808  0.19619514 0.178835  ]\n",
      " [0.16066408 0.18061449 0.1852078  0.16329509 0.19655818 0.17881337]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    330\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.5556366338863259\n",
      "    Rolling avg. 20 reward:     155.0\n",
      "    Step:   235056\n",
      "    Q value:    0.17217490077018738\n",
      "    Loss:   0.2880789041519165\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.17762014 0.17227757 0.17201331 0.16789304 0.1662567  0.17319095]\n",
      " [0.17762014 0.17227757 0.17201331 0.16789304 0.1662567  0.17319095]]\n",
      "Episode:    340\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.5446642335065592\n",
      "    Rolling avg. 20 reward:     117.0\n",
      "    Step:   243034\n",
      "    Q value:    0.1771242320537567\n",
      "    Loss:   0.6871743202209473\n",
      "    Look-up table:\n",
      "[[0.17134506 0.15968508 0.16230437 0.16700324 0.15335931 0.15658635]\n",
      " [0.17134506 0.15968508 0.16230437 0.16700324 0.15335931 0.15658635]\n",
      " [0.17099971 0.1595173  0.16202937 0.16665475 0.15332554 0.156661  ]\n",
      " ...\n",
      " [0.17636132 0.1766222  0.17563204 0.16421631 0.18341258 0.17520392]\n",
      " [0.17657593 0.17672297 0.17580159 0.16437431 0.18402955 0.1754646 ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    350\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.5339125142647762\n",
      "    Rolling avg. 20 reward:     193.5\n",
      "    Step:   251009\n",
      "    Q value:    0.1760788857936859\n",
      "    Loss:   0.3828667402267456\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    360\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.5239739509123011\n",
      "    Rolling avg. 20 reward:     222.5\n",
      "    Step:   258525\n",
      "    Q value:    0.17174923419952393\n",
      "    Loss:   0.07035539299249649\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [0.16647641 0.17102073 0.16099618 0.17425475 0.15887195 0.15909405]\n",
      " [0.16647641 0.17102073 0.16099618 0.17425475 0.15887195 0.15909405]\n",
      " ...\n",
      " [0.15942685 0.1947185  0.16185988 0.17554235 0.15945663 0.16579615]\n",
      " [0.15942685 0.1947185  0.16185988 0.17554235 0.15945663 0.16579615]\n",
      " [0.15933333 0.19477801 0.16178973 0.17536888 0.15938091 0.16646534]]\n",
      "Episode:    370\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.5130826507822615\n",
      "    Rolling avg. 20 reward:     219.5\n",
      "    Step:   266927\n",
      "    Q value:    0.15659040212631226\n",
      "    Loss:   0.00017211720114573836\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [0.16313782 0.15877505 0.1565024  0.1730798  0.17519875 0.16250412]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.15241106 0.17371492 0.14223598 0.15230556 0.15058498 0.15289038]\n",
      " [0.15227027 0.17366549 0.14222553 0.15236115 0.15052804 0.15301618]]\n",
      "Episode:    380\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.5036526891220293\n",
      "    Rolling avg. 20 reward:     173.5\n",
      "    Step:   274347\n",
      "    Q value:    0.15425615012645721\n",
      "    Loss:   0.6871408224105835\n",
      "    Look-up table:\n",
      "[[0.14107519 0.15105252 0.14319316 0.1612525  0.13540308 0.14440508]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.1452426  0.15180717 0.14138326 0.15864907 0.14277993 0.16129664]]\n",
      "Episode:    390\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.49468658439030255\n",
      "    Rolling avg. 20 reward:     140.0\n",
      "    Step:   281532\n",
      "    Q value:    0.16352784633636475\n",
      "    Loss:   0.3743543326854706\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [0.16519384 0.15355887 0.15284352 0.14990968 0.14436609 0.14422534]\n",
      " [0.16519384 0.15355887 0.15284352 0.14990968 0.14436609 0.14422534]\n",
      " ...\n",
      " [0.182274   0.16737515 0.15681271 0.16097817 0.14442305 0.16229545]\n",
      " [0.18254776 0.16715147 0.15678295 0.16067579 0.14442518 0.16241951]\n",
      " [0.18254776 0.16715147 0.15678295 0.16067579 0.14442518 0.16241951]]\n",
      "Episode:    400\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.48572949599759374\n",
      "    Rolling avg. 20 reward:     170.0\n",
      "    Step:   288841\n",
      "    Q value:    0.1461353302001953\n",
      "    Loss:   0.30444902181625366\n",
      "    Look-up table:\n",
      "[[0.14210492 0.139275   0.13671723 0.14192639 0.13352436 0.15289371]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [0.13207817 0.15223569 0.13106483 0.13217388 0.13093746 0.15802327]\n",
      " [0.13207817 0.15223569 0.13106483 0.13217388 0.13093746 0.15802327]\n",
      " [0.1320473  0.15257832 0.13104136 0.13207568 0.13090126 0.15774491]]\n",
      "Episode:    410\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.47764097662760674\n",
      "    Rolling avg. 20 reward:     160.0\n",
      "    Step:   295558\n",
      "    Q value:    0.13599440455436707\n",
      "    Loss:   0.3046734631061554\n",
      "    Look-up table:\n",
      "[[0.15254949 0.16039768 0.15974407 0.1519271  0.15287644 0.14245403]\n",
      " [0.15254949 0.16039768 0.15974407 0.1519271  0.15287644 0.14245403]\n",
      " [0.15251361 0.16034739 0.15976301 0.15188816 0.1526864  0.14244409]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    420\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.4689925261083612\n",
      "    Rolling avg. 20 reward:     124.75\n",
      "    Step:   302867\n",
      "    Q value:    0.14857634902000427\n",
      "    Loss:   0.37457558512687683\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.14114431 0.1549339  0.14564058 0.1471452  0.13834448 0.14649846]]\n",
      "Episode:    430\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.4606261732467568\n",
      "    Rolling avg. 20 reward:     142.75\n",
      "    Step:   310067\n",
      "    Q value:    0.1640039086341858\n",
      "    Loss:   0.4606833755970001\n",
      "    Look-up table:\n",
      "[[0.14700302 0.14476801 0.13952692 0.15400323 0.15865423 0.15843382]\n",
      " [0.14720337 0.14478706 0.139541   0.15397669 0.15863644 0.15831405]\n",
      " [0.14720337 0.14478706 0.139541   0.15397669 0.15863644 0.15831405]\n",
      " ...\n",
      " [0.16335112 0.15799417 0.17694172 0.16086385 0.1693683  0.15877967]\n",
      " [0.16335112 0.15799417 0.17694172 0.16086385 0.1693683  0.15877967]\n",
      " [0.16338497 0.15804307 0.17764163 0.16102242 0.16988292 0.15907353]]\n",
      "Episode:    440\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.4517580666300551\n",
      "    Rolling avg. 20 reward:     203.5\n",
      "    Step:   317843\n",
      "    Q value:    0.16396428644657135\n",
      "    Loss:   0.0001432744029443711\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [0.14510231 0.16444834 0.15903053 0.15045391 0.17107916 0.17058377]\n",
      " [0.14510231 0.16444834 0.15903053 0.15045391 0.17107916 0.17058377]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    450\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.4427882924397541\n",
      "    Rolling avg. 20 reward:     194.75\n",
      "    Step:   325865\n",
      "    Q value:    0.14488646388053894\n",
      "    Loss:   1.0619474649429321\n",
      "    Look-up table:\n",
      "[[0.14414294 0.15727086 0.17064704 0.15138997 0.15016137 0.15842003]\n",
      " [0.14403322 0.1569594  0.17056404 0.1511324  0.15003392 0.158262  ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.15202776 0.14110789 0.14098224 0.15085576 0.14684092 0.14474148]]\n",
      "Episode:    460\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.43198645335370306\n",
      "    Rolling avg. 20 reward:     203.5\n",
      "    Step:   335744\n",
      "    Q value:    0.15256357192993164\n",
      "    Loss:   0.44436460733413696\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    470\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.4234346550485313\n",
      "    Rolling avg. 20 reward:     224.25\n",
      "    Step:   343742\n",
      "    Q value:    0.1542084813117981\n",
      "    Loss:   0.5308893322944641\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [0.14478925 0.15499963 0.1337425  0.16140437 0.13439542 0.15946771]\n",
      " [0.14478925 0.15499963 0.1337425  0.16140437 0.13439542 0.15946771]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.14224882 0.14516366 0.14080358 0.1528544  0.14167362 0.16231117]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    480\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.41522339653603124\n",
      "    Rolling avg. 20 reward:     193.5\n",
      "    Step:   351575\n",
      "    Q value:    0.15980228781700134\n",
      "    Loss:   0.22643396258354187\n",
      "    Look-up table:\n",
      "[[0.13413194 0.1382768  0.14009711 0.13734533 0.14196511 0.13355747]\n",
      " [0.13409658 0.1383756  0.14029756 0.1372119  0.14242125 0.13342465]\n",
      " [0.13409658 0.1383756  0.14029756 0.1372119  0.14242125 0.13342465]\n",
      " ...\n",
      " [0.16947767 0.16238196 0.1515476  0.13813159 0.16510423 0.16178067]\n",
      " [0.16947767 0.16238196 0.1515476  0.13813159 0.16510423 0.16178067]\n",
      " [0.16947408 0.16236079 0.15163657 0.13821641 0.16507764 0.16208506]]\n",
      "Episode:    490\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.4085897760519999\n",
      "    Rolling avg. 20 reward:     164.0\n",
      "    Step:   358017\n",
      "    Q value:    0.1450500637292862\n",
      "    Loss:   0.22650443017482758\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [0.13778171 0.14552659 0.13659215 0.15053494 0.13775073 0.1450431 ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.14795606 0.14265408 0.14383388 0.14686289 0.13914621 0.14455631]\n",
      " [0.14829262 0.14319785 0.14380707 0.14707236 0.13921426 0.14452489]]\n",
      "Episode:    500\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.3990190382017767\n",
      "    Rolling avg. 20 reward:     188.75\n",
      "    Step:   367498\n",
      "    Q value:    0.13880464434623718\n",
      "    Loss:   0.2264024168252945\n",
      "    Look-up table:\n",
      "[[0.13180755 0.14539851 0.13718422 0.14499901 0.13265833 0.13180797]\n",
      " [0.13180755 0.14539851 0.13718422 0.14499901 0.13265833 0.13180797]\n",
      " [0.13194728 0.14551492 0.13728021 0.14547752 0.1328291  0.13192841]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.12983897 0.13808779 0.14111699 0.14268145 0.13000737 0.13329108]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    510\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.3902037749803602\n",
      "    Rolling avg. 20 reward:     213.25\n",
      "    Step:   376434\n",
      "    Q value:    0.159684419631958\n",
      "    Loss:   2.3131298803491518e-05\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [0.15077059 0.15044752 0.15804571 0.15047903 0.16332811 0.17733578]\n",
      " [0.15077059 0.15044752 0.15804571 0.15047903 0.16332811 0.17733578]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.14764211 0.16877013 0.15102044 0.14855549 0.16153072 0.16294795]\n",
      " [0.14764211 0.16877013 0.15102044 0.14855549 0.16153072 0.16294795]]\n",
      "Episode:    520\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.3818141895388809\n",
      "    Rolling avg. 20 reward:     211.5\n",
      "    Step:   385128\n",
      "    Q value:    0.16342484951019287\n",
      "    Loss:   0.4610011875629425\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [0.16443801 0.18199883 0.17107098 0.1647182  0.1649764  0.15351322]\n",
      " [0.16443801 0.18199883 0.17107098 0.1647182  0.1649764  0.15351322]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.15459482 0.16077136 0.16697912 0.16063006 0.15242448 0.17202038]]\n",
      "Episode:    530\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.37376566946550976\n",
      "    Rolling avg. 20 reward:     229.75\n",
      "    Step:   393650\n",
      "    Q value:    0.1570509374141693\n",
      "    Loss:   0.4610673189163208\n",
      "    Look-up table:\n",
      "[[0.14881687 0.15416841 0.14917618 0.13875596 0.13905419 0.15845008]\n",
      " [0.14880811 0.15424243 0.1492769  0.13873425 0.13903396 0.15854509]\n",
      " [0.14880811 0.15424243 0.1492769  0.13873425 0.13903396 0.15854509]\n",
      " ...\n",
      " [0.1693822  0.15654244 0.14315973 0.16807067 0.15239765 0.15122974]\n",
      " [0.16954739 0.1564762  0.14316393 0.16782308 0.15236941 0.15117551]\n",
      " [0.16954739 0.1564762  0.14316393 0.16782308 0.15236941 0.15117551]]\n",
      "Episode:    540\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.36721831197894805\n",
      "    Rolling avg. 20 reward:     192.0\n",
      "    Step:   400719\n",
      "    Q value:    0.13425704836845398\n",
      "    Loss:   0.4526105523109436\n",
      "    Look-up table:\n",
      "[[0.15696384 0.14327918 0.15487771 0.14851965 0.13928518 0.15577148]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.15747958 0.14337243 0.15486941 0.14848797 0.13935566 0.15551144]\n",
      " ...\n",
      " [0.13101022 0.12994067 0.13390155 0.13364756 0.14537878 0.12839845]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.1308964  0.12990397 0.13382778 0.13355774 0.14562801 0.12836784]]\n",
      "Episode:    550\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.3599414940473229\n",
      "    Rolling avg. 20 reward:     193.5\n",
      "    Step:   408725\n",
      "    Q value:    0.15431377291679382\n",
      "    Loss:   0.00040579907363280654\n",
      "    Look-up table:\n",
      "[[0.12899832 0.13976513 0.13162124 0.13165225 0.15197839 0.13536276]\n",
      " [0.12899832 0.13976513 0.13162124 0.13165225 0.15197839 0.13536276]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [0.16131511 0.14556241 0.1360698  0.13227934 0.16184789 0.14972767]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    560\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.35287856065445355\n",
      "    Rolling avg. 20 reward:     214.75\n",
      "    Step:   416652\n",
      "    Q value:    0.15734443068504333\n",
      "    Loss:   0.46083498001098633\n",
      "    Look-up table:\n",
      "[[0.14006132 0.13685203 0.13623951 0.13258514 0.14050739 0.13389832]\n",
      " [0.14006132 0.13685203 0.13623951 0.13258514 0.14050739 0.13389832]\n",
      " [0.14000931 0.13679329 0.13590415 0.13265458 0.14084585 0.13378623]\n",
      " ...\n",
      " [0.16019684 0.17362465 0.15111648 0.14688176 0.15744443 0.15363951]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.16002811 0.17326535 0.15112607 0.14679661 0.15757504 0.15352271]]\n",
      "Episode:    570\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.3457622677474462\n",
      "    Rolling avg. 20 reward:     233.5\n",
      "    Step:   424801\n",
      "    Q value:    0.15273810923099518\n",
      "    Loss:   0.3826323449611664\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [0.14019403 0.16973272 0.14669625 0.15227604 0.16231348 0.16187543]\n",
      " [0.14019403 0.16973272 0.14669625 0.15227604 0.16231348 0.16187543]\n",
      " ...\n",
      " [0.14693905 0.14627561 0.14408386 0.13230377 0.1573984  0.14869384]\n",
      " [0.14693905 0.14627561 0.14408386 0.13230377 0.1573984  0.14869384]\n",
      " [0.14681269 0.14621471 0.14400186 0.13232028 0.15750144 0.14871693]]\n",
      "Episode:    580\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.33845171046379324\n",
      "    Rolling avg. 20 reward:     267.5\n",
      "    Step:   433349\n",
      "    Q value:    0.13599176704883575\n",
      "    Loss:   9.202059300150722e-05\n",
      "    Look-up table:\n",
      "[[0.17027356 0.15602987 0.15304744 0.15440311 0.14766183 0.15030755]\n",
      " [0.17090629 0.15617897 0.15302116 0.15435015 0.14766498 0.15029261]\n",
      " [0.17090629 0.15617897 0.15302116 0.15435015 0.14766498 0.15029261]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.13549764 0.13627648 0.14494185 0.12622665 0.12679951 0.12968387]]\n",
      "Episode:    590\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.3302620380748856\n",
      "    Rolling avg. 20 reward:     235.5\n",
      "    Step:   443147\n",
      "    Q value:    0.1659313440322876\n",
      "    Loss:   0.00025449407985433936\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [0.15651613 0.163891   0.18170314 0.16876981 0.15811799 0.15945792]\n",
      " [0.15661225 0.16397381 0.18156444 0.16860095 0.15795535 0.1594363 ]\n",
      " ...\n",
      " [0.16785622 0.16246298 0.16948134 0.16980547 0.15756948 0.15025377]\n",
      " [0.16785622 0.16246298 0.16948134 0.16980547 0.15756948 0.15025377]\n",
      " [0.16732955 0.16259371 0.16928805 0.16971906 0.157529   0.15023714]]\n",
      "Episode:    600\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.32310225974044676\n",
      "    Rolling avg. 20 reward:     201.75\n",
      "    Step:   451914\n",
      "    Q value:    0.15527310967445374\n",
      "    Loss:   0.00011314479343127459\n",
      "    Look-up table:\n",
      "[[0.1585197  0.1482358  0.16163641 0.16260774 0.16528888 0.1550284 ]\n",
      " [0.15859795 0.14824772 0.16177133 0.16252474 0.16526577 0.15496515]\n",
      " [0.15859795 0.14824772 0.16177133 0.16252474 0.16526577 0.15496515]\n",
      " ...\n",
      " [0.16210143 0.14311619 0.15402593 0.15486795 0.15354812 0.14489709]\n",
      " [0.16176002 0.14310242 0.15409124 0.15516505 0.15343948 0.14502861]\n",
      " [0.16176002 0.14310242 0.15409124 0.15516505 0.15343948 0.14502861]]\n",
      "Episode:    610\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.3163388155499242\n",
      "    Rolling avg. 20 reward:     198.75\n",
      "    Step:   460376\n",
      "    Q value:    0.1689433753490448\n",
      "    Loss:   7.687113247811794e-05\n",
      "    Look-up table:\n",
      "[[0.1503229  0.15260659 0.15571946 0.16223945 0.14125402 0.14060579]\n",
      " [0.1503229  0.15260659 0.15571946 0.16223945 0.14125402 0.14060579]\n",
      " [0.15022826 0.15257972 0.15591215 0.16245212 0.14121485 0.14067072]\n",
      " ...\n",
      " [0.15630397 0.15662283 0.16087081 0.17156573 0.1505646  0.16525777]\n",
      " [0.15631934 0.15663412 0.16083774 0.171377   0.15060814 0.16521972]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    620\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.31077954992125745\n",
      "    Rolling avg. 20 reward:     200.75\n",
      "    Step:   467468\n",
      "    Q value:    0.1538204848766327\n",
      "    Loss:   0.7651688456535339\n",
      "    Look-up table:\n",
      "[[0.16210452 0.14834544 0.16051096 0.13777989 0.15701005 0.15469767]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [0.14871736 0.16033414 0.15089156 0.16039538 0.15483929 0.14484936]\n",
      " [0.14875741 0.16036983 0.15158893 0.16024365 0.15477264 0.14479446]\n",
      " [0.14875741 0.16036983 0.15158893 0.16024365 0.15477264 0.14479446]]\n",
      "Episode:    630\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.3055478200831789\n",
      "    Rolling avg. 20 reward:     176.0\n",
      "    Step:   474259\n",
      "    Q value:    0.1570916324853897\n",
      "    Loss:   0.00012883433373644948\n",
      "    Look-up table:\n",
      "[[0.15380432 0.15922818 0.1646421  0.1513603  0.15551417 0.13957542]\n",
      " [0.15406908 0.15910022 0.16467308 0.15137196 0.15547727 0.13960852]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [0.14345583 0.15522783 0.15413679 0.14319757 0.17298554 0.14210331]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    640\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.2992139204924134\n",
      "    Rolling avg. 20 reward:     184.0\n",
      "    Step:   482638\n",
      "    Q value:    0.1565760225057602\n",
      "    Loss:   0.00010945231770165265\n",
      "    Look-up table:\n",
      "[[0.15406831 0.15823603 0.1539169  0.16187109 0.17305297 0.17600717]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.15381567 0.15746982 0.15372996 0.16124149 0.17257981 0.17561585]\n",
      " ...\n",
      " [0.16746531 0.14670917 0.14600837 0.14403626 0.16616447 0.15730913]\n",
      " [0.16697063 0.14666924 0.14598925 0.14403574 0.16621323 0.15738663]\n",
      " [0.16697063 0.14666924 0.14598925 0.14403574 0.16621323 0.15738663]]\n",
      "Episode:    650\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.2924310001922547\n",
      "    Rolling avg. 20 reward:     231.75\n",
      "    Step:   491810\n",
      "    Q value:    0.14837448298931122\n",
      "    Loss:   0.22629891335964203\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.14985286 0.17537487 0.16543718 0.16367505 0.17026806 0.17087924]\n",
      " ...\n",
      " [0.1373262  0.14315261 0.15877439 0.15023269 0.14746223 0.1376728 ]\n",
      " [0.13723962 0.14319044 0.15854229 0.14988488 0.1473268  0.13759741]\n",
      " [0.13723962 0.14319044 0.15854229 0.14988488 0.1473268  0.13759741]]\n",
      "Episode:    660\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.28616861928472953\n",
      "    Rolling avg. 20 reward:     254.25\n",
      "    Step:   500469\n",
      "    Q value:    0.16359922289848328\n",
      "    Loss:   0.6007141470909119\n",
      "    Look-up table:\n",
      "[[0.14204612 0.16148949 0.15203828 0.16634999 0.15446593 0.15267314]\n",
      " [0.14204612 0.16148949 0.15203828 0.16634999 0.15446593 0.15267314]\n",
      " [0.14265041 0.1618107  0.15256138 0.16667624 0.15464883 0.15281141]\n",
      " ...\n",
      " [0.14291604 0.16689514 0.15509151 0.18136775 0.14313793 0.15576573]\n",
      " [0.14291604 0.16689514 0.15509151 0.18136775 0.14313793 0.15576573]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    670\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.28042566744976616\n",
      "    Rolling avg. 20 reward:     242.75\n",
      "    Step:   508578\n",
      "    Q value:    0.16304484009742737\n",
      "    Loss:   0.00024642213247716427\n",
      "    Look-up table:\n",
      "[[0.16749166 0.16885701 0.16144314 0.14539447 0.14546017 0.16475265]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.16792618 0.16856356 0.16162995 0.14539373 0.14545912 0.16485323]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.15391426 0.1653194  0.15037648 0.17490965 0.15373489 0.16729884]\n",
      " [0.15391426 0.1653194  0.15037648 0.17490965 0.15373489 0.16729884]]\n",
      "Episode:    680\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.2749388378094865\n",
      "    Rolling avg. 20 reward:     192.5\n",
      "    Step:   516482\n",
      "    Q value:    0.1590319722890854\n",
      "    Loss:   0.37472546100616455\n",
      "    Look-up table:\n",
      "[[0.12473874 0.13808507 0.13415505 0.13119359 0.12903796 0.1290336 ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.1247239  0.13835953 0.13469408 0.13118453 0.12903789 0.1290336 ]\n",
      " ...\n",
      " [0.13194031 0.16155331 0.14897151 0.13185874 0.16601834 0.169614  ]\n",
      " [0.13196404 0.16144326 0.14936805 0.13186702 0.16626216 0.16981536]\n",
      " [0.13196404 0.16144326 0.14936805 0.13186702 0.16626216 0.16981536]]\n",
      "Episode:    690\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.2681954843750867\n",
      "    Rolling avg. 20 reward:     220.75\n",
      "    Step:   526415\n",
      "    Q value:    0.14698174595832825\n",
      "    Loss:   0.07030284404754639\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [0.13410221 0.14323901 0.13134809 0.12517393 0.16690888 0.16679475]\n",
      " [0.13415888 0.14321896 0.13141674 0.12527832 0.16749348 0.16697671]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.15173063 0.16405059 0.14606309 0.12720715 0.13882862 0.15438369]\n",
      " [0.15156615 0.16389552 0.14603481 0.12712771 0.1387268  0.15418294]]\n",
      "Episode:    700\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.2627843170462456\n",
      "    Rolling avg. 20 reward:     221.75\n",
      "    Step:   534568\n",
      "    Q value:    0.12442214787006378\n",
      "    Loss:   0.0001198260288219899\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.1356926  0.12065245 0.12905473 0.12176588 0.14389652 0.11689803]\n",
      " ...\n",
      " [0.11757074 0.11453693 0.13673058 0.11441829 0.12503213 0.13069288]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.11746034 0.11476488 0.13694665 0.11439195 0.12482185 0.13102263]]\n",
      "Episode:    710\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.2575215956419686\n",
      "    Rolling avg. 20 reward:     168.5\n",
      "    Step:   542660\n",
      "    Q value:    0.12671048939228058\n",
      "    Loss:   0.7571725249290466\n",
      "    Look-up table:\n",
      "[[0.11783319 0.14512931 0.12679215 0.14437348 0.11988778 0.13005999]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.11771751 0.14548032 0.12666486 0.1442652  0.1197992  0.12998717]\n",
      " ...\n",
      " [0.11569709 0.13075562 0.11670988 0.11657318 0.11569671 0.1176347 ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.11569709 0.13099116 0.11669894 0.11655179 0.11569672 0.11762368]]\n",
      "Episode:    720\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.2521851542935402\n",
      "    Rolling avg. 20 reward:     176.0\n",
      "    Step:   551036\n",
      "    Q value:    0.1319485604763031\n",
      "    Loss:   0.21808072924613953\n",
      "    Look-up table:\n",
      "[[0.11108373 0.11005662 0.12069515 0.11086518 0.11112417 0.13498364]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.11109684 0.11006786 0.12069277 0.11087845 0.11113468 0.1346034 ]\n",
      " ...\n",
      " [0.11481096 0.11003632 0.1102808  0.11998881 0.13844401 0.14274491]\n",
      " [0.11472837 0.11004934 0.11029272 0.12017436 0.13849732 0.14240946]\n",
      " [0.11472837 0.11004934 0.11029272 0.12017436 0.13849732 0.14240946]]\n",
      "Episode:    730\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.2469951080555746\n",
      "    Rolling avg. 20 reward:     200.25\n",
      "    Step:   559354\n",
      "    Q value:    0.1244700476527214\n",
      "    Loss:   0.8268846273422241\n",
      "    Look-up table:\n",
      "[[0.11236613 0.12112097 0.13388526 0.11145654 0.12734233 0.12753342]\n",
      " [0.11235799 0.12100921 0.13384257 0.11146375 0.12729093 0.12731233]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [0.12149132 0.11353291 0.12285634 0.10256827 0.1304042  0.11349352]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    740\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.24187982328840502\n",
      "    Rolling avg. 20 reward:     228.5\n",
      "    Step:   567725\n",
      "    Q value:    0.12348847091197968\n",
      "    Loss:   0.6871427297592163\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [0.13229693 0.1290563  0.10924108 0.1181422  0.13219288 0.11010828]\n",
      " [0.13209927 0.12868772 0.10926414 0.11828121 0.13220903 0.11009465]\n",
      " ...\n",
      " [0.11366908 0.11749963 0.12737317 0.11530938 0.12308563 0.11524003]\n",
      " [0.11366908 0.11749963 0.12737317 0.11530938 0.12308563 0.11524003]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    750\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.23674437629259165\n",
      "    Rolling avg. 20 reward:     224.25\n",
      "    Step:   576309\n",
      "    Q value:    0.12639260292053223\n",
      "    Loss:   0.07008491456508636\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [0.11630417 0.12062747 0.10526612 0.12027922 0.15054239 0.12586373]\n",
      " [0.11630417 0.12062747 0.10526612 0.12027922 0.15054239 0.12586373]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.12269165 0.10913426 0.10880088 0.11675389 0.13679381 0.10888833]]\n",
      "Episode:    760\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.23202055173560976\n",
      "    Rolling avg. 20 reward:     223.0\n",
      "    Step:   584371\n",
      "    Q value:    0.1274038553237915\n",
      "    Loss:   9.614622103981674e-05\n",
      "    Look-up table:\n",
      "[[0.12435697 0.14042798 0.11964249 0.11429122 0.11408018 0.11844365]\n",
      " [0.12421706 0.13995554 0.11960734 0.11429123 0.11408209 0.11866109]\n",
      " [0.12421706 0.13995554 0.11960734 0.11429123 0.11408209 0.11866109]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.12218548 0.12986955 0.11453097 0.11422698 0.11333112 0.12472811]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    770\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.22584262769312013\n",
      "    Rolling avg. 20 reward:     238.5\n",
      "    Step:   595166\n",
      "    Q value:    0.12038939446210861\n",
      "    Loss:   0.00012458479613997042\n",
      "    Look-up table:\n",
      "[[0.12271599 0.12658367 0.14457121 0.12652642 0.14193189 0.12249061]\n",
      " [0.12271599 0.12658367 0.14457121 0.12652642 0.14193189 0.12249061]\n",
      " [0.12280411 0.1267674  0.14460063 0.12642947 0.14197554 0.12257086]\n",
      " ...\n",
      " [0.11650858 0.12082715 0.11268107 0.11367844 0.12294644 0.11701129]\n",
      " [0.11721892 0.12080925 0.1127128  0.11486912 0.12323909 0.11765276]\n",
      " [0.11721892 0.12080925 0.1127128  0.11486912 0.12323909 0.11765276]]\n",
      "Episode:    780\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.22158879628329797\n",
      "    Rolling avg. 20 reward:     214.25\n",
      "    Step:   602772\n",
      "    Q value:    0.1401868462562561\n",
      "    Loss:   6.0208665672689676e-05\n",
      "    Look-up table:\n",
      "[[0.12281468 0.13007025 0.15259562 0.14126903 0.13377672 0.13142945]\n",
      " [0.12282345 0.13003649 0.15212339 0.14108691 0.13349046 0.1313694 ]\n",
      " [0.12282345 0.13003649 0.15212339 0.14108691 0.13349046 0.1313694 ]\n",
      " ...\n",
      " [0.12595518 0.14449129 0.14421888 0.13810027 0.12336911 0.1331605 ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.12602088 0.14469798 0.14391965 0.13813958 0.12360822 0.13315615]]\n",
      "Episode:    790\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.21698557334858726\n",
      "    Rolling avg. 20 reward:     192.25\n",
      "    Step:   611169\n",
      "    Q value:    0.15900954604148865\n",
      "    Loss:   0.3048661947250366\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [0.13685894 0.18202014 0.13686089 0.14169721 0.16914557 0.13480346]\n",
      " [0.13685894 0.18202014 0.13686089 0.14169721 0.16914557 0.13480346]\n",
      " ...\n",
      " [0.16607983 0.14518625 0.13789399 0.15614513 0.1679533  0.13877746]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.16646554 0.14558776 0.13805319 0.15664551 0.16835362 0.1388595 ]]\n",
      "Episode:    800\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.2121488902969958\n",
      "    Rolling avg. 20 reward:     189.0\n",
      "    Step:   620186\n",
      "    Q value:    0.16241060197353363\n",
      "    Loss:   0.07008946686983109\n",
      "    Look-up table:\n",
      "[[0.13297187 0.12279981 0.12304575 0.12303694 0.12316711 0.1355751 ]\n",
      " [0.13297187 0.12279981 0.12304575 0.12303694 0.12316711 0.1355751 ]\n",
      " [0.13272345 0.12279954 0.12304086 0.12303593 0.12316622 0.13543512]\n",
      " ...\n",
      " [0.1542407  0.17316784 0.153878   0.15013041 0.1441225  0.15940505]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    810\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.2067227055495431\n",
      "    Rolling avg. 20 reward:     207.75\n",
      "    Step:   630550\n",
      "    Q value:    0.17376336455345154\n",
      "    Loss:   0.8350446224212646\n",
      "    Look-up table:\n",
      "[[0.12936038 0.13246576 0.14610034 0.13544096 0.15581711 0.15635984]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.12952192 0.13247935 0.14587694 0.13543971 0.15567929 0.15627471]\n",
      " ...\n",
      " [0.16171394 0.15114832 0.16418204 0.14808884 0.16798365 0.1836931 ]\n",
      " [0.16190775 0.15117665 0.16412207 0.14812079 0.16781896 0.18351296]\n",
      " [0.16190775 0.15117665 0.16412207 0.14812079 0.16781896 0.18351296]]\n",
      "Episode:    820\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.20284016102922692\n",
      "    Rolling avg. 20 reward:     243.0\n",
      "    Step:   638134\n",
      "    Q value:    0.1461067497730255\n",
      "    Loss:   0.6708667874336243\n",
      "    Look-up table:\n",
      "[[0.13731721 0.14835714 0.13071492 0.13072711 0.13974828 0.13164935]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [0.14415672 0.14997958 0.13042209 0.13103601 0.13216433 0.13091159]\n",
      " [0.14412619 0.15023091 0.13042024 0.13103208 0.13215686 0.130907  ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    830\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.2\n",
      "    Rolling avg. 20 reward:     199.75\n",
      "    Step:   645145\n",
      "    Q value:    0.14255434274673462\n",
      "    Loss:   7.367783837253228e-05\n",
      "    Look-up table:\n",
      "[[0.1473659  0.14406455 0.13100392 0.13132593 0.13315356 0.13147172]\n",
      " [0.14713444 0.14396085 0.13098434 0.13130541 0.13314039 0.13145286]\n",
      " [0.14713444 0.14396085 0.13098434 0.13130541 0.13314039 0.13145286]\n",
      " ...\n",
      " [0.14415354 0.138878   0.13104433 0.13100262 0.14538012 0.13104774]\n",
      " [0.14415354 0.138878   0.13104433 0.13100262 0.14538012 0.13104774]\n",
      " [0.14422026 0.13875531 0.13104501 0.13100301 0.14514302 0.13104808]]\n",
      "Episode:    840\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.2\n",
      "    Rolling avg. 20 reward:     176.25\n",
      "    Step:   654326\n",
      "    Q value:    0.13372543454170227\n",
      "    Loss:   0.4607572555541992\n",
      "    Look-up table:\n",
      "[[0.13479556 0.13653038 0.13437644 0.13802072 0.13445824 0.13615409]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.13465884 0.13631876 0.1335921  0.13794477 0.13436116 0.13605535]\n",
      " ...\n",
      " [0.1265745  0.12640509 0.1411936  0.12969917 0.12639864 0.12691256]\n",
      " [0.12657185 0.12640487 0.14111055 0.12962508 0.12639856 0.12690726]\n",
      " [0.12657185 0.12640487 0.14111055 0.12962508 0.12639856 0.12690726]]\n",
      "Episode:    850\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.2\n",
      "    Rolling avg. 20 reward:     210.0\n",
      "    Step:   664033\n",
      "    Q value:    0.12955144047737122\n",
      "    Loss:   0.0001421791093889624\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [0.11785046 0.13494025 0.12533933 0.12298399 0.1211222  0.11749233]\n",
      " [0.11785046 0.13494025 0.12533933 0.12298399 0.1211222  0.11749233]\n",
      " ...\n",
      " [0.11796124 0.12196989 0.1325098  0.11736628 0.12040517 0.14721647]\n",
      " [0.11796124 0.12196989 0.1325098  0.11736628 0.12040517 0.14721647]\n",
      " [0.11795489 0.12167903 0.13243312 0.11736675 0.12058491 0.14738721]]\n",
      "Episode:    860\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.2\n",
      "    Rolling avg. 20 reward:     222.75\n",
      "    Step:   672289\n",
      "    Q value:    0.13915979862213135\n",
      "    Loss:   0.000211825841688551\n",
      "    Look-up table:\n",
      "[[0.14316998 0.14760888 0.14377746 0.12109993 0.12383176 0.12276408]\n",
      " [0.14348079 0.14796062 0.1439689  0.12118205 0.12386782 0.12284988]\n",
      " [0.14348079 0.14796062 0.1439689  0.12118205 0.12386782 0.12284988]\n",
      " ...\n",
      " [0.14769851 0.13800074 0.13319415 0.1254375  0.14205493 0.12465641]\n",
      " [0.14769851 0.13800074 0.13319415 0.1254375  0.14205493 0.12465641]\n",
      " [0.14711644 0.1379694  0.13316642 0.12540954 0.14207487 0.1246039 ]]\n",
      "Episode:    870\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.2\n",
      "    Rolling avg. 20 reward:     274.75\n",
      "    Step:   681932\n",
      "    Q value:    0.1362345814704895\n",
      "    Loss:   0.9911710023880005\n",
      "    Look-up table:\n",
      "[[0.13592383 0.12690957 0.15062967 0.13124177 0.16054432 0.13016474]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.13597481 0.12691371 0.15072288 0.13122679 0.16052437 0.13045658]\n",
      " ...\n",
      " [0.12250914 0.12234586 0.12263888 0.12266219 0.14156249 0.14380036]\n",
      " [0.12223502 0.12228603 0.12258837 0.12257363 0.14126122 0.14317393]\n",
      " [0.12223502 0.12228603 0.12258837 0.12257363 0.14126122 0.14317393]]\n",
      "Episode:    880\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.2\n",
      "    Rolling avg. 20 reward:     275.75\n",
      "    Step:   690541\n",
      "    Q value:    0.1531321108341217\n",
      "    Loss:   2.8040722099831328e-05\n",
      "    Look-up table:\n",
      "[[0.12814605 0.15317325 0.13239732 0.12731269 0.15969209 0.13143684]\n",
      " [0.12814605 0.15317325 0.13239732 0.12731269 0.15969209 0.13143684]\n",
      " [0.12814192 0.1529458  0.1323546  0.12732309 0.15990461 0.13140659]\n",
      " ...\n",
      " [0.16263604 0.15262422 0.16309556 0.15199868 0.13800463 0.14287736]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.1632093  0.15297139 0.16342917 0.15234129 0.1380849  0.14290147]]\n",
      "Episode:    890\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.2\n",
      "    Rolling avg. 20 reward:     206.5\n",
      "    Step:   698335\n",
      "    Q value:    0.14543399214744568\n",
      "    Loss:   0.000281760556390509\n",
      "    Look-up table:\n",
      "[[0.13300382 0.13228756 0.11330573 0.11061392 0.11214244 0.11016092]\n",
      " [0.13310984 0.13214326 0.11331484 0.11064728 0.1121854  0.110176  ]\n",
      " [0.13310984 0.13214326 0.11331484 0.11064728 0.1121854  0.110176  ]\n",
      " ...\n",
      " [0.14617926 0.1519675  0.12793908 0.13703693 0.12811901 0.11744286]\n",
      " [0.14617926 0.1519675  0.12793908 0.13703693 0.12811901 0.11744286]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    900\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.2\n",
      "    Rolling avg. 20 reward:     213.75\n",
      "    Step:   709012\n",
      "    Q value:    0.15968124568462372\n",
      "    Loss:   9.878315177047625e-05\n",
      "    Look-up table:\n",
      "[[0.15526144 0.15494464 0.13823348 0.14102909 0.1537071  0.14399518]\n",
      " [0.15526144 0.15494464 0.13823348 0.14102909 0.1537071  0.14399518]\n",
      " [0.15529938 0.15510455 0.13827917 0.1410971  0.15383141 0.14427722]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.14616227 0.14323655 0.16875507 0.15383197 0.1621605  0.15192132]\n",
      " [0.14616227 0.14323655 0.16875507 0.15383197 0.1621605  0.15192132]]\n",
      "Episode:    910\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.2\n",
      "    Rolling avg. 20 reward:     230.75\n",
      "    Step:   717682\n",
      "    Q value:    0.15916267037391663\n",
      "    Loss:   3.4913182258605957\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [0.13312499 0.13513234 0.14141159 0.14141826 0.13478966 0.14520919]\n",
      " [0.13310184 0.13510637 0.14156276 0.14168069 0.13477223 0.14523506]\n",
      " ...\n",
      " [0.13171534 0.16801821 0.17170972 0.13400264 0.13170478 0.13699618]\n",
      " [0.1317163  0.16766836 0.17176324 0.13398606 0.13170207 0.136897  ]\n",
      " [0.1317163  0.16766836 0.17176324 0.13398606 0.13170207 0.136897  ]]\n",
      "Episode:    920\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.2\n",
      "    Rolling avg. 20 reward:     229.0\n",
      "    Step:   727602\n",
      "    Q value:    0.14788329601287842\n",
      "    Loss:   0.46102750301361084\n",
      "    Look-up table:\n",
      "[[0.13918552 0.14047232 0.16101913 0.14383079 0.15361114 0.13712397]\n",
      " [0.13918552 0.14047232 0.16101913 0.14383079 0.15361114 0.13712397]\n",
      " [0.13909465 0.14041609 0.16127288 0.14394215 0.15367615 0.13708609]\n",
      " ...\n",
      " [0.1468502  0.15711458 0.1412605  0.17085145 0.1646537  0.14315274]\n",
      " [0.14708169 0.15701653 0.14114268 0.17078617 0.16462922 0.14305924]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    930\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.2\n",
      "    Rolling avg. 20 reward:     238.0\n",
      "    Step:   736182\n",
      "    Q value:    0.13753819465637207\n",
      "    Loss:   6.875277904327959e-05\n",
      "    Look-up table:\n",
      "[[0.13760571 0.13596354 0.13388568 0.14044386 0.14746836 0.14132938]\n",
      " [0.13778239 0.13564993 0.13384458 0.14012957 0.14734949 0.14125626]\n",
      " [0.13778239 0.13564993 0.13384458 0.14012957 0.14734949 0.14125626]\n",
      " ...\n",
      " [0.12454345 0.12082825 0.1254233  0.14015894 0.13690487 0.13963258]\n",
      " [0.12453248 0.12082394 0.12541167 0.14014229 0.13693754 0.13951622]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    940\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.2\n",
      "    Rolling avg. 20 reward:     239.75\n",
      "    Step:   745292\n",
      "    Q value:    0.1488543450832367\n",
      "    Loss:   0.3744201064109802\n",
      "    Look-up table:\n",
      "[[0.14973576 0.12740904 0.1321279  0.14205982 0.15504144 0.12724283]\n",
      " [0.14967202 0.1274243  0.1320544  0.14225675 0.15473127 0.12725592]\n",
      " [0.14967202 0.1274243  0.1320544  0.14225675 0.15473127 0.12725592]\n",
      " ...\n",
      " [0.14442785 0.12944472 0.12955433 0.15435733 0.15145785 0.12935773]\n",
      " [0.14458467 0.12941119 0.12953588 0.15484382 0.15154915 0.12933528]\n",
      " [0.14458467 0.12941119 0.12953588 0.15484382 0.15154915 0.12933528]]\n",
      "Episode:    950\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.2\n",
      "    Rolling avg. 20 reward:     214.0\n",
      "    Step:   754138\n",
      "    Q value:    0.13760893046855927\n",
      "    Loss:   0.00019970184075646102\n",
      "    Look-up table:\n",
      "[[0.14054716 0.13378423 0.14811699 0.14394382 0.14576496 0.13211718]\n",
      " [0.14076325 0.13376537 0.14783892 0.14377387 0.14596036 0.13209634]\n",
      " [0.14076325 0.13376537 0.14783892 0.14377387 0.14596036 0.13209634]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.13996221 0.12276388 0.12391313 0.12014493 0.13555354 0.13342418]\n",
      " [0.13996221 0.12276388 0.12391313 0.12014493 0.13555354 0.13342418]]\n",
      "Episode:    960\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.2\n",
      "    Rolling avg. 20 reward:     171.5\n",
      "    Step:   762334\n",
      "    Q value:    0.13454461097717285\n",
      "    Loss:   0.2264477163553238\n",
      "    Look-up table:\n",
      "[[0.13577673 0.13600339 0.12977083 0.12456246 0.11408725 0.1136276 ]\n",
      " [0.13632432 0.13578936 0.12969121 0.12452661 0.11407863 0.11359944]\n",
      " [0.13632432 0.13578936 0.12969121 0.12452661 0.11407863 0.11359944]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.14032289 0.11318254 0.12789184 0.11589422 0.13730288 0.11385614]\n",
      " [0.14032289 0.11318254 0.12789184 0.11589422 0.13730288 0.11385614]]\n",
      "Episode:    970\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.2\n",
      "    Rolling avg. 20 reward:     184.5\n",
      "    Step:   771787\n",
      "    Q value:    0.12788870930671692\n",
      "    Loss:   2.8389245926518925e-05\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [0.12987012 0.13497238 0.11568199 0.12754013 0.12685052 0.13769433]\n",
      " [0.12987012 0.13497238 0.11568199 0.12754013 0.12685052 0.13769433]\n",
      " ...\n",
      " [0.12288309 0.12449457 0.12126257 0.12514447 0.12307036 0.13529399]\n",
      " [0.12288309 0.12449457 0.12126257 0.12514447 0.12307036 0.13529399]\n",
      " [0.12287878 0.12439094 0.1212694  0.12508076 0.12306739 0.13518877]]\n",
      "Episode:    980\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.2\n",
      "    Rolling avg. 20 reward:     201.25\n",
      "    Step:   781423\n",
      "    Q value:    0.12566420435905457\n",
      "    Loss:   0.00023933433112688363\n",
      "    Look-up table:\n",
      "[[0.12923913 0.12880701 0.12208628 0.12759601 0.13065292 0.12792817]\n",
      " [0.12904726 0.12858167 0.12186407 0.12749617 0.13053103 0.12731783]\n",
      " [0.12904726 0.12858167 0.12186407 0.12749617 0.13053103 0.12731783]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.12283541 0.13568878 0.11935803 0.11684079 0.12146216 0.10770937]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    990\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.2\n",
      "    Rolling avg. 20 reward:     202.25\n",
      "    Step:   789635\n",
      "    Q value:    0.13072431087493896\n",
      "    Loss:   0.37523335218429565\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [0.13447076 0.10906439 0.11316182 0.13342707 0.12334969 0.11645018]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [0.12742448 0.11339493 0.13361213 0.13310435 0.12792288 0.1127704 ]\n",
      " [0.12742448 0.11339493 0.13361213 0.13310435 0.12792288 0.1127704 ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    1000\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.2\n",
      "    Rolling avg. 20 reward:     209.0\n",
      "    Step:   798273\n",
      "    Q value:    0.12968698143959045\n",
      "    Loss:   0.0001743548345984891\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [0.11171053 0.12524264 0.11023425 0.12205678 0.11736498 0.1080081 ]\n",
      " [0.11171053 0.12524264 0.11023425 0.12205678 0.11736498 0.1080081 ]\n",
      " ...\n",
      " [0.11104281 0.12550464 0.13114107 0.13080241 0.13983905 0.13685948]\n",
      " [0.11104281 0.12550464 0.13114107 0.13080241 0.13983905 0.13685948]\n",
      " [0.11105752 0.12539814 0.13146031 0.13068481 0.13999104 0.13692623]]\n",
      "Training finished at 1000 episodes!\n",
      "    Final epsilon:  0.2\n",
      "    Final Rolling avg. 20 reward:   209.0\n",
      "    Final look-up table\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [0.11171053 0.12524264 0.11023425 0.12205678 0.11736498 0.1080081 ]\n",
      " [0.11171053 0.12524264 0.11023425 0.12205678 0.11736498 0.1080081 ]\n",
      " ...\n",
      " [0.11104281 0.12550464 0.13114107 0.13080241 0.13983905 0.13685948]\n",
      " [0.11104281 0.12550464 0.13114107 0.13080241 0.13983905 0.13685948]\n",
      " [0.11105752 0.12539814 0.13146031 0.13068481 0.13999104 0.13692623]]\n",
      "\u001B[32m[I 2022-06-07 03:36:39,832]\u001B[0m Trial 0 finished with value: 209.0 and parameters: {'exploration_rate_decay': 0.9999975, 'exploration_rate_min': 0.2, 'batch_size': 64, 'gamma': 0.93, 'lr': 0.0008, 'learn_every': 2, 'sync_every': 10000}. Best is trial 0 with value: 209.0.\u001B[0m\n",
      "Current Params:\n",
      "    exploration_rate_decay: 0.999975\n",
      "    exploration_rate_min: 0.05\n",
      "    batch_size: 16\n",
      "    gamma: 0.93\n",
      "    lr: 0.00030000000000000003\n",
      "    learn_every: 5\n",
      "    sync_every: 15000\n",
      "\n",
      "Episode:    10\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8627961344477312\n",
      "    Rolling avg. 20 reward:     145.0\n",
      "    Step:   5903\n",
      "    Q value:    None\n",
      "    Loss:   0\n",
      "    Look-up table:\n",
      "[[-0.01283416 -0.02025608  0.00561806 -0.00785228  0.01467862 -0.02434137]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    20\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.7214775040344699\n",
      "    Rolling avg. 20 reward:     158.75\n",
      "    Step:   13058\n",
      "    Q value:    0.03276379406452179\n",
      "    Loss:   0.0004766496131196618\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.01979962 0.01844935 0.02026713 0.01307221 0.03885417 0.01604427]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    30\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.5934920134786128\n",
      "    Rolling avg. 20 reward:     189.0\n",
      "    Step:   20869\n",
      "    Q value:    0.0175260491669178\n",
      "    Loss:   0.00011446740973042324\n",
      "    Look-up table:\n",
      "[[ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.44124497e-05  1.08057950e-02  1.26493359e-02  1.07435621e-02\n",
      "   4.55078855e-03 -1.69158739e-04]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " ...\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]]\n",
      "Episode:    40\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.47665645770347603\n",
      "    Rolling avg. 20 reward:     224.75\n",
      "    Step:   29638\n",
      "    Q value:    0.017142673954367638\n",
      "    Loss:   0.0006719262455590069\n",
      "    Look-up table:\n",
      "[[ 1.24268234e-04  2.18568444e-02 -2.42426805e-03 -2.00410597e-02\n",
      "   3.44752707e-03 -1.85546782e-02]\n",
      " [ 6.05583191e-05  2.19562948e-02 -2.44548544e-03 -2.03975178e-02\n",
      "   3.26535292e-03 -1.86779797e-02]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " ...\n",
      " [ 8.77177529e-03  2.06992496e-02  2.21867710e-02  1.31902602e-02\n",
      "   1.07409768e-02  1.34753026e-02]\n",
      " [ 8.96661635e-03  2.07038894e-02  2.23349594e-02  1.31481579e-02\n",
      "   1.07649714e-02  1.35786654e-02]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]]\n",
      "Episode:    50\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.40205700796192617\n",
      "    Rolling avg. 20 reward:     189.75\n",
      "    Step:   36446\n",
      "    Q value:    0.016557566821575165\n",
      "    Loss:   0.0017731881234794855\n",
      "    Look-up table:\n",
      "[[ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.02309866  0.0256992  -0.00266904  0.01542385  0.01001598  0.01444775]\n",
      " [ 0.023011    0.02570007 -0.00278465  0.01528779  0.01007513  0.01434075]\n",
      " ...\n",
      " [ 0.03312193  0.03404227  0.03430609  0.0412659   0.02804803  0.02602714]\n",
      " [ 0.03323732  0.03394698  0.03456348  0.04121408  0.02796989  0.02607724]\n",
      " [ 0.03359988  0.03386734  0.03483226  0.03910126  0.02789435  0.02609392]]\n",
      "Episode:    60\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.3311069591151577\n",
      "    Rolling avg. 20 reward:     137.5\n",
      "    Step:   44212\n",
      "    Q value:    0.04072193428874016\n",
      "    Loss:   0.001403806614689529\n",
      "    Look-up table:\n",
      "[[ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 0.01281429 -0.02229808 -0.00223292  0.0202663   0.07434725  0.00589817]\n",
      " [ 0.0119247  -0.02451556 -0.0035698   0.0151531   0.07562847  0.0047744 ]\n",
      " [ 0.01389729 -0.02134146  0.00146203  0.0130105   0.07798772  0.01034934]]\n",
      "Episode:    70\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.2674115324517195\n",
      "    Rolling avg. 20 reward:     168.25\n",
      "    Step:   52758\n",
      "    Q value:    0.04339171200990677\n",
      "    Loss:   0.0002839697408489883\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [0.02438809 0.01324217 0.02686559 0.03184501 0.01076625 0.01182064]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [0.03229922 0.02092088 0.02110751 0.02355975 0.05319057 0.02743012]\n",
      " [0.03223699 0.02090425 0.02095527 0.02339393 0.0531628  0.02760951]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    80\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.22152521902886776\n",
      "    Rolling avg. 20 reward:     190.0\n",
      "    Step:   60288\n",
      "    Q value:    0.06546377390623093\n",
      "    Loss:   0.0003332228516228497\n",
      "    Look-up table:\n",
      "[[ 1.04345120e-02 -1.57996453e-03 -4.91477549e-04 -6.28709793e-03\n",
      "  -8.12599063e-03 -4.52099927e-03]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " ...\n",
      " [ 1.55108869e-01  1.02173954e-01  1.12606302e-01  9.23786461e-02\n",
      "   1.03239991e-01  1.04602829e-01]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.53946474e-01  1.01299845e-01  1.10846087e-01  9.21190232e-02\n",
      "   1.03735536e-01  1.04416221e-01]]\n",
      "Episode:    90\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.17654196346012435\n",
      "    Rolling avg. 20 reward:     197.25\n",
      "    Step:   69367\n",
      "    Q value:    0.031779393553733826\n",
      "    Loss:   0.0009745779680088162\n",
      "    Look-up table:\n",
      "[[-1.65919326e-02 -3.40255834e-02 -1.67681500e-02  4.88888472e-04\n",
      "  -1.47839412e-02 -2.19634287e-02]\n",
      " [-1.64770298e-02 -3.42090614e-02 -1.67525783e-02  5.23384660e-04\n",
      "  -1.49435177e-02 -2.20413692e-02]\n",
      " [-1.63109452e-02 -3.39921154e-02 -1.67913809e-02  7.57683069e-04\n",
      "  -1.48218051e-02 -2.19030268e-02]\n",
      " ...\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.44271776e-02 -3.21805850e-02  1.21046044e-02  2.32193619e-04\n",
      "   9.01861861e-03  1.89040788e-03]\n",
      " [ 1.56613961e-02 -3.07762921e-02  1.36311091e-02 -1.36263669e-04\n",
      "   9.41716507e-03  1.74265355e-03]]\n",
      "Episode:    100\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.14648254407195793\n",
      "    Rolling avg. 20 reward:     209.25\n",
      "    Step:   76833\n",
      "    Q value:    0.10385514795780182\n",
      "    Loss:   0.004774188622832298\n",
      "    Look-up table:\n",
      "[[-0.00148976  0.03444071  0.02451568  0.02212681  0.00371787  0.00987962]\n",
      " [-0.00174332  0.03255019  0.02375338  0.02178438  0.0030141   0.00842155]\n",
      " [-0.00224534  0.03293071  0.02353368  0.02174008  0.00252082  0.00810121]\n",
      " ...\n",
      " [ 0.05980258  0.00350173  0.24799421  0.14451185  0.02797251  0.05703849]\n",
      " [ 0.05973374  0.00390986  0.24793181  0.14473873  0.02817715  0.05713162]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    110\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.1233164870746574\n",
      "    Rolling avg. 20 reward:     200.25\n",
      "    Step:   83719\n",
      "    Q value:    0.09365524351596832\n",
      "    Loss:   0.003532558912411332\n",
      "    Look-up table:\n",
      "[[ 0.00647892  0.00663045  0.02698158  0.01956054  0.01189208  0.00921996]\n",
      " [ 0.00609207  0.00665099  0.02677431  0.01927162  0.01140505  0.00809775]\n",
      " [ 0.00596431  0.00627211  0.02635346  0.01929875  0.01150964  0.00775841]\n",
      " ...\n",
      " [-0.01861562  0.0072666  -0.01993195  0.01458741 -0.01392379  0.00346434]\n",
      " [-0.01845924  0.00730158 -0.01987846  0.01459926 -0.01385678  0.00322961]\n",
      " [-0.01965543  0.00466461 -0.02089421  0.01481973 -0.01545506  0.0043799 ]]\n",
      "Episode:    120\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.1023426795649705\n",
      "    Rolling avg. 20 reward:     197.25\n",
      "    Step:   91176\n",
      "    Q value:    0.07049430161714554\n",
      "    Loss:   0.0005135014653205872\n",
      "    Look-up table:\n",
      "[[ 1.23748891e-02  5.41454926e-03  9.02691111e-03 -8.51017237e-03\n",
      "  -2.73458958e-02  8.73681158e-04]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.23991743e-02  6.48861006e-03  9.07696784e-03 -8.44380260e-03\n",
      "  -2.86342949e-02 -2.00809911e-03]\n",
      " ...\n",
      " [ 3.65205929e-02  6.06946424e-02  8.30454528e-02  8.21795762e-02\n",
      "   7.00436160e-02  4.87124547e-02]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 3.64880748e-02  5.89661151e-02  8.38200301e-02  7.97127634e-02\n",
      "   7.05970600e-02  4.71598022e-02]]\n",
      "Episode:    130\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.08340424673455042\n",
      "    Rolling avg. 20 reward:     210.0\n",
      "    Step:   99361\n",
      "    Q value:    0.08200027048587799\n",
      "    Loss:   0.5871919393539429\n",
      "    Look-up table:\n",
      "[[-7.53071159e-04 -4.88056242e-02 -5.87714463e-03 -3.84322181e-03\n",
      "  -1.56373903e-02 -1.91128403e-02]\n",
      " [-7.05871731e-04 -4.65061218e-02 -5.90299070e-03 -4.68921661e-03\n",
      "  -1.38856471e-02 -2.24567950e-02]\n",
      " [-1.22141466e-03 -4.46575284e-02 -6.19520247e-03 -5.27833775e-03\n",
      "  -1.17962882e-02 -2.34112665e-02]\n",
      " ...\n",
      " [ 9.78161693e-02  1.50720268e-01  1.12135306e-01  1.04208484e-01\n",
      "   1.34549797e-01  1.39176384e-01]\n",
      " [ 9.77786481e-02  1.50236264e-01  1.12120979e-01  1.04082599e-01\n",
      "   1.34504616e-01  1.38472959e-01]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]]\n",
      "Episode:    140\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.07000537599629816\n",
      "    Rolling avg. 20 reward:     181.5\n",
      "    Step:   106366\n",
      "    Q value:    0.051434226334095\n",
      "    Loss:   0.0002779294445645064\n",
      "    Look-up table:\n",
      "[[ 0.03330371 -0.02906252 -0.02218349  0.01305694 -0.00276263  0.02237857]\n",
      " [ 0.03305042 -0.02941353 -0.02325475  0.01173583 -0.0031507   0.02154734]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 0.08109938  0.06587061  0.05113666  0.08392312  0.08775018  0.05098088]\n",
      " [ 0.07935854  0.06541195  0.05098888  0.08317077  0.08732251  0.05085023]\n",
      " [ 0.07939432  0.06319843  0.04809538  0.08094399  0.08524001  0.05094983]]\n",
      "Episode:    150\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.056470555085466445\n",
      "    Rolling avg. 20 reward:     168.5\n",
      "    Step:   114960\n",
      "    Q value:    0.04044192284345627\n",
      "    Loss:   0.8969775438308716\n",
      "    Look-up table:\n",
      "[[-0.00467014 -0.12124284 -0.05482088 -0.01989757 -0.01792663  0.02703476]\n",
      " [-0.00801302 -0.12219673 -0.05718556 -0.02198915 -0.02235194  0.02257458]\n",
      " [-0.00885667 -0.12228975 -0.05741487 -0.02266175 -0.02253557  0.02143266]\n",
      " ...\n",
      " [ 0.07295456  0.0589669   0.01468896  0.0602744   0.03392683  0.06685761]\n",
      " [ 0.07308728  0.05883079  0.01522804  0.06065889  0.03433952  0.06762119]\n",
      " [ 0.07151619  0.05785252  0.01470368  0.0596955   0.03318983  0.06663278]]\n",
      "Episode:    160\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     183.5\n",
      "    Step:   122059\n",
      "    Q value:    0.10408401489257812\n",
      "    Loss:   1.8440004587173462\n",
      "    Look-up table:\n",
      "[[ 0.00628362 -0.00305315 -0.00607166  0.02140138  0.02303864  0.0246467 ]\n",
      " [ 0.00586022 -0.00303286 -0.00700542  0.02019237  0.02169077  0.0238247 ]\n",
      " [ 0.00541014 -0.0028202  -0.00790434  0.01928861  0.02013477  0.0232696 ]\n",
      " ...\n",
      " [ 0.18744043  0.14420167  0.08432056  0.15785146  0.16653138  0.19499017]\n",
      " [ 0.18795492  0.14556476  0.08321346  0.15889996  0.16678491  0.19283146]\n",
      " [ 0.1807065   0.13340381  0.08225378  0.15425798  0.15217005  0.18519999]]\n",
      "Episode:    170\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     209.0\n",
      "    Step:   131416\n",
      "    Q value:    0.062230758368968964\n",
      "    Loss:   0.5821138024330139\n",
      "    Look-up table:\n",
      "[[ 0.0393663   0.02974517 -0.01471744  0.02086011 -0.00313362  0.01389331]\n",
      " [ 0.03851699  0.02916902 -0.01529188  0.02067599 -0.00401635  0.01321283]\n",
      " [ 0.03932135  0.02879829 -0.01557452  0.01979313 -0.00441327  0.01277359]\n",
      " ...\n",
      " [ 0.05794086  0.06149017 -0.05634582  0.01875694 -0.00990408  0.05144871]\n",
      " [ 0.05851259  0.06164733 -0.05641447  0.01839665 -0.00975405  0.051406  ]\n",
      " [ 0.05331881  0.05580048 -0.06101485  0.01902946 -0.01495348  0.04967853]]\n",
      "Episode:    180\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     201.25\n",
      "    Step:   140116\n",
      "    Q value:    0.09969306737184525\n",
      "    Loss:   0.00040902619366534054\n",
      "    Look-up table:\n",
      "[[-0.04725017 -0.01643108 -0.04578146  0.0104461   0.00563712 -0.0255137 ]\n",
      " [-0.04846147 -0.01717364 -0.04712163  0.01172286  0.00440507 -0.02737466]\n",
      " [-0.04948131 -0.01670539 -0.04747063  0.00979271  0.00346046 -0.027525  ]\n",
      " ...\n",
      " [ 0.06261638  0.07334649  0.06891818  0.05557571  0.07292889  0.0777477 ]\n",
      " [ 0.06266288  0.07321079  0.06899848  0.05555391  0.07300478  0.07757708]\n",
      " [ 0.06294688  0.07287965  0.07020558  0.05642605  0.0734804   0.07715359]]\n",
      "Episode:    190\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     193.75\n",
      "    Step:   150166\n",
      "    Q value:    0.14292028546333313\n",
      "    Loss:   0.001160785323008895\n",
      "    Look-up table:\n",
      "[[ 0.0056874  -0.01246974  0.02058374  0.00741211  0.03851816  0.02095554]\n",
      " [ 0.00243455 -0.01590978  0.01734629  0.00783265  0.03559417  0.01764604]\n",
      " [ 0.00152256 -0.01703873  0.01497974  0.00734434  0.033741    0.01677994]\n",
      " ...\n",
      " [ 0.08280404  0.05490275  0.07628395  0.07707521  0.09585467  0.09124434]\n",
      " [ 0.0823939   0.054841    0.07560771  0.07645221  0.09534988  0.09009822]\n",
      " [ 0.07947186  0.04786328  0.0721614   0.07391448  0.0912167   0.08628277]]\n",
      "Episode:    200\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     181.25\n",
      "    Step:   158310\n",
      "    Q value:    0.14964653551578522\n",
      "    Loss:   0.000537457293830812\n",
      "    Look-up table:\n",
      "[[-0.0138661  -0.0108262   0.02739976 -0.02369218  0.02690012 -0.00489552]\n",
      " [-0.01614916 -0.01197382  0.0254047  -0.02560217  0.02424468 -0.00762   ]\n",
      " [-0.01747492 -0.01335121  0.025251   -0.02665187  0.02458858 -0.00734127]\n",
      " ...\n",
      " [ 0.19672441  0.16716799  0.22450379  0.11841477  0.13622716  0.1552005 ]\n",
      " [ 0.19646284  0.16632514  0.22471538  0.12025987  0.13678047  0.15534571]\n",
      " [ 0.1927141   0.16408314  0.22357321  0.11483371  0.13410439  0.15184261]]\n",
      "Episode:    210\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     150.5\n",
      "    Step:   166297\n",
      "    Q value:    0.11981900036334991\n",
      "    Loss:   0.0006986426888033748\n",
      "    Look-up table:\n",
      "[[ 0.06055964  0.02792846  0.08358511  0.04569812  0.04147561  0.11494144]\n",
      " [ 0.05199442  0.01963979  0.07596764  0.03802437  0.03290793  0.10623096]\n",
      " [ 0.04751456  0.01611637  0.07337931  0.03386167  0.02888644  0.10132452]\n",
      " ...\n",
      " [ 0.00265092  0.02754775  0.00066314 -0.00777911  0.01882694  0.01903399]\n",
      " [ 0.00274607  0.02789681  0.00045088 -0.00689813  0.01872806  0.01953028]\n",
      " [ 0.00107562  0.02614539 -0.00040329 -0.00451349  0.0139194   0.01525845]]\n",
      "Episode:    220\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     186.5\n",
      "    Step:   175543\n",
      "    Q value:    0.159629687666893\n",
      "    Loss:   0.0012751873582601547\n",
      "    Look-up table:\n",
      "[[ 0.01375126  0.01343066 -0.06947192 -0.01221897  0.0079049  -0.04943788]\n",
      " [ 0.01104677  0.01371443 -0.06794833 -0.01390659  0.00660904 -0.0496043 ]\n",
      " [ 0.01056689  0.01412563 -0.06721396 -0.01413736  0.00686177 -0.04951361]\n",
      " ...\n",
      " [ 0.20695382  0.15654093  0.20053191  0.10647275  0.21049328  0.19103216]\n",
      " [ 0.20622672  0.15619378  0.20000982  0.10630856  0.21017128  0.19069305]\n",
      " [ 0.2058569   0.16029748  0.2038767   0.10958014  0.21475801  0.19400181]]\n",
      "Episode:    230\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     182.0\n",
      "    Step:   183841\n",
      "    Q value:    0.12516778707504272\n",
      "    Loss:   0.0009285772684961557\n",
      "    Look-up table:\n",
      "[[-0.03324349 -0.042712   -0.04867618 -0.0246736  -0.02608658 -0.06516895]\n",
      " [-0.03728898 -0.04492848 -0.04878315 -0.02327045 -0.02764517 -0.07099953]\n",
      " [-0.03861243 -0.04539223 -0.04826386 -0.02373078 -0.02841669 -0.072052  ]\n",
      " ...\n",
      " [ 0.07930258  0.14327717  0.06853888  0.08496362  0.12034267  0.08642706]\n",
      " [ 0.07892098  0.14289063  0.0681217   0.08459893  0.1198937   0.08599658]\n",
      " [ 0.07957993  0.14432657  0.06757204  0.08800825  0.1204795   0.08688855]]\n",
      "Episode:    240\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     175.5\n",
      "    Step:   191623\n",
      "    Q value:    0.08122265338897705\n",
      "    Loss:   0.000779992900788784\n",
      "    Look-up table:\n",
      "[[-0.0254401   0.00353403 -0.00070636 -0.02435202 -0.02649396 -0.01104574]\n",
      " [-0.03166838  0.00050318 -0.00284629 -0.02846057 -0.0325947  -0.01744202]\n",
      " [-0.03196834  0.00061031 -0.0026816  -0.02862792 -0.03310505 -0.01830974]\n",
      " ...\n",
      " [-0.01767872 -0.05809518  0.00057895 -0.05851827 -0.02870353 -0.0201109 ]\n",
      " [-0.01835043 -0.05804396  0.00022151 -0.05950261 -0.02947057 -0.02159368]\n",
      " [-0.01518698 -0.05911956  0.00046014 -0.05735848 -0.0272835  -0.01902465]]\n",
      "Episode:    250\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     207.0\n",
      "    Step:   200542\n",
      "    Q value:    0.20372989773750305\n",
      "    Loss:   0.008820117451250553\n",
      "    Look-up table:\n",
      "[[-0.04623519 -0.07227267 -0.06129439 -0.09914049 -0.09080842 -0.08073023]\n",
      " [-0.05030988 -0.07605937 -0.06414749 -0.10323586 -0.09594274 -0.08896963]\n",
      " [-0.05189216 -0.07724367 -0.06428653 -0.10347671 -0.09751964 -0.08904082]\n",
      " ...\n",
      " [ 0.14949858  0.11982965  0.1614348   0.11849932  0.21152467  0.19954287]\n",
      " [ 0.14897719  0.12018248  0.16093907  0.11739128  0.20994079  0.19901833]\n",
      " [ 0.15011184  0.1219525   0.1584235   0.12236302  0.20873718  0.20376742]]\n",
      "Episode:    260\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     202.25\n",
      "    Step:   208112\n",
      "    Q value:    0.1753159761428833\n",
      "    Loss:   0.0016115870093926787\n",
      "    Look-up table:\n",
      "[[-0.08207461 -0.04932489 -0.07859471 -0.0805945  -0.08148779 -0.04304978]\n",
      " [-0.08456255 -0.05008242 -0.08512584 -0.0845105  -0.08503073 -0.05111115]\n",
      " [-0.08576451 -0.05038209 -0.08835549 -0.08678212 -0.08727804 -0.05277129]\n",
      " ...\n",
      " [ 0.28727973  0.31533805  0.2691046   0.22363198  0.28038567  0.30418545]\n",
      " [ 0.27316305  0.29283643  0.25623435  0.21109363  0.27114666  0.28374398]\n",
      " [ 0.25668201  0.27773109  0.23895347  0.20131047  0.2550818   0.26566297]]\n",
      "Episode:    270\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     182.75\n",
      "    Step:   216409\n",
      "    Q value:    0.13412347435951233\n",
      "    Loss:   0.0005175357218831778\n",
      "    Look-up table:\n",
      "[[1.95584893e-02 3.69067341e-02 3.79394144e-02 3.02069932e-02\n",
      "  3.92519087e-02 4.18408439e-02]\n",
      " [3.00823897e-03 2.79814899e-02 2.78280675e-02 1.61848813e-02\n",
      "  2.53224969e-02 2.75967196e-02]\n",
      " [9.35316086e-04 2.56035924e-02 2.38064528e-02 1.35355666e-02\n",
      "  2.38662511e-02 2.56364793e-02]\n",
      " ...\n",
      " [6.22954518e-02 1.22138798e-01 7.70367533e-02 8.71583223e-02\n",
      "  9.85946432e-02 8.73822570e-02]\n",
      " [1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 1.00000000e+00]\n",
      " [6.15349896e-02 1.24312513e-01 7.37867057e-02 8.55720639e-02\n",
      "  9.54118520e-02 8.71384963e-02]]\n",
      "Episode:    280\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     188.0\n",
      "    Step:   224705\n",
      "    Q value:    0.14699873328208923\n",
      "    Loss:   0.009805343113839626\n",
      "    Look-up table:\n",
      "[[-0.0208462  -0.03408314 -0.04687439 -0.0126808  -0.04589349  0.03451416]\n",
      " [-0.02695916 -0.03459918 -0.05175896 -0.01549239 -0.0506728   0.03223115]\n",
      " [-0.02779371 -0.03489497 -0.05490887 -0.01649269 -0.05160609  0.03185467]\n",
      " ...\n",
      " [ 0.13228135  0.05523267  0.06901856  0.18425222  0.07906176  0.17406188]\n",
      " [ 0.12971254  0.05548136  0.06833608  0.18548919  0.07732093  0.1756779 ]\n",
      " [ 0.12031594  0.02896722  0.06846857  0.16546479  0.07075541  0.15524451]]\n",
      "Episode:    290\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     163.75\n",
      "    Step:   232068\n",
      "    Q value:    0.12333065271377563\n",
      "    Loss:   0.0005654277629218996\n",
      "    Look-up table:\n",
      "[[ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.00704882 -0.00244308  0.02785404  0.02613332 -0.01879437  0.024597  ]\n",
      " [-0.01177193 -0.00408027  0.02485821  0.02297095 -0.02112168  0.02254643]\n",
      " ...\n",
      " [ 0.1748791   0.1823312   0.18342566  0.14928509  0.13431385  0.17551108]\n",
      " [ 0.17321497  0.1810334   0.18181714  0.14834537  0.13195947  0.17394231]\n",
      " [ 0.17586786  0.17984483  0.17602172  0.15180524  0.13073586  0.17709322]]\n",
      "Episode:    300\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     148.0\n",
      "    Step:   240159\n",
      "    Q value:    0.19086822867393494\n",
      "    Loss:   1.1750692129135132\n",
      "    Look-up table:\n",
      "[[ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.04039454 -0.05690077  0.0063291  -0.03653021 -0.02507047 -0.07551834]\n",
      " [-0.04277887 -0.05581373  0.00456537 -0.03823735 -0.02625221 -0.07693319]\n",
      " ...\n",
      " [ 0.15846147  0.15510397  0.20354456  0.08812349  0.07959381  0.13129924]\n",
      " [ 0.15301295  0.15218103  0.19666928  0.08485765  0.07914647  0.12919429]\n",
      " [ 0.13385946  0.11677931  0.17947707  0.06078789  0.06673349  0.09597018]]\n",
      "Episode:    310\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     147.0\n",
      "    Step:   247323\n",
      "    Q value:    0.23406024277210236\n",
      "    Loss:   0.002027121838182211\n",
      "    Look-up table:\n",
      "[[-0.06053105  0.03448388 -0.04238878  0.02442294 -0.03716095 -0.00658479]\n",
      " [-0.07019807  0.03390621 -0.0445036   0.02022135 -0.04439206 -0.0149546 ]\n",
      " [-0.07758182  0.03489136 -0.04657863  0.01530476 -0.0481039  -0.01862957]\n",
      " ...\n",
      " [-0.10892525  0.13046782 -0.07607323  0.03426807 -0.121379   -0.02177945]\n",
      " [-0.10728198  0.12997155 -0.07575299  0.0326831  -0.12013225 -0.02088782]\n",
      " [-0.11336727  0.10657147 -0.10349858  0.0204338  -0.11594789 -0.02496506]]\n",
      "Episode:    320\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     158.75\n",
      "    Step:   255420\n",
      "    Q value:    0.12302089482545853\n",
      "    Loss:   0.00048680606414563954\n",
      "    Look-up table:\n",
      "[[ 0.05418438  0.04044795 -0.02328387  0.00860804 -0.00591841 -0.02512388]\n",
      " [ 0.05167517  0.04300895 -0.02121654  0.00395311 -0.00822853 -0.03079833]\n",
      " [ 0.05147215  0.04433672 -0.01992844  0.00282019 -0.00813217 -0.03067994]\n",
      " ...\n",
      " [ 0.09945652  0.03755607  0.09741536  0.03600436  0.09013126  0.06163026]\n",
      " [ 0.09842971  0.03615446  0.09639627  0.0341198   0.09030646  0.05995472]\n",
      " [ 0.0811419   0.01352338  0.0670066   0.00475436  0.08246208  0.02224645]]\n",
      "Episode:    330\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     158.5\n",
      "    Step:   263854\n",
      "    Q value:    0.09477493166923523\n",
      "    Loss:   0.00015543514746241271\n",
      "    Look-up table:\n",
      "[[-0.01476157 -0.06471765 -0.09683448 -0.00869876 -0.06059861 -0.07816066]\n",
      " [-0.01854549 -0.06549335 -0.09112351 -0.01592845 -0.06519848 -0.0895042 ]\n",
      " [-0.02443139 -0.06093223 -0.09263994 -0.02322307 -0.0679927  -0.09736599]\n",
      " ...\n",
      " [ 0.23489216  0.21071869  0.16325235  0.24470405  0.15023145  0.13968167]\n",
      " [ 0.23572905  0.21153384  0.16297479  0.24593595  0.14934827  0.14127015]\n",
      " [ 0.21788952  0.19202478  0.13813864  0.23251103  0.14038688  0.12214874]]\n",
      "Episode:    340\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     124.75\n",
      "    Step:   270849\n",
      "    Q value:    0.10978882014751434\n",
      "    Loss:   0.001595943234860897\n",
      "    Look-up table:\n",
      "[[ 0.003024   -0.02810906 -0.02528855 -0.03969596 -0.02427047 -0.03527485]\n",
      " [ 0.00287578 -0.02456331 -0.02329671 -0.04323436 -0.02454008 -0.03926349]\n",
      " [ 0.00238448 -0.02173711 -0.02257025 -0.04532789 -0.02537975 -0.0421429 ]\n",
      " ...\n",
      " [ 0.03057324  0.05290879  0.02195498 -0.01222014  0.04092959  0.02302399]\n",
      " [ 0.02973361  0.05312568  0.02307171 -0.01295786  0.04118776  0.02357362]\n",
      " [ 0.01138499  0.02022405 -0.01062308 -0.03962928  0.0171781  -0.00630209]]\n",
      "Episode:    350\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     130.5\n",
      "    Step:   278462\n",
      "    Q value:    0.04137912765145302\n",
      "    Loss:   0.0007080192444846034\n",
      "    Look-up table:\n",
      "[[-0.01216714 -0.01462375 -0.06131047 -0.06329198 -0.03274004 -0.04998277]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.00907232 -0.01140693 -0.05420017 -0.07695003 -0.03463323 -0.06123449]\n",
      " ...\n",
      " [ 0.11740482  0.0435994   0.07661535  0.06525532  0.12565914  0.05140805]\n",
      " [ 0.11198723  0.04358895  0.07512008  0.06632265  0.12156471  0.05411866]\n",
      " [ 0.07950482  0.00208718  0.03066722  0.03640495  0.08343631  0.03618316]]\n",
      "Episode:    360\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     133.25\n",
      "    Step:   284818\n",
      "    Q value:    0.1177365779876709\n",
      "    Loss:   0.0023784302175045013\n",
      "    Look-up table:\n",
      "[[-0.10876603 -0.11796932 -0.05708125 -0.07881509 -0.05764304 -0.05366854]\n",
      " [-0.11176108 -0.11930378 -0.05716531 -0.08272137 -0.05815838 -0.05524559]\n",
      " [-0.1129238  -0.11787005 -0.05615118 -0.08353852 -0.0562474  -0.05621321]\n",
      " ...\n",
      " [ 0.13298747  0.15609044  0.16936871  0.19577156  0.16546744  0.24957031]\n",
      " [ 0.13417818  0.15710817  0.16790965  0.19807276  0.16737643  0.25069952]\n",
      " [ 0.05549733  0.05623611  0.07416146  0.08052084  0.09835149  0.14830631]]\n",
      "Episode:    370\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     175.25\n",
      "    Step:   294517\n",
      "    Q value:    0.07963138818740845\n",
      "    Loss:   0.2778831124305725\n",
      "    Look-up table:\n",
      "[[-0.09179588 -0.0671915  -0.03016797 -0.09327827 -0.04209489 -0.13183999]\n",
      " [-0.09379013 -0.06705509 -0.03143039 -0.09686974 -0.04099892 -0.13430524]\n",
      " [-0.09601106 -0.0660008  -0.03165485 -0.09994923 -0.03917089 -0.14073828]\n",
      " ...\n",
      " [ 0.11634769  0.04279941  0.09313458  0.10027613  0.15001684  0.03830409]\n",
      " [ 0.11777926  0.04449394  0.09076663  0.10094606  0.15011574  0.03917482]\n",
      " [ 0.10134498  0.02817093  0.07790728  0.08564923  0.13761288  0.01293737]]\n",
      "Episode:    380\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     206.25\n",
      "    Step:   302937\n",
      "    Q value:    0.12094078212976456\n",
      "    Loss:   0.0017816047184169292\n",
      "    Look-up table:\n",
      "[[-0.12275533 -0.13296182 -0.06774236 -0.11468855 -0.11352281 -0.10965306]\n",
      " [-0.12275074 -0.12893458 -0.06551555 -0.11426699 -0.11203544 -0.10875767]\n",
      " [-0.1234834  -0.12453891 -0.06388913 -0.11664259 -0.10829897 -0.10753977]\n",
      " ...\n",
      " [ 0.0402562  -0.06665283 -0.02324076  0.08660483 -0.00583994  0.01521753]\n",
      " [ 0.05131342 -0.04499732  0.02268046  0.08102588  0.03338508  0.00819862]\n",
      " [-0.00433336 -0.06664987 -0.07587156  0.05182718 -0.00394143  0.03926495]]\n",
      "Episode:    390\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     145.75\n",
      "    Step:   309966\n",
      "    Q value:    0.03739137202501297\n",
      "    Loss:   0.0009233404998667538\n",
      "    Look-up table:\n",
      "[[-0.09904251 -0.14109719 -0.13504447 -0.07424524 -0.09206168 -0.10133202]\n",
      " [-0.10024104 -0.1383183  -0.13234933 -0.07504497 -0.08865757 -0.10031612]\n",
      " [-0.10001536 -0.12962773 -0.12650152 -0.07782139 -0.07913679 -0.0932887 ]\n",
      " ...\n",
      " [ 0.16513698  0.1241878   0.22263215  0.17499897  0.13964675  0.23906769]\n",
      " [ 0.16718835  0.12518391  0.22355905  0.17622817  0.14029391  0.24033727]\n",
      " [ 0.12381937  0.10853591  0.17744257  0.12581925  0.11278003  0.21604253]]\n",
      "Episode:    400\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     117.5\n",
      "    Step:   317405\n",
      "    Q value:    0.24626001715660095\n",
      "    Loss:   0.006848038174211979\n",
      "    Look-up table:\n",
      "[[ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.15415351 -0.14855273 -0.12688884 -0.16241798 -0.15154138 -0.15122443]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 0.61517942  0.56172585  0.49451116  0.90200722  0.61809099  0.47200415]\n",
      " [ 0.60434371  0.55374795  0.49113819  0.87846637  0.6098873   0.46594596]\n",
      " [ 0.34623438  0.32261765  0.2593115   0.55643284  0.38706714  0.27436557]]\n",
      "Episode:    410\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     142.75\n",
      "    Step:   325495\n",
      "    Q value:    0.10456575453281403\n",
      "    Loss:   0.0010800291784107685\n",
      "    Look-up table:\n",
      "[[-0.11344117 -0.15172414 -0.09556414 -0.10020748 -0.16763334 -0.16632958]\n",
      " [-0.11727034 -0.15423585 -0.09569052 -0.10460308 -0.168832   -0.16871983]\n",
      " [-0.12123869 -0.15728833 -0.0989565  -0.10918882 -0.16709661 -0.16851741]\n",
      " ...\n",
      " [ 0.05718171 -0.04477428 -0.05169559 -0.01316923 -0.12309435 -0.03122368]\n",
      " [ 0.05785862 -0.04351848 -0.05254839 -0.0128904  -0.12416396 -0.03266448]\n",
      " [ 0.04263011 -0.06829119 -0.09016761 -0.01957589 -0.1208753  -0.10225429]]\n",
      "Episode:    420\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     161.0\n",
      "    Step:   333075\n",
      "    Q value:    0.11447043716907501\n",
      "    Loss:   0.0018661152571439743\n",
      "    Look-up table:\n",
      "[[-0.08648537 -0.09642538 -0.08733207 -0.0864078  -0.09135258 -0.12314731]\n",
      " [-0.08614375 -0.09631982 -0.08688444 -0.08668844 -0.09063423 -0.12401533]\n",
      " [-0.08437423 -0.09354286 -0.08666506 -0.08837029 -0.08500108 -0.12111771]\n",
      " ...\n",
      " [ 0.05809747  0.07711647  0.05443212  0.05820273  0.07264653  0.06863915]\n",
      " [ 0.05818368  0.07712428  0.05542152  0.05761681  0.07282148  0.06939412]\n",
      " [ 0.03850876  0.04780804  0.02681151  0.0427487   0.03806898  0.03996772]]\n",
      "Episode:    430\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     149.75\n",
      "    Step:   340723\n",
      "    Q value:    0.1667281538248062\n",
      "    Loss:   0.004382116720080376\n",
      "    Look-up table:\n",
      "[[-2.28456035e-01 -1.09798342e-01  5.80139458e-03 -1.44541636e-01\n",
      "  -1.16822794e-01 -8.45572054e-02]\n",
      " [-2.27364749e-01 -1.08180836e-01  8.81443918e-03 -1.42014265e-01\n",
      "  -1.14025861e-01 -8.15450698e-02]\n",
      " [-2.26191014e-01 -1.10767975e-01  1.35659277e-02 -1.47235602e-01\n",
      "  -1.08449847e-01 -7.87923783e-02]\n",
      " ...\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 4.18348759e-02  4.59818393e-02  6.27260208e-02  2.54442245e-02\n",
      "   2.47610807e-02  8.49282146e-02]\n",
      " [ 7.02825189e-03  7.08281994e-04  5.07319421e-02  5.99414110e-04\n",
      "  -9.84331965e-03  4.81720716e-02]]\n",
      "Episode:    440\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     150.5\n",
      "    Step:   348052\n",
      "    Q value:    0.13569822907447815\n",
      "    Loss:   2.0926413536071777\n",
      "    Look-up table:\n",
      "[[-0.15933125 -0.0399148  -0.10129535 -0.10600871 -0.11807847 -0.07117181]\n",
      " [-0.15780516 -0.03917311 -0.0982891  -0.10782555 -0.11673489 -0.07211666]\n",
      " [-0.15731271 -0.04264593 -0.0962263  -0.11440045 -0.11567837 -0.07406048]\n",
      " ...\n",
      " [ 0.05150566  0.15835038  0.03202681  0.04391506  0.10994928 -0.11550924]\n",
      " [ 0.04908325  0.15502815  0.02800825  0.03768274  0.10388589 -0.12145351]\n",
      " [ 0.01530372  0.12581816 -0.00814523  0.01507944  0.06998925 -0.15768282]]\n",
      "Episode:    450\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     154.25\n",
      "    Step:   355217\n",
      "    Q value:    0.08789137005805969\n",
      "    Loss:   0.0014456649078056216\n",
      "    Look-up table:\n",
      "[[-0.02908206 -0.02100703 -0.06638923 -0.01654884 -0.03240383 -0.07386553]\n",
      " [-0.02614328 -0.0199053  -0.06471485 -0.01392096 -0.02938151 -0.07215276]\n",
      " [-0.02499577 -0.01872803 -0.06289059 -0.01598677 -0.02611104 -0.06794831]\n",
      " ...\n",
      " [-0.00794652 -0.07673772 -0.06561281 -0.02073821  0.01673417 -0.05080214]\n",
      " [-0.00841333 -0.07651262 -0.06608324 -0.0210613   0.01369582 -0.05063887]\n",
      " [-0.02570631 -0.104054   -0.09196346 -0.03756893 -0.0060063  -0.08394842]]\n",
      "Episode:    460\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     170.5\n",
      "    Step:   363575\n",
      "    Q value:    0.07152841985225677\n",
      "    Loss:   0.006004734430462122\n",
      "    Look-up table:\n",
      "[[ 0.0177529  -0.02741687 -0.09033297 -0.03400336 -0.17714162 -0.110753  ]\n",
      " [ 0.02115025 -0.02235149 -0.09032173 -0.03078562 -0.17660607 -0.11121964]\n",
      " [ 0.02587381 -0.01452503 -0.08958016 -0.03134471 -0.16907854 -0.10884103]\n",
      " ...\n",
      " [-0.05893521 -0.11341223  0.01646024 -0.14445563 -0.10189666 -0.16104288]\n",
      " [-0.05840404 -0.11407977  0.01630409 -0.14308418 -0.10199244 -0.16097395]\n",
      " [-0.05987832 -0.11733055 -0.00509273 -0.18909074 -0.11576571 -0.19900821]]\n",
      "Episode:    470\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     155.25\n",
      "    Step:   370303\n",
      "    Q value:    0.028282254934310913\n",
      "    Loss:   0.0005547392647713423\n",
      "    Look-up table:\n",
      "[[-0.06811817 -0.09562109 -0.08812037 -0.05656788 -0.06351878 -0.09576304]\n",
      " [-0.06988361 -0.09713487 -0.08626595 -0.05734764 -0.06671844 -0.09418024]\n",
      " [-0.07177332 -0.09671746 -0.08183143 -0.06335135 -0.06443857 -0.09014677]\n",
      " ...\n",
      " [ 0.14800031  0.15397443  0.08137702  0.08178113  0.11440222  0.04592489]\n",
      " [ 0.1490466   0.15643916  0.084168    0.08191024  0.11650076  0.04926221]\n",
      " [ 0.11595649  0.12366156  0.05482024  0.06527535  0.08739565  0.02232963]]\n",
      "Episode:    480\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     105.75\n",
      "    Step:   376919\n",
      "    Q value:    0.09312999248504639\n",
      "    Loss:   0.0007649004692211747\n",
      "    Look-up table:\n",
      "[[ 0.00208673 -0.08191913 -0.03737228 -0.01058449 -0.00840855 -0.05963437]\n",
      " [-0.00069565 -0.08584964 -0.04018214 -0.01368795 -0.01131149 -0.06347956]\n",
      " [ 0.0029968  -0.08169274 -0.03601497 -0.0129481  -0.00676996 -0.05477712]\n",
      " ...\n",
      " [ 0.20780042 -0.02048878  0.09645584  0.09643309  0.04521628  0.09396752]\n",
      " [ 0.21211958 -0.02109845  0.09963264  0.09601723  0.0449504   0.09643327]\n",
      " [ 0.19095567 -0.04338764  0.08453407  0.10882609  0.0239919   0.07746767]]\n",
      "Episode:    490\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     142.5\n",
      "    Step:   385410\n",
      "    Q value:    0.06396753340959549\n",
      "    Loss:   0.00032322388142347336\n",
      "    Look-up table:\n",
      "[[-0.11803535 -0.09039289 -0.06968328 -0.09682105 -0.04746898 -0.0359751 ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.13040605 -0.09232178 -0.07299256 -0.10828243 -0.05360422 -0.03479089]\n",
      " ...\n",
      " [ 0.06446981  0.0430321   0.04936273  0.05733851  0.0883155  -0.01448672]\n",
      " [ 0.06465399  0.04496858  0.05226484  0.05825076  0.09008726 -0.01448931]\n",
      " [ 0.02027339  0.00499873 -0.00452897  0.01862772  0.0759743  -0.07783552]]\n",
      "Episode:    500\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     201.5\n",
      "    Step:   394624\n",
      "    Q value:    0.1056039035320282\n",
      "    Loss:   0.00045279727783054113\n",
      "    Look-up table:\n",
      "[[-0.07991432 -0.16371244 -0.21149567 -0.05251269 -0.07642028 -0.06592149]\n",
      " [-0.08551158 -0.16498801 -0.21211864 -0.05832158 -0.07664326 -0.06886207]\n",
      " [-0.08788346 -0.16078106 -0.21039911 -0.06608032 -0.07518291 -0.06801464]\n",
      " ...\n",
      " [ 0.14321345  0.06021812  0.1492776   0.13140643  0.15253523 -0.0391036 ]\n",
      " [ 0.16614202  0.04326721  0.13853815  0.14454015  0.15171947 -0.02062325]\n",
      " [-0.1375193  -0.03778861 -0.01955096 -0.02144085  0.00196572 -0.19942081]]\n",
      "Episode:    510\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     202.75\n",
      "    Step:   403178\n",
      "    Q value:    0.09149283170700073\n",
      "    Loss:   0.0025556362234055996\n",
      "    Look-up table:\n",
      "[[-0.0448561  -0.12391536 -0.07966977 -0.01310067 -0.09334356 -0.04803957]\n",
      " [-0.04593296 -0.12754728 -0.07935414 -0.0154693  -0.09677127 -0.04873152]\n",
      " [-0.04440352 -0.12787196 -0.07408121 -0.02123009 -0.09634431 -0.05022983]\n",
      " ...\n",
      " [ 0.13124476  0.09443085  0.23777539  0.15959725  0.27995044  0.203016  ]\n",
      " [ 0.1318738   0.09272848  0.2339094   0.16032416  0.28088602  0.19959231]\n",
      " [-0.03565378 -0.0349821   0.08195649  0.02964586  0.13392866  0.04420067]]\n",
      "Episode:    520\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     147.25\n",
      "    Step:   409349\n",
      "    Q value:    0.07418209314346313\n",
      "    Loss:   0.0018887178739532828\n",
      "    Look-up table:\n",
      "[[ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.05054381 -0.02048273 -0.07732579 -0.0562159  -0.03589822 -0.01895104]\n",
      " [-0.05005689 -0.01931374 -0.07330367 -0.06002332 -0.03450994 -0.02456094]\n",
      " ...\n",
      " [ 0.04679178  0.0393209   0.03950685  0.1319249   0.02262193  0.04094931]\n",
      " [ 0.04643118  0.04014497  0.04004766  0.1307916   0.0246319   0.04069865]\n",
      " [-0.00463103  0.01448467 -0.01446442  0.08215188 -0.01015522 -0.01405339]]\n",
      "Episode:    530\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     155.0\n",
      "    Step:   417307\n",
      "    Q value:    0.10880400985479355\n",
      "    Loss:   0.0008385034161619842\n",
      "    Look-up table:\n",
      "[[-0.00495048 -0.02662504 -0.01769002 -0.04708095 -0.00775163 -0.08923297]\n",
      " [-0.00577445 -0.02824989 -0.02071649 -0.04853244 -0.00916083 -0.0867475 ]\n",
      " [-0.01040483 -0.03453675 -0.02784306 -0.05518328 -0.01244605 -0.07901752]\n",
      " ...\n",
      " [ 0.17935184  0.20985636  0.21160051  0.13539284  0.15844765  0.10200937]\n",
      " [ 0.17805105  0.20927526  0.20932785  0.1351333   0.16023111  0.10400169]\n",
      " [ 0.13578939  0.18951339  0.15767935  0.09190741  0.12607226  0.07364142]]\n",
      "Episode:    540\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     192.5\n",
      "    Step:   425804\n",
      "    Q value:    0.06901904940605164\n",
      "    Loss:   0.0006852933438494802\n",
      "    Look-up table:\n",
      "[[ 0.00065933 -0.05647264 -0.08845912 -0.00647181 -0.00525081 -0.05784415]\n",
      " [-0.00327465 -0.06005745 -0.09438048 -0.0073882  -0.00783914 -0.05537401]\n",
      " [-0.01439086 -0.06991857 -0.10477994 -0.01335299 -0.01706085 -0.04811965]\n",
      " ...\n",
      " [ 0.06361678 -0.03025649 -0.07990147  0.0366035   0.01540168  0.17857943]\n",
      " [ 0.06433206 -0.02991588 -0.07980014  0.03774361  0.01590127  0.1787096 ]\n",
      " [ 0.01211286 -0.0750542  -0.11510377 -0.01277336 -0.03175996  0.12831241]]\n",
      "Episode:    550\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     187.5\n",
      "    Step:   433512\n",
      "    Q value:    0.06146376207470894\n",
      "    Loss:   0.0016663259593769908\n",
      "    Look-up table:\n",
      "[[-0.03784896 -0.09472325  0.00223935 -0.06684025 -0.02455947 -0.09569007]\n",
      " [-0.03911689 -0.09811081  0.00152957 -0.06755616 -0.02348574 -0.10325907]\n",
      " [-0.04472803 -0.10548948 -0.0075404  -0.07113023 -0.02872981 -0.09748204]\n",
      " ...\n",
      " [ 0.03690645 -0.01074199  0.02536951  0.10622212 -0.07547137  0.16520442]\n",
      " [ 0.03623113 -0.01102535  0.02799234  0.10900752 -0.07430279  0.15657984]\n",
      " [-0.01230443 -0.05449711 -0.00756249  0.06935217 -0.09496112  0.12314428]]\n",
      "Episode:    560\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     181.0\n",
      "    Step:   441702\n",
      "    Q value:    0.07518342137336731\n",
      "    Loss:   0.0032538294326514006\n",
      "    Look-up table:\n",
      "[[-0.02572651 -0.06170353  0.01641217 -0.00682673 -0.04242675 -0.05225271]\n",
      " [-0.02904552 -0.06855294  0.01393679 -0.00915909 -0.04590367 -0.06400949]\n",
      " [-0.03175285 -0.07297502  0.01356429 -0.01232521 -0.05030461 -0.0772208 ]\n",
      " ...\n",
      " [-0.00319797  0.11171725  0.07393475  0.02762702 -0.09935291  0.20318843]\n",
      " [ 0.00022972  0.11233014  0.07419342  0.02735835 -0.09850535  0.20995514]\n",
      " [-0.06422263  0.05214477  0.00517952 -0.07007107 -0.13868278  0.14876734]]\n",
      "Episode:    570\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     188.0\n",
      "    Step:   449765\n",
      "    Q value:    0.10386541485786438\n",
      "    Loss:   0.00840518157929182\n",
      "    Look-up table:\n",
      "[[-0.07086056 -0.10572104 -0.06944822 -0.10138986 -0.03861903 -0.08704507]\n",
      " [-0.07525027 -0.11508031 -0.07344593 -0.10435206 -0.04038469 -0.10226938]\n",
      " [-0.07751614 -0.12032504 -0.07616965 -0.10837168 -0.0426148  -0.11178789]\n",
      " ...\n",
      " [ 0.02936146  0.03884566  0.23199917  0.0750704   0.26211923  0.14968368]\n",
      " [ 0.02836382  0.03836747  0.23115529  0.07398811  0.26255292  0.14761487]\n",
      " [-0.01020077 -0.00439012  0.19838336  0.02527282  0.22256523  0.11549175]]\n",
      "Episode:    580\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     166.75\n",
      "    Step:   457364\n",
      "    Q value:    0.08970843255519867\n",
      "    Loss:   0.9066465497016907\n",
      "    Look-up table:\n",
      "[[-0.14056276 -0.06380533 -0.11663246 -0.11111419 -0.16696565 -0.06676073]\n",
      " [-0.14142703 -0.07138963 -0.12116322 -0.1124626  -0.16731511 -0.07262085]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 0.09156615  0.10270113  0.12819633  0.09068714  0.097027    0.12542188]\n",
      " [ 0.09189109  0.10313365  0.12856615  0.09062548  0.09745071  0.12608728]\n",
      " [ 0.01579058  0.02299064  0.06784403  0.00836484  0.01083696  0.02302107]]\n",
      "Episode:    590\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     126.75\n",
      "    Step:   463706\n",
      "    Q value:    0.14702653884887695\n",
      "    Loss:   0.004797306843101978\n",
      "    Look-up table:\n",
      "[[-0.12083648 -0.1441575  -0.0640458  -0.09374183 -0.08602731  0.04157047]\n",
      " [-0.12246038 -0.14700751 -0.06692135 -0.09302339 -0.08393191  0.03345013]\n",
      " [-0.12503307 -0.15043394 -0.07053399 -0.09318408 -0.08145423  0.022741  ]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.21455206  0.19067524  0.13621897  0.17464109  0.14039139  0.21082704]\n",
      " [ 0.09643765  0.07196692  0.02679455  0.05261984  0.03153729  0.04653473]]\n",
      "Episode:    600\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     153.25\n",
      "    Step:   471896\n",
      "    Q value:    0.0977083370089531\n",
      "    Loss:   0.00271077873185277\n",
      "    Look-up table:\n",
      "[[-0.20071557 -0.13395984 -0.17146371 -0.1415047  -0.16935959 -0.24283126]\n",
      " [-0.20026265 -0.14086306 -0.17269573 -0.14034687 -0.16680676 -0.25644112]\n",
      " [-0.20432614 -0.14857984 -0.18017787 -0.14288987 -0.16391763 -0.27441648]\n",
      " ...\n",
      " [ 0.1014557   0.07902512  0.13947289  0.06138378  0.1120239   0.12282549]\n",
      " [ 0.10125011  0.08014505  0.14036988  0.05995129  0.111656    0.1258934 ]\n",
      " [ 0.07711345  0.07292774  0.12143144  0.04511797  0.10984701  0.08930504]]\n",
      "Episode:    610\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     169.5\n",
      "    Step:   478569\n",
      "    Q value:    0.05213925987482071\n",
      "    Loss:   0.0032583875581622124\n",
      "    Look-up table:\n",
      "[[-0.07672192 -0.09670517 -0.11969195 -0.09309588 -0.07931621 -0.10012557]\n",
      " [-0.08035909 -0.11462644 -0.13376831 -0.10154973 -0.08177109 -0.10950767]\n",
      " [-0.07655495 -0.12599969 -0.14050098 -0.10455658 -0.07707597 -0.11357479]\n",
      " ...\n",
      " [-0.01099958 -0.00881542  0.02440599 -0.05912974  0.03485829 -0.02944595]\n",
      " [-0.01425253 -0.01191966  0.023975   -0.06508601  0.03185154 -0.03131294]\n",
      " [-0.07227604 -0.05310068 -0.01509301 -0.14864215 -0.00492217 -0.05297488]]\n",
      "Episode:    620\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     158.25\n",
      "    Step:   486346\n",
      "    Q value:    0.07620558142662048\n",
      "    Loss:   0.5935649871826172\n",
      "    Look-up table:\n",
      "[[-0.05242321 -0.06027026 -0.0857411  -0.0122236  -0.0672448  -0.07710478]\n",
      " [-0.05649877 -0.07027158 -0.08898753 -0.01830269 -0.0719956  -0.08069418]\n",
      " [-0.0620693  -0.08011186 -0.09451541 -0.02391894 -0.07757555 -0.08742015]\n",
      " ...\n",
      " [ 0.05176112  0.01330675  0.03171673  0.00532439  0.08833128  0.0876195 ]\n",
      " [ 0.0524558   0.01423825  0.03176963  0.00713511  0.08822129  0.08675371]\n",
      " [ 0.0134216  -0.03097479 -0.02673277 -0.02635923  0.07276613  0.02301191]]\n",
      "Episode:    630\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     136.0\n",
      "    Step:   493808\n",
      "    Q value:    0.08850952982902527\n",
      "    Loss:   0.0006258671055547893\n",
      "    Look-up table:\n",
      "[[-0.13135463 -0.09318766 -0.10245413 -0.07758765 -0.09231277 -0.04041964]\n",
      " [-0.13500524 -0.09907174 -0.10442379 -0.08303101 -0.09547816 -0.04437679]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 0.21335539  0.1217206   0.18293899  0.15088928  0.16670334  0.13823064]\n",
      " [ 0.21258375  0.12029599  0.18222371  0.150429    0.16675134  0.13909265]\n",
      " [ 0.15512042  0.06666723  0.11250977  0.12139207  0.13814674  0.08780287]]\n",
      "Episode:    640\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     126.25\n",
      "    Step:   501247\n",
      "    Q value:    0.0942782312631607\n",
      "    Loss:   0.0015782078262418509\n",
      "    Look-up table:\n",
      "[[-0.0383909  -0.04786007 -0.05744259 -0.05634412 -0.07714656 -0.05556142]\n",
      " [-0.04785246 -0.05769481 -0.0627739  -0.06512429 -0.08952436 -0.06878269]\n",
      " [-0.05813175 -0.06845535 -0.06942214 -0.07225005 -0.10159376 -0.08278692]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.03824517 -0.06606412 -0.04215413 -0.03305541 -0.09917489 -0.04775701]\n",
      " [-0.14911297 -0.19182137 -0.10004458 -0.08155005 -0.14011869 -0.15958641]]\n",
      "Episode:    650\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     190.75\n",
      "    Step:   510776\n",
      "    Q value:    0.024558596312999725\n",
      "    Loss:   0.001623815856873989\n",
      "    Look-up table:\n",
      "[[-0.06442207 -0.05426086 -0.09872487 -0.07812096 -0.11184321 -0.0247127 ]\n",
      " [-0.06626099 -0.05763997 -0.09609523 -0.0817935  -0.11314909 -0.02491246]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [-0.17269662 -0.20435476 -0.09477749 -0.06731926 -0.25658354 -0.16373332]\n",
      " [-0.18371549 -0.21067598 -0.10827667 -0.08076803 -0.27204505 -0.17312382]\n",
      " [-0.18719697 -0.24550524 -0.19512042 -0.16706058 -0.39790291 -0.33631024]]\n",
      "Episode:    660\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     189.5\n",
      "    Step:   517520\n",
      "    Q value:    0.08471090346574783\n",
      "    Loss:   0.0019455122528597713\n",
      "    Look-up table:\n",
      "[[-0.06422372 -0.07112598 -0.11635251 -0.06403784 -0.1273606  -0.05672193]\n",
      " [-0.06478389 -0.07708085 -0.11588927 -0.06571665 -0.12614609 -0.06558862]\n",
      " [-0.07577191 -0.11151093 -0.12774809 -0.07839182 -0.12903349 -0.09601116]\n",
      " ...\n",
      " [ 0.27004951  0.22608754  0.22515894  0.17790413  0.17667069  0.14053822]\n",
      " [ 0.27464515  0.22907919  0.22616175  0.1823412   0.18164262  0.14637621]\n",
      " [ 0.1176356   0.04870428  0.0463772   0.03002568  0.06498809  0.05063416]]\n",
      "Episode:    670\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     151.25\n",
      "    Step:   524240\n",
      "    Q value:    0.419779896736145\n",
      "    Loss:   1.8581597805023193\n",
      "    Look-up table:\n",
      "[[-0.10072255 -0.13337821 -0.11484139 -0.07746872 -0.10587065 -0.11643687]\n",
      " [-0.10913214 -0.14316371 -0.1172273  -0.08533558 -0.11419906 -0.12701237]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 0.03366266  0.06867409  0.04188207 -0.00602169  0.02463737  0.18582296]\n",
      " [ 0.0292996   0.0686892   0.03973351 -0.00940879  0.02376531  0.17962031]\n",
      " [-0.0601152   0.04914953 -0.00596693 -0.04936059 -0.04653154  0.16508541]]\n",
      "Episode:    680\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     145.75\n",
      "    Step:   530722\n",
      "    Q value:    0.05072401091456413\n",
      "    Loss:   0.005328186322003603\n",
      "    Look-up table:\n",
      "[[-0.12692156 -0.1190069  -0.12135725 -0.10421485 -0.09401479 -0.10256457]\n",
      " [-0.12964424 -0.11647736 -0.11785628 -0.110494   -0.09746982 -0.10443088]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 0.04846932  0.05186039  0.01516323 -0.02246404  0.14642653  0.06676489]\n",
      " [ 0.04758453  0.05111675  0.02221745 -0.02141234  0.14672656  0.07381016]\n",
      " [-0.023496    0.05059986  0.01359861 -0.00355384  0.07520193  0.10506688]]\n",
      "Episode:    690\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     165.75\n",
      "    Step:   538291\n",
      "    Q value:    0.03647264093160629\n",
      "    Loss:   0.2109065055847168\n",
      "    Look-up table:\n",
      "[[-0.10052516 -0.07282843 -0.09497738 -0.09361577 -0.10450928 -0.17416278]\n",
      " [-0.10682525 -0.0794519  -0.09668931 -0.10288334 -0.10543667 -0.18034065]\n",
      " [-0.11420439 -0.09070723 -0.10662621 -0.1210885  -0.10650985 -0.19589043]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.00964865 -0.03832747 -0.0471832  -0.10125299 -0.15051366 -0.11193717]\n",
      " [-0.09417859 -0.1228326  -0.13045727 -0.11521234 -0.28131074 -0.2256797 ]]\n",
      "Episode:    700\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     208.25\n",
      "    Step:   547862\n",
      "    Q value:    -0.026658931747078896\n",
      "    Loss:   0.0014827174600213766\n",
      "    Look-up table:\n",
      "[[-0.18689914 -0.15700531 -0.12044466 -0.09360255 -0.18932734 -0.11121529]\n",
      " [-0.20456098 -0.17331257 -0.12885398 -0.11075641 -0.20302506 -0.12630016]\n",
      " [-0.22218494 -0.19309744 -0.1395326  -0.13065074 -0.21557657 -0.14242929]\n",
      " ...\n",
      " [-0.10157293 -0.17385991 -0.1433685  -0.12591824 -0.04289067 -0.16276911]\n",
      " [-0.10178383 -0.17384547 -0.14195161 -0.12404817 -0.04379264 -0.16073254]\n",
      " [-0.18613411 -0.23742545 -0.21723412 -0.20140961 -0.14699748 -0.2453084 ]]\n",
      "Episode:    710\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     205.0\n",
      "    Step:   556203\n",
      "    Q value:    0.05568999797105789\n",
      "    Loss:   0.0010098478524014354\n",
      "    Look-up table:\n",
      "[[-0.13985768 -0.09425019 -0.12782286 -0.12560432 -0.17616268 -0.08635861]\n",
      " [-0.14879823 -0.09874834 -0.13012193 -0.13640843 -0.18276586 -0.09268916]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 0.02960423  0.04116482 -0.01047918  0.0955883   0.05239391  0.13585845]\n",
      " [ 0.02852911  0.04047382 -0.01163352  0.09623066  0.05225337  0.134321  ]\n",
      " [-0.01910001 -0.00679131 -0.03296013  0.05107975 -0.00265329  0.08310451]]\n",
      "Episode:    720\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     198.75\n",
      "    Step:   564380\n",
      "    Q value:    -0.03400132805109024\n",
      "    Loss:   0.0027485075406730175\n",
      "    Look-up table:\n",
      "[[-0.17122597 -0.14388269 -0.16776751 -0.18101136 -0.16733617 -0.14382339]\n",
      " [-0.18132871 -0.15282416 -0.1774105  -0.19684832 -0.17592508 -0.15626392]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [-0.12862393 -0.09693417 -0.12478997 -0.02473377 -0.22594683 -0.1086213 ]\n",
      " [-0.12372324 -0.0964804  -0.12389015 -0.02390681 -0.22086631 -0.105515  ]\n",
      " [-0.17210495 -0.11094379 -0.25370294 -0.07699941 -0.25813866 -0.16700768]]\n",
      "Episode:    730\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     199.0\n",
      "    Step:   572543\n",
      "    Q value:    0.06581571698188782\n",
      "    Loss:   0.5727201104164124\n",
      "    Look-up table:\n",
      "[[-0.12432727 -0.11540772 -0.12672037 -0.12831904 -0.12793046 -0.10251111]\n",
      " [-0.13547131 -0.12568165 -0.13718364 -0.15430982 -0.14396474 -0.12575251]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [-0.05280989 -0.02505313 -0.02491137 -0.03863516 -0.06712399 -0.10363704]\n",
      " [-0.05245623 -0.02547093 -0.0255942  -0.03879322 -0.06641574 -0.10542533]\n",
      " [-0.15677142 -0.10597856 -0.12829611 -0.08408234 -0.13848613 -0.21314213]]\n",
      "Episode:    740\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     214.75\n",
      "    Step:   580641\n",
      "    Q value:    0.1069217100739479\n",
      "    Loss:   0.004909033887088299\n",
      "    Look-up table:\n",
      "[[-0.09857003 -0.12674834 -0.11568324 -0.10618229 -0.09068939 -0.09893692]\n",
      " [-0.11156215 -0.13893397 -0.12880774 -0.12509181 -0.10896236 -0.11832631]\n",
      " [-0.11772993 -0.14468406 -0.13550948 -0.13310455 -0.11752507 -0.12520966]\n",
      " ...\n",
      " [-0.16063423 -0.18476839 -0.18711044 -0.15635853 -0.22449832 -0.29540011]\n",
      " [-0.16066782 -0.18678717 -0.18877403 -0.15713875 -0.22426973 -0.2986522 ]\n",
      " [-0.21387349 -0.23546642 -0.25273716 -0.17288399 -0.24352916 -0.35958856]]\n",
      "Episode:    750\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     212.0\n",
      "    Step:   588231\n",
      "    Q value:    0.07148100435733795\n",
      "    Loss:   1.6655806303024292\n",
      "    Look-up table:\n",
      "[[-0.13717197 -0.17410585 -0.12769607 -0.11719838 -0.12068325 -0.10256436]\n",
      " [-0.15342383 -0.1920177  -0.14579722 -0.1381664  -0.13679329 -0.12109274]\n",
      " [-0.16301739 -0.19831158 -0.15261126 -0.14542253 -0.14172259 -0.12470078]\n",
      " ...\n",
      " [ 0.21720362  0.27918169  0.14677376  0.05537733  0.19945015  0.13421673]\n",
      " [ 0.21104437  0.27510095  0.14636292  0.05623139  0.19379304  0.13732818]\n",
      " [ 0.03828853  0.10333554 -0.0265096   0.00856516  0.02177015 -0.03544116]]\n",
      "Episode:    760\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     217.75\n",
      "    Step:   597005\n",
      "    Q value:    0.049632273614406586\n",
      "    Loss:   0.0012866929173469543\n",
      "    Look-up table:\n",
      "[[-0.2379051  -0.17132482 -0.16374218 -0.17165966 -0.13455327 -0.1125876 ]\n",
      " [-0.25765991 -0.17870462 -0.17126074 -0.19554754 -0.15089943 -0.13253978]\n",
      " [-0.277316   -0.18806316 -0.18024671 -0.21542601 -0.1747658  -0.15316644]\n",
      " ...\n",
      " [-0.14870529 -0.07038549 -0.13215682 -0.12804018 -0.00509097 -0.03995779]\n",
      " [-0.15281923 -0.07235485 -0.13390803 -0.13099749 -0.00861815 -0.043704  ]\n",
      " [-0.1855626  -0.07815897 -0.13417584 -0.11321987 -0.05554894 -0.06528899]]\n",
      "Episode:    770\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     188.25\n",
      "    Step:   603633\n",
      "    Q value:    0.07383564859628677\n",
      "    Loss:   0.010958975180983543\n",
      "    Look-up table:\n",
      "[[-0.22766635 -0.17744477 -0.16583312 -0.17681034 -0.14523633 -0.18338707]\n",
      " [-0.24057695 -0.18344365 -0.17095888 -0.18847309 -0.14782493 -0.18924311]\n",
      " [-0.25186172 -0.19067995 -0.1767152  -0.19892405 -0.15480806 -0.19670883]\n",
      " ...\n",
      " [ 0.11119074  0.2488611   0.13241829  0.14548744  0.14803967  0.21343443]\n",
      " [ 0.11504653  0.25540417  0.13687277  0.15488279  0.15557185  0.22353974]\n",
      " [ 0.04709697  0.18786308  0.07849821  0.0641076   0.02071765  0.0953473 ]]\n",
      "Episode:    780\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     131.0\n",
      "    Step:   611038\n",
      "    Q value:    0.04893660545349121\n",
      "    Loss:   1.2281596660614014\n",
      "    Look-up table:\n",
      "[[-0.12252481 -0.15897368 -0.18328288 -0.11864483 -0.22913633 -0.2871221 ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.15042867 -0.19119118 -0.21364033 -0.16400763 -0.29458612 -0.34282109]\n",
      " ...\n",
      " [ 0.0114565  -0.07106532 -0.00721601 -0.01444991  0.0507863   0.0485394 ]\n",
      " [ 0.00784434 -0.07502078 -0.00955901 -0.01933174  0.0454991   0.04228178]\n",
      " [-0.04963921 -0.10498591 -0.03449246 -0.02024838  0.00462446 -0.03830209]]\n",
      "Episode:    790\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     149.0\n",
      "    Step:   619175\n",
      "    Q value:    0.15939569473266602\n",
      "    Loss:   0.02048276551067829\n",
      "    Look-up table:\n",
      "[[-0.15020184 -0.16534202 -0.17790774 -0.12167841 -0.15893705 -0.2298108 ]\n",
      " [-0.16991015 -0.19036148 -0.20698223 -0.15026069 -0.20120375 -0.2842932 ]\n",
      " [-0.18988468 -0.21578111 -0.23026243 -0.17304865 -0.2342297  -0.32245466]\n",
      " ...\n",
      " [ 0.07666408  0.0836847   0.04762177  0.07263114  0.03274678  0.1333809 ]\n",
      " [ 0.0775748   0.08401226  0.04709744  0.07270592  0.03345166  0.13244218]\n",
      " [ 0.07560349  0.04753107 -0.00278419  0.07548766  0.01329771  0.05640262]]\n",
      "Episode:    800\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     192.25\n",
      "    Step:   627687\n",
      "    Q value:    0.02422315999865532\n",
      "    Loss:   0.001026910380460322\n",
      "    Look-up table:\n",
      "[[-0.2479614  -0.24416724 -0.32956621 -0.24501792 -0.2398538  -0.25688088]\n",
      " [-0.27784532 -0.26897463 -0.36539164 -0.29145771 -0.29288113 -0.31962717]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 0.05691816  0.03860201  0.00711086 -0.01733166  0.00967716  0.09055203]\n",
      " [ 0.0567008   0.03577287  0.00666821 -0.01396258  0.00560574  0.0906696 ]\n",
      " [ 0.04375072  0.02931072 -0.02454683 -0.01852708 -0.01082388  0.01886231]]\n",
      "Episode:    810\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     155.75\n",
      "    Step:   635271\n",
      "    Q value:    0.04565924406051636\n",
      "    Loss:   0.002249167300760746\n",
      "    Look-up table:\n",
      "[[-0.22707464 -0.24052313 -0.26625419 -0.24342376 -0.26285005 -0.20219281]\n",
      " [-0.24193807 -0.24942279 -0.2744047  -0.27598763 -0.30949736 -0.26931176]\n",
      " [-0.24215259 -0.24562556 -0.26680702 -0.2780813  -0.31148005 -0.27806148]\n",
      " ...\n",
      " [-0.0357316  -0.02748428 -0.04594451 -0.0728548  -0.11571217 -0.00804749]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.08294168 -0.06183861 -0.10164547 -0.09032397 -0.17915052 -0.09065977]]\n",
      "Episode:    820\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     139.75\n",
      "    Step:   644373\n",
      "    Q value:    0.06144697964191437\n",
      "    Loss:   1.7746778726577759\n",
      "    Look-up table:\n",
      "[[-0.22563732 -0.23403041 -0.19853523 -0.19941682 -0.15729064 -0.13460007]\n",
      " [-0.25193813 -0.24774142 -0.21503487 -0.24154654 -0.18979067 -0.16759351]\n",
      " [-0.26115379 -0.24644406 -0.21373537 -0.25458351 -0.19760209 -0.17507276]\n",
      " ...\n",
      " [ 0.05811918  0.02804504  0.06191076  0.02161931 -0.00769648  0.00051084]\n",
      " [ 0.05771959  0.02665739  0.05878446  0.02008267 -0.01161554  0.00087771]\n",
      " [ 0.03145105 -0.00871213 -0.02213937 -0.01621221 -0.04932922 -0.04267079]]\n",
      "Episode:    830\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     146.0\n",
      "    Step:   651298\n",
      "    Q value:    0.12898734211921692\n",
      "    Loss:   0.009660232812166214\n",
      "    Look-up table:\n",
      "[[-0.18704566 -0.19215721 -0.18764913 -0.19141564 -0.1773558  -0.19925016]\n",
      " [-0.2099203  -0.20610574 -0.20077685 -0.22750108 -0.20252201 -0.22566324]\n",
      " [-0.21309866 -0.20982718 -0.2016764  -0.23255961 -0.21795341 -0.23282254]\n",
      " ...\n",
      " [ 0.01243803  0.0045345  -0.00643921  0.02701285  0.09390473  0.07729474]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.05918443 -0.03873572 -0.07081583 -0.01897421  0.00446841 -0.02920172]]\n",
      "Episode:    840\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     131.75\n",
      "    Step:   658255\n",
      "    Q value:    0.1017361506819725\n",
      "    Loss:   0.0012960534077137709\n",
      "    Look-up table:\n",
      "[[-0.23621517 -0.24886307 -0.2099674  -0.34848189 -0.28037784 -0.22666454]\n",
      " [-0.24649653 -0.25334087 -0.21754488 -0.38047624 -0.30418399 -0.24912167]\n",
      " [-0.25173542 -0.26182643 -0.21577021 -0.37691939 -0.31888106 -0.24788308]\n",
      " ...\n",
      " [ 0.17599213  0.2032561   0.35218063  0.34884483  0.12894715  0.10144407]\n",
      " [ 0.18046629  0.2056915   0.3533724   0.35374814  0.13177276  0.1013162 ]\n",
      " [ 0.08033919  0.04982305  0.22460029  0.21004951  0.06349856  0.09249297]]\n",
      "Episode:    850\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     154.0\n",
      "    Step:   665802\n",
      "    Q value:    0.08408046513795853\n",
      "    Loss:   0.008858839981257915\n",
      "    Look-up table:\n",
      "[[-0.22216593 -0.29369652 -0.24781561 -0.23438051 -0.24274492 -0.25227588]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.22327332 -0.28976429 -0.25419223 -0.26245669 -0.28294551 -0.27351379]\n",
      " ...\n",
      " [ 0.03300816  0.0216644  -0.061315    0.0375313   0.03934646 -0.01542151]\n",
      " [ 0.02964514  0.02092649 -0.05858967  0.03012444  0.03874364 -0.01928979]\n",
      " [ 0.01528257 -0.02766994 -0.13961449  0.05892187 -0.04602492 -0.0855132 ]]\n",
      "Episode:    860\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     187.25\n",
      "    Step:   675631\n",
      "    Q value:    -0.006492052227258682\n",
      "    Loss:   0.000462151481769979\n",
      "    Look-up table:\n",
      "[[-0.25137329 -0.23075227 -0.25107461 -0.26355407 -0.21818092 -0.22119397]\n",
      " [-0.25631893 -0.23011287 -0.25114715 -0.27938828 -0.22561428 -0.22573382]\n",
      " [-0.25622433 -0.22693218 -0.24773836 -0.28434211 -0.22689039 -0.22495112]\n",
      " ...\n",
      " [-0.00271699  0.00550281 -0.00165319 -0.01017162  0.00633705 -0.04986128]\n",
      " [-0.00059383  0.00727393 -0.00039929 -0.00820944  0.00593996 -0.05183014]\n",
      " [-0.06358814 -0.03134453 -0.05806628  0.04640587 -0.08941978 -0.05562806]]\n",
      "Episode:    870\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     193.0\n",
      "    Step:   682967\n",
      "    Q value:    0.05611998587846756\n",
      "    Loss:   0.001532507361844182\n",
      "    Look-up table:\n",
      "[[-2.33632550e-01 -2.24463016e-01 -2.56862670e-01 -2.38512248e-01\n",
      "  -1.91379040e-01 -2.53876865e-01]\n",
      " [-2.40989044e-01 -2.30607748e-01 -2.65868783e-01 -2.49778748e-01\n",
      "  -1.95309728e-01 -2.62830496e-01]\n",
      " [-2.42175683e-01 -2.27310032e-01 -2.66484737e-01 -2.47736275e-01\n",
      "  -1.95271909e-01 -2.64722109e-01]\n",
      " ...\n",
      " [-7.55087733e-02 -2.50248760e-02 -1.50943995e-02 -1.16553724e-01\n",
      "  -1.41891837e-03  3.09066474e-02]\n",
      " [-7.35341311e-02 -2.34015286e-02 -1.34153962e-02 -1.15920573e-01\n",
      "  -1.44270062e-03  3.34687233e-02]\n",
      " [-4.75342572e-02 -7.36117363e-06 -1.62545145e-02 -7.25023448e-02\n",
      "  -2.38734186e-02 -1.79655850e-02]]\n",
      "Episode:    880\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     158.75\n",
      "    Step:   691574\n",
      "    Q value:    0.05676128342747688\n",
      "    Loss:   0.0014455011114478111\n",
      "    Look-up table:\n",
      "[[-0.14988682 -0.1697192  -0.18602446 -0.21700963 -0.13155499 -0.2747291 ]\n",
      " [-0.15339983 -0.17183851 -0.19235992 -0.22951594 -0.13442698 -0.28466091]\n",
      " [-0.14683148 -0.16242059 -0.18471965 -0.22543937 -0.12899545 -0.27979067]\n",
      " ...\n",
      " [ 0.00373523 -0.02227964 -0.05570185  0.00643504  0.01255113 -0.01323491]\n",
      " [ 0.00214085 -0.02487694 -0.05875489  0.00456566  0.01095709 -0.01532185]\n",
      " [-0.03374428 -0.0123149  -0.0709646  -0.04010543 -0.01735508 -0.10221151]]\n",
      "Episode:    890\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     159.75\n",
      "    Step:   699225\n",
      "    Q value:    0.04226323962211609\n",
      "    Loss:   0.010517154820263386\n",
      "    Look-up table:\n",
      "[[-0.22355253 -0.24109462 -0.26579267 -0.25539908 -0.25074559 -0.29293779]\n",
      " [-0.21072239 -0.23435101 -0.26017994 -0.24036375 -0.2354694  -0.28204957]\n",
      " [-0.20306791 -0.22510023 -0.25658026 -0.22729594 -0.22425666 -0.27448699]\n",
      " ...\n",
      " [ 0.02323577  0.0262606  -0.06007847 -0.01382104  0.07042199  0.03570357]\n",
      " [ 0.0236063   0.0260409  -0.05899614 -0.0129737   0.06965287  0.03744808]\n",
      " [ 0.02344367  0.02271663 -0.07302719 -0.00986382  0.06032145  0.00847352]]\n",
      "Episode:    900\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     153.75\n",
      "    Step:   706050\n",
      "    Q value:    0.09704500436782837\n",
      "    Loss:   0.592605471611023\n",
      "    Look-up table:\n",
      "[[-0.24771836 -0.27211374 -0.34658945 -0.2624419  -0.26434261 -0.26030728]\n",
      " [-0.23913771 -0.26504809 -0.33992755 -0.25150746 -0.25669408 -0.25382727]\n",
      " [-0.23310873 -0.26009178 -0.33422089 -0.24407792 -0.25087094 -0.24886292]\n",
      " ...\n",
      " [ 0.03175765  0.01771152  0.05414742  0.02353618  0.00603759  0.09239009]\n",
      " [ 0.03307144  0.01814526  0.05631939  0.02679791  0.00486514  0.09373391]\n",
      " [-0.03096253 -0.0458729  -0.06571612 -0.02334785 -0.04318854 -0.01681155]]\n",
      "Episode:    910\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     131.5\n",
      "    Step:   711771\n",
      "    Q value:    -0.008368742652237415\n",
      "    Loss:   0.0013378460425883532\n",
      "    Look-up table:\n",
      "[[-0.27522197 -0.2717433  -0.29503644 -0.24274269 -0.32134086 -0.25093612]\n",
      " [-0.25736025 -0.25610101 -0.27555466 -0.22791752 -0.3003673  -0.23487231]\n",
      " [-0.251948   -0.25049767 -0.26792586 -0.22470251 -0.29442182 -0.2302523 ]\n",
      " ...\n",
      " [ 0.08074801  0.11430234  0.06765306  0.13035533  0.12082604  0.09667392]\n",
      " [ 0.07781054  0.11390329  0.06530005  0.12933135  0.11723281  0.09312755]\n",
      " [ 0.03947175  0.09642892  0.02761097  0.14150146  0.04553454  0.03559875]]\n",
      "Episode:    920\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     148.0\n",
      "    Step:   719283\n",
      "    Q value:    -0.0035039810463786125\n",
      "    Loss:   0.001775553566403687\n",
      "    Look-up table:\n",
      "[[-0.25173116 -0.18920457 -0.31325197 -0.30060309 -0.26241195 -0.27930203]\n",
      " [-0.24124184 -0.18853062 -0.3081609  -0.2932688  -0.25620401 -0.27963504]\n",
      " [-0.23644441 -0.18683609 -0.30488747 -0.28643781 -0.25201952 -0.27746227]\n",
      " ...\n",
      " [-0.08343875 -0.14086033 -0.13288713 -0.18583471 -0.09798256 -0.11011612]\n",
      " [-0.08411598 -0.14136349 -0.13336176 -0.18660688 -0.0990172  -0.1111778 ]\n",
      " [-0.12715837 -0.18828981 -0.16157436 -0.18681484 -0.13657528 -0.20954174]]\n",
      "Episode:    930\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     199.75\n",
      "    Step:   727600\n",
      "    Q value:    0.04831923544406891\n",
      "    Loss:   0.0008306792005896568\n",
      "    Look-up table:\n",
      "[[-0.24853677 -0.23583126 -0.32250339 -0.24174061 -0.1987716  -0.22933498]\n",
      " [-0.24227929 -0.23098756 -0.31386486 -0.23751831 -0.19963989 -0.23296332]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [-0.24323347 -0.11579359 -0.19194341 -0.18155333 -0.18882835 -0.1448493 ]\n",
      " [-0.2425079  -0.11527079 -0.19068083 -0.18008447 -0.19035172 -0.14588261]\n",
      " [-0.30495766 -0.17750046 -0.28839037 -0.21218115 -0.20154735 -0.21908578]]\n",
      "Episode:    940\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     206.25\n",
      "    Step:   735065\n",
      "    Q value:    0.2642551064491272\n",
      "    Loss:   0.008501208387315273\n",
      "    Look-up table:\n",
      "[[-0.284255   -0.25757182 -0.2359513  -0.31525645 -0.25558543 -0.24238846]\n",
      " [-0.27888271 -0.255822   -0.22743964 -0.31696931 -0.25142741 -0.24079821]\n",
      " [-0.27169219 -0.25261945 -0.21942502 -0.31495544 -0.24624461 -0.23693809]\n",
      " ...\n",
      " [ 0.1195814   0.0196061   0.10900959  0.06870227  0.07469591  0.03701892]\n",
      " [ 0.11884613  0.02042097  0.11009754  0.06910828  0.07416782  0.03709549]\n",
      " [ 0.07873437 -0.01075757  0.07083942  0.06924219  0.063357    0.00725162]]\n",
      "Episode:    950\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     214.75\n",
      "    Step:   744943\n",
      "    Q value:    0.011945053935050964\n",
      "    Loss:   0.5931071639060974\n",
      "    Look-up table:\n",
      "[[-0.20635858 -0.22578716 -0.25470638 -0.24900764 -0.19509581 -0.18339825]\n",
      " [-0.20372608 -0.2211083  -0.24951333 -0.24611023 -0.19950479 -0.18687484]\n",
      " [-0.19496325 -0.20877756 -0.23540014 -0.23768398 -0.19595629 -0.18136159]\n",
      " ...\n",
      " [-0.15510955 -0.10814124 -0.10324892 -0.10390857 -0.16569951 -0.1120041 ]\n",
      " [-0.1555064  -0.10786515 -0.10233691 -0.10457668 -0.16748783 -0.11384213]\n",
      " [-0.21401119 -0.18783078 -0.19788501 -0.18610883 -0.20695016 -0.2075597 ]]\n",
      "Episode:    960\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     225.75\n",
      "    Step:   753305\n",
      "    Q value:    0.1469581425189972\n",
      "    Loss:   0.0014687450602650642\n",
      "    Look-up table:\n",
      "[[-0.19115886 -0.23427203 -0.29060361 -0.22698247 -0.22237745 -0.27963123]\n",
      " [-0.19275045 -0.23675856 -0.29318288 -0.23097527 -0.22999462 -0.28679439]\n",
      " [-0.18873131 -0.2318683  -0.28745022 -0.2271148  -0.22694436 -0.28246889]\n",
      " ...\n",
      " [ 0.04134202  0.05870244  0.03468516  0.03363675  0.00461331  0.0031836 ]\n",
      " [ 0.04265289  0.05971962  0.03591314  0.03533213  0.00669476  0.0053634 ]\n",
      " [-0.02147952  0.02012426 -0.04466766  0.00320873 -0.07242897 -0.06954297]]\n",
      "Episode:    970\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     210.25\n",
      "    Step:   762572\n",
      "    Q value:    0.049481626600027084\n",
      "    Loss:   2.4472649097442627\n",
      "    Look-up table:\n",
      "[[-0.2000843  -0.20145492 -0.24079883 -0.25150838 -0.23872614 -0.1946075 ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.20265323 -0.20352219 -0.24460542 -0.25804731 -0.25387365 -0.2062763 ]\n",
      " ...\n",
      " [-0.0469678  -0.08612712 -0.03620198 -0.05726469  0.03480449 -0.00326341]\n",
      " [-0.04882501 -0.08909759 -0.03668886 -0.05895323  0.0337272  -0.00468948]\n",
      " [-0.11906339 -0.12116137 -0.08904442 -0.10367277 -0.05197573 -0.07168248]]\n",
      "Episode:    980\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     199.5\n",
      "    Step:   770628\n",
      "    Q value:    0.03999058157205582\n",
      "    Loss:   0.8991179466247559\n",
      "    Look-up table:\n",
      "[[-0.196684   -0.27777547 -0.2632876  -0.28110391 -0.25667509 -0.28909636]\n",
      " [-0.20113042 -0.27374679 -0.26421994 -0.27838492 -0.25657812 -0.29271638]\n",
      " [-0.19948158 -0.26995301 -0.26102155 -0.27713203 -0.25669017 -0.29158229]\n",
      " ...\n",
      " [-0.01327318 -0.057659   -0.05094612 -0.03029123 -0.07113957 -0.08085379]\n",
      " [-0.01315388 -0.05778652 -0.05040234 -0.02967024 -0.06968576 -0.07997784]\n",
      " [-0.05318391 -0.10353878 -0.09226328 -0.06670484 -0.1000458  -0.09185624]]\n",
      "Episode:    990\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     160.5\n",
      "    Step:   779138\n",
      "    Q value:    -0.0033631883561611176\n",
      "    Loss:   0.012816333211958408\n",
      "    Look-up table:\n",
      "[[-0.182181   -0.24363133 -0.1970048  -0.22226733 -0.18641296 -0.20477626]\n",
      " [-0.19751665 -0.23495904 -0.19240782 -0.22769415 -0.18901867 -0.20694813]\n",
      " [-0.20364392 -0.22996777 -0.18917248 -0.22836488 -0.18880305 -0.20670524]\n",
      " ...\n",
      " [-0.20627522 -0.16104546 -0.13647267 -0.17996922 -0.18163085 -0.21524826]\n",
      " [-0.2019133  -0.15772125 -0.13426521 -0.17664954 -0.18018696 -0.21215013]\n",
      " [-0.24461913 -0.20693508 -0.19230315 -0.27142486 -0.25437695 -0.28533074]]\n",
      "Episode:    1000\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     156.75\n",
      "    Step:   786682\n",
      "    Q value:    0.08313597738742828\n",
      "    Loss:   0.0010739493882283568\n",
      "    Look-up table:\n",
      "[[-0.25452763 -0.20482028 -0.29364243 -0.19767898 -0.21291831 -0.21498072]\n",
      " [-0.26350838 -0.20532486 -0.29612258 -0.21029261 -0.22677812 -0.22259808]\n",
      " [-0.26765829 -0.20676818 -0.29879549 -0.21692076 -0.23378643 -0.22622973]\n",
      " ...\n",
      " [ 0.00818759 -0.05712536 -0.02804428 -0.02735677 -0.06341115 -0.02161643]\n",
      " [ 0.00904876 -0.0559355  -0.02634802 -0.02540964 -0.06199801 -0.02262038]\n",
      " [-0.10904774 -0.14440873 -0.19977075 -0.13814095 -0.17893705 -0.18299383]]\n",
      "Training finished at 1000 episodes!\n",
      "    Final epsilon:  0.05\n",
      "    Final Rolling avg. 20 reward:   156.75\n",
      "    Final look-up table\n",
      "[[-0.25452763 -0.20482028 -0.29364243 -0.19767898 -0.21291831 -0.21498072]\n",
      " [-0.26350838 -0.20532486 -0.29612258 -0.21029261 -0.22677812 -0.22259808]\n",
      " [-0.26765829 -0.20676818 -0.29879549 -0.21692076 -0.23378643 -0.22622973]\n",
      " ...\n",
      " [ 0.00818759 -0.05712536 -0.02804428 -0.02735677 -0.06341115 -0.02161643]\n",
      " [ 0.00904876 -0.0559355  -0.02634802 -0.02540964 -0.06199801 -0.02262038]\n",
      " [-0.10904774 -0.14440873 -0.19977075 -0.13814095 -0.17893705 -0.18299383]]\n",
      "\u001B[32m[I 2022-06-07 04:26:16,293]\u001B[0m Trial 1 finished with value: 156.75 and parameters: {'exploration_rate_decay': 0.999975, 'exploration_rate_min': 0.05, 'batch_size': 16, 'gamma': 0.93, 'lr': 0.00030000000000000003, 'learn_every': 5, 'sync_every': 15000}. Best is trial 0 with value: 209.0.\u001B[0m\n",
      "Current Params:\n",
      "    exploration_rate_decay: 0.999975\n",
      "    exploration_rate_min: 0.05\n",
      "    batch_size: 48\n",
      "    gamma: 0.93\n",
      "    lr: 0.0009000000000000001\n",
      "    learn_every: 4\n",
      "    sync_every: 5000\n",
      "\n",
      "Episode:    10\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8410937395917899\n",
      "    Rolling avg. 20 reward:     168.0\n",
      "    Step:   6922\n",
      "    Q value:    None\n",
      "    Loss:   0\n",
      "    Look-up table:\n",
      "[[ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.01777036  0.01692564 -0.03257204  0.03734555 -0.02439554  0.03353534]]\n",
      "Episode:    20\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.7241881578572497\n",
      "    Rolling avg. 20 reward:     141.0\n",
      "    Step:   12908\n",
      "    Q value:    0.03285916894674301\n",
      "    Loss:   4.803195406566374e-05\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [0.03962401 0.0325871  0.0155636  0.03096328 0.02638139 0.04426099]\n",
      " [0.03962401 0.0325871  0.0155636  0.03096328 0.02638139 0.04426099]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    30\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.6181457469049321\n",
      "    Rolling avg. 20 reward:     138.75\n",
      "    Step:   19241\n",
      "    Q value:    0.046159546822309494\n",
      "    Loss:   0.09339704364538193\n",
      "    Look-up table:\n",
      "[[0.05414613 0.03806298 0.03719524 0.03043323 0.02965461 0.02923061]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [0.05374689 0.03783413 0.05065204 0.04051735 0.03623428 0.03854273]\n",
      " [0.05374689 0.03783413 0.05065204 0.04051735 0.03623428 0.03854273]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    40\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.530912574453962\n",
      "    Rolling avg. 20 reward:     148.0\n",
      "    Step:   25326\n",
      "    Q value:    0.06521885842084885\n",
      "    Loss:   3.950377140427008e-05\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [0.04115204 0.04699036 0.04733212 0.05003228 0.05338092 0.05705773]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [0.0667137  0.07099187 0.05237405 0.06648965 0.06428667 0.06467507]\n",
      " [0.06676672 0.07077555 0.05242597 0.06642033 0.06419584 0.06430133]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    50\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.4320731010967548\n",
      "    Rolling avg. 20 reward:     173.0\n",
      "    Step:   33566\n",
      "    Q value:    0.07645836472511292\n",
      "    Loss:   0.3018092215061188\n",
      "    Look-up table:\n",
      "[[0.0672634  0.07200179 0.07256304 0.05894943 0.07747757 0.07890655]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.0672634  0.07200179 0.07256304 0.05894943 0.07747757 0.07890655]\n",
      " ...\n",
      " [0.07464107 0.08097869 0.07968245 0.05930352 0.06568374 0.06986906]\n",
      " [0.07449719 0.08134683 0.07972323 0.05937922 0.06563087 0.06967277]\n",
      " [0.07449719 0.08134683 0.07972323 0.05937922 0.06563087 0.06967277]]\n",
      "Episode:    60\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.36413244121707516\n",
      "    Rolling avg. 20 reward:     177.75\n",
      "    Step:   40409\n",
      "    Q value:    0.08753043413162231\n",
      "    Loss:   0.0932956263422966\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [0.09185661 0.08605698 0.0786421  0.07790336 0.0747492  0.0964074 ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [0.10332762 0.08567341 0.07618193 0.08672322 0.07842849 0.08639564]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.10369664 0.08563529 0.07619981 0.08680555 0.07844383 0.08633528]]\n",
      "Episode:    70\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.3019964650481076\n",
      "    Rolling avg. 20 reward:     152.5\n",
      "    Step:   47893\n",
      "    Q value:    0.09206636995077133\n",
      "    Loss:   0.19763073325157166\n",
      "    Look-up table:\n",
      "[[0.07755537 0.09004311 0.07637744 0.09035396 0.08882063 0.07649256]\n",
      " [0.07755537 0.09004311 0.07637744 0.09035396 0.08882063 0.07649256]\n",
      " [0.0775093  0.09030002 0.07634158 0.09011225 0.08834577 0.07646003]\n",
      " ...\n",
      " [0.07782833 0.09957597 0.07753373 0.09799531 0.08660356 0.09783128]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.07782677 0.09918121 0.07753488 0.09794462 0.0863914  0.09821818]]\n",
      "Episode:    80\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.2524247213203089\n",
      "    Rolling avg. 20 reward:     141.5\n",
      "    Step:   55065\n",
      "    Q value:    0.09059885144233704\n",
      "    Loss:   3.3861979318317026e-05\n",
      "    Look-up table:\n",
      "[[0.07561906 0.0759209  0.0822651  0.08286274 0.07437727 0.08337024]\n",
      " [0.07561906 0.0759209  0.0822651  0.08286274 0.07437727 0.08337024]\n",
      " [0.07581257 0.07620674 0.0820368  0.08269802 0.07436597 0.08352753]\n",
      " ...\n",
      " [0.09102064 0.07729744 0.07469583 0.095228   0.07435761 0.07942015]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.0912089  0.07739767 0.07477868 0.09535602 0.07441609 0.0794903 ]]\n",
      "Episode:    90\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.19960394658323796\n",
      "    Rolling avg. 20 reward:     167.25\n",
      "    Step:   64456\n",
      "    Q value:    0.08445152640342712\n",
      "    Loss:   0.00016115843027364463\n",
      "    Look-up table:\n",
      "[[0.06883389 0.09509251 0.06967717 0.06917562 0.08261207 0.07095186]\n",
      " [0.06883389 0.09509251 0.06967717 0.06917562 0.08261207 0.07095186]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [0.0686958  0.08849934 0.06916913 0.06885033 0.0770708  0.06818219]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    100\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15820350814533796\n",
      "    Rolling avg. 20 reward:     220.5\n",
      "    Step:   73754\n",
      "    Q value:    0.08871021121740341\n",
      "    Loss:   0.7076548337936401\n",
      "    Look-up table:\n",
      "[[0.08183158 0.10810141 0.08678232 0.08422397 0.08292717 0.08432683]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.08183158 0.10810141 0.08678232 0.08422397 0.08292717 0.08432683]\n",
      " ...\n",
      " [0.07170694 0.09075388 0.07945603 0.07394035 0.07438209 0.07546633]\n",
      " [0.07169128 0.09128237 0.07967711 0.07391666 0.07437029 0.07544915]\n",
      " [0.07169128 0.09128237 0.07967711 0.07391666 0.07437029 0.07544915]]\n",
      "Episode:    110\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.12579195164007925\n",
      "    Rolling avg. 20 reward:     210.0\n",
      "    Step:   82924\n",
      "    Q value:    0.08275596797466278\n",
      "    Loss:   0.29091334342956543\n",
      "    Look-up table:\n",
      "[[0.07336976 0.0799519  0.09822072 0.06804156 0.07807524 0.07612411]\n",
      " [0.07336976 0.0799519  0.09822072 0.06804156 0.07807524 0.07612411]\n",
      " [0.07336976 0.0799519  0.09822072 0.06804156 0.07807524 0.07612411]\n",
      " ...\n",
      " [0.0663301  0.06859104 0.08763982 0.06760877 0.07283962 0.07848789]\n",
      " [0.0663301  0.06859104 0.08763982 0.06760877 0.07283962 0.07848789]\n",
      " [0.0663301  0.06859104 0.08763982 0.06760877 0.07283962 0.07848789]]\n",
      "Episode:    120\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.10046672264914494\n",
      "    Rolling avg. 20 reward:     195.5\n",
      "    Step:   91916\n",
      "    Q value:    0.06479191035032272\n",
      "    Loss:   6.26461987849325e-05\n",
      "    Look-up table:\n",
      "[[0.06320459 0.07140011 0.06308056 0.06381062 0.11307242 0.06157995]\n",
      " [0.06320459 0.07140011 0.06308056 0.06381062 0.11307242 0.06157995]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [0.05857151 0.05780798 0.06032571 0.05609803 0.06078205 0.0715315 ]\n",
      " [0.05857151 0.05780798 0.06032571 0.05609803 0.06078205 0.0715315 ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    130\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.07975812915015533\n",
      "    Rolling avg. 20 reward:     215.75\n",
      "    Step:   101149\n",
      "    Q value:    0.08919711410999298\n",
      "    Loss:   0.00024398494861088693\n",
      "    Look-up table:\n",
      "[[0.09670518 0.07789937 0.07603852 0.09847054 0.09566789 0.10726204]\n",
      " [0.09670518 0.07789937 0.07603852 0.09847054 0.09566789 0.10726204]\n",
      " [0.09670518 0.07789937 0.07603852 0.09847054 0.09566789 0.10726204]\n",
      " ...\n",
      " [0.08880126 0.09348614 0.0772585  0.08100868 0.08377287 0.09128273]\n",
      " [0.08880126 0.09348614 0.0772585  0.08100868 0.08377287 0.09128273]\n",
      " [0.08779258 0.093915   0.07726775 0.08092804 0.08376753 0.09078813]]\n",
      "Episode:    140\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.06464243235639149\n",
      "    Rolling avg. 20 reward:     245.0\n",
      "    Step:   109554\n",
      "    Q value:    0.10235290229320526\n",
      "    Loss:   0.30170130729675293\n",
      "    Look-up table:\n",
      "[[0.07807553 0.07860745 0.08818875 0.07233029 0.08718511 0.08626123]\n",
      " [0.07779943 0.07860401 0.08842431 0.0724996  0.08723654 0.08618893]\n",
      " [0.07779943 0.07860401 0.08842431 0.0724996  0.08723654 0.08618893]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.09202784 0.07887634 0.08231001 0.08024226 0.11496063 0.08157524]\n",
      " [0.09202784 0.07887634 0.08231001 0.08024226 0.11496063 0.08157524]]\n",
      "Episode:    150\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05253441350759554\n",
      "    Rolling avg. 20 reward:     238.75\n",
      "    Step:   117850\n",
      "    Q value:    0.08896549791097641\n",
      "    Loss:   0.00018053961684927344\n",
      "    Look-up table:\n",
      "[[0.07846262 0.10172936 0.07720411 0.07480007 0.08016443 0.08183254]\n",
      " [0.07845199 0.10166072 0.07719307 0.07476874 0.08015988 0.0817275 ]\n",
      " [0.07845199 0.10166072 0.07719307 0.07476874 0.08015988 0.0817275 ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.0737389  0.09304273 0.07480768 0.07301462 0.07936284 0.08040596]\n",
      " [0.0737389  0.09304273 0.07480768 0.07301462 0.07936284 0.08040596]]\n",
      "Episode:    160\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     238.25\n",
      "    Step:   127763\n",
      "    Q value:    0.11418601125478745\n",
      "    Loss:   9.100851457333192e-05\n",
      "    Look-up table:\n",
      "[[0.08419517 0.08558888 0.09251095 0.0857014  0.08993874 0.09330028]\n",
      " [0.08419517 0.08558888 0.09251095 0.0857014  0.08993874 0.09330028]\n",
      " [0.08419517 0.08558888 0.09251095 0.0857014  0.08993874 0.09330028]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.11215229 0.0886133  0.10618901 0.09094831 0.08974317 0.11674735]\n",
      " [0.11215229 0.0886133  0.10618901 0.09094831 0.08974317 0.11674735]]\n",
      "Episode:    170\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     232.5\n",
      "    Step:   136562\n",
      "    Q value:    0.11451166868209839\n",
      "    Loss:   0.00013667310122400522\n",
      "    Look-up table:\n",
      "[[0.09863786 0.09753704 0.09774338 0.0978779  0.09596036 0.11202271]\n",
      " [0.09863786 0.09753704 0.09774338 0.0978779  0.09596036 0.11202271]\n",
      " [0.09863783 0.09754642 0.09774872 0.09788174 0.09596193 0.11187941]\n",
      " ...\n",
      " [0.09790406 0.09725351 0.10610608 0.09703256 0.09610985 0.11701063]\n",
      " [0.09790544 0.09725579 0.10575871 0.09704451 0.09611093 0.11695696]\n",
      " [0.09790544 0.09725579 0.10575871 0.09704451 0.09611093 0.11695696]]\n",
      "Episode:    180\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     215.5\n",
      "    Step:   146038\n",
      "    Q value:    0.12783925235271454\n",
      "    Loss:   8.204096229746938e-05\n",
      "    Look-up table:\n",
      "[[0.12100656 0.13602719 0.10133743 0.11645505 0.09938122 0.10721831]\n",
      " [0.12100656 0.13602719 0.10133743 0.11645505 0.09938122 0.10721831]\n",
      " [0.12146625 0.13575485 0.10143572 0.11642988 0.09941555 0.10730009]\n",
      " ...\n",
      " [0.11549953 0.12876163 0.11392266 0.11564472 0.10470406 0.11086609]\n",
      " [0.11550055 0.12846613 0.11393537 0.11564383 0.10471874 0.11086946]\n",
      " [0.11550055 0.12846613 0.11393537 0.11564383 0.10471874 0.11086946]]\n",
      "Episode:    190\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     215.5\n",
      "    Step:   154246\n",
      "    Q value:    0.12746551632881165\n",
      "    Loss:   0.0002703175996430218\n",
      "    Look-up table:\n",
      "[[0.10506261 0.10699986 0.10410391 0.10322873 0.12441602 0.1031855 ]\n",
      " [0.10506277 0.10695308 0.10414824 0.10323213 0.12461628 0.10319266]\n",
      " [0.10506277 0.10695308 0.10414824 0.10323213 0.12461628 0.10319266]\n",
      " ...\n",
      " [0.10508098 0.10521268 0.10481099 0.10379465 0.1294885  0.10406525]\n",
      " [0.10508098 0.10521253 0.10481234 0.10379755 0.12947166 0.10406741]\n",
      " [0.10508098 0.10521253 0.10481234 0.10379755 0.12947166 0.10406741]]\n",
      "Episode:    200\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     269.25\n",
      "    Step:   164671\n",
      "    Q value:    0.13424500823020935\n",
      "    Loss:   1.9812687241937965e-05\n",
      "    Look-up table:\n",
      "[[0.1341068  0.12500714 0.11823052 0.12553114 0.1442319  0.12609392]\n",
      " [0.13409838 0.12502123 0.1183291  0.12553607 0.14450806 0.12611088]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [0.12932445 0.1237765  0.12587646 0.12896831 0.13693184 0.12538525]\n",
      " [0.12932445 0.1237765  0.12587646 0.12896831 0.13693184 0.12538525]\n",
      " [0.12932445 0.1237765  0.12587646 0.12896831 0.13693184 0.12538525]]\n",
      "Episode:    210\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     284.25\n",
      "    Step:   174419\n",
      "    Q value:    0.1413910984992981\n",
      "    Loss:   9.717216016724706e-05\n",
      "    Look-up table:\n",
      "[[0.12805073 0.12730113 0.12927179 0.12546426 0.1258416  0.14145534]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.12805073 0.12730113 0.12927179 0.12546426 0.1258416  0.14145534]\n",
      " ...\n",
      " [0.12792638 0.12766027 0.12890919 0.1207255  0.12615302 0.14196607]\n",
      " [0.12792638 0.12766027 0.12890919 0.1207255  0.12615302 0.14196607]\n",
      " [0.12792638 0.12766027 0.12890919 0.1207255  0.12615302 0.14196607]]\n",
      "Episode:    220\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     246.5\n",
      "    Step:   182388\n",
      "    Q value:    0.14570283889770508\n",
      "    Loss:   0.4060206115245819\n",
      "    Look-up table:\n",
      "[[0.12640627 0.12817997 0.12512219 0.12342773 0.15002082 0.13426571]\n",
      " [0.12640627 0.12817997 0.12512219 0.12342773 0.15002082 0.13426571]\n",
      " [0.1264168  0.12818    0.12514763 0.12343706 0.15036428 0.13418528]\n",
      " ...\n",
      " [0.12802298 0.12818088 0.12773137 0.12630543 0.14691615 0.13319556]\n",
      " [0.12802298 0.12818088 0.12773137 0.12630543 0.14691615 0.13319556]\n",
      " [0.12802298 0.12818088 0.12773137 0.12630543 0.14691615 0.13319556]]\n",
      "Episode:    230\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     240.75\n",
      "    Step:   190488\n",
      "    Q value:    0.1666959971189499\n",
      "    Loss:   0.40592873096466064\n",
      "    Look-up table:\n",
      "[[0.13149802 0.12184343 0.13354908 0.13111004 0.14377737 0.13462195]\n",
      " [0.13149802 0.12184343 0.13354908 0.13111004 0.14377737 0.13462195]\n",
      " [0.13149802 0.12184343 0.13354908 0.13111004 0.14377737 0.13462195]\n",
      " ...\n",
      " [0.14655606 0.1622923  0.14686254 0.14777941 0.1754338  0.14777628]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.14655606 0.1622923  0.14686254 0.14777941 0.1754338  0.14777628]]\n",
      "Episode:    240\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     230.0\n",
      "    Step:   199520\n",
      "    Q value:    0.15468885004520416\n",
      "    Loss:   0.00013201218098402023\n",
      "    Look-up table:\n",
      "[[0.14193963 0.16232364 0.15208684 0.15674323 0.147145   0.14595458]\n",
      " [0.14193963 0.16232364 0.15208684 0.15674323 0.147145   0.14595458]\n",
      " [0.14193963 0.16232364 0.15208684 0.15674323 0.147145   0.14595458]\n",
      " ...\n",
      " [0.13964456 0.15725487 0.1402224  0.14809133 0.14841564 0.14074244]\n",
      " [0.13964456 0.15725487 0.1402224  0.14809133 0.14841564 0.14074244]\n",
      " [0.13964456 0.15725487 0.1402224  0.14809133 0.14841564 0.14074244]]\n",
      "Episode:    250\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     251.75\n",
      "    Step:   208335\n",
      "    Q value:    0.15093177556991577\n",
      "    Loss:   0.00029257594724185765\n",
      "    Look-up table:\n",
      "[[0.14267527 0.14259359 0.14257197 0.14213581 0.17268257 0.14267518]\n",
      " [0.14267527 0.14259374 0.1425726  0.14213856 0.17227018 0.14267518]\n",
      " [0.14267527 0.14259374 0.1425726  0.14213856 0.17227018 0.14267518]\n",
      " ...\n",
      " [0.12863123 0.14129393 0.13537486 0.13022035 0.14990714 0.15151496]\n",
      " [0.12863123 0.14129393 0.13537486 0.13022035 0.14990714 0.15151496]\n",
      " [0.12863123 0.14129393 0.13537486 0.13022035 0.14990714 0.15151496]]\n",
      "Episode:    260\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     284.25\n",
      "    Step:   218244\n",
      "    Q value:    0.1502464860677719\n",
      "    Loss:   1.1136983633041382\n",
      "    Look-up table:\n",
      "[[0.13466461 0.14997578 0.13250363 0.13450404 0.13117103 0.13073316]\n",
      " [0.13466461 0.14987235 0.13251072 0.13450459 0.13117327 0.13073508]\n",
      " [0.13466461 0.14987235 0.13251072 0.13450459 0.13117327 0.13073508]\n",
      " ...\n",
      " [0.13462619 0.15058081 0.13353419 0.13453294 0.13214986 0.1316274 ]\n",
      " [0.13462619 0.15058081 0.13353419 0.13453294 0.13214986 0.1316274 ]\n",
      " [0.13462619 0.15058081 0.13353419 0.13453294 0.13214986 0.1316274 ]]\n",
      "Episode:    270\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     267.5\n",
      "    Step:   226939\n",
      "    Q value:    0.150798037648201\n",
      "    Loss:   0.19767002761363983\n",
      "    Look-up table:\n",
      "[[0.12564902 0.1275295  0.13183834 0.1252     0.13272409 0.12663758]\n",
      " [0.12564902 0.1275295  0.13183834 0.1252     0.13272409 0.12663758]\n",
      " [0.12564902 0.1275295  0.13183834 0.1252     0.13272409 0.12663758]\n",
      " ...\n",
      " [0.12765141 0.1530979  0.12913686 0.12801242 0.1370813  0.12759314]\n",
      " [0.12765141 0.1530979  0.12913686 0.12801242 0.1370813  0.12759314]\n",
      " [0.12765141 0.1530979  0.12913686 0.12801242 0.1370813  0.12759314]]\n",
      "Episode:    280\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     228.25\n",
      "    Step:   235453\n",
      "    Q value:    0.1770368069410324\n",
      "    Loss:   0.7077311873435974\n",
      "    Look-up table:\n",
      "[[0.13323046 0.13215883 0.13356841 0.13547295 0.15542102 0.13302529]\n",
      " [0.13323046 0.13215883 0.13356841 0.13547295 0.15542102 0.13302529]\n",
      " [0.13323046 0.13215883 0.13356841 0.13547295 0.15542102 0.13302529]\n",
      " ...\n",
      " [0.16937508 0.13329414 0.13833658 0.13776937 0.17736992 0.14202955]\n",
      " [0.16937508 0.13329414 0.13833658 0.13776937 0.17736992 0.14202955]\n",
      " [0.17052196 0.13330269 0.13834979 0.13778175 0.17711148 0.1420489 ]]\n",
      "Episode:    290\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     207.75\n",
      "    Step:   244555\n",
      "    Q value:    0.14602917432785034\n",
      "    Loss:   0.0002575870312284678\n",
      "    Look-up table:\n",
      "[[0.13871518 0.12388212 0.12315637 0.12375331 0.14450993 0.13639979]\n",
      " [0.13871518 0.12388212 0.12315637 0.12375331 0.14450993 0.13639979]\n",
      " [0.13903321 0.12388359 0.12316898 0.12376359 0.14454727 0.13640203]\n",
      " ...\n",
      " [0.1355879  0.12302057 0.1227771  0.1217813  0.14970867 0.13339229]\n",
      " [0.1355879  0.12302057 0.1227771  0.1217813  0.14970867 0.13339229]\n",
      " [0.1355879  0.12302057 0.1227771  0.1217813  0.14970867 0.13339229]]\n",
      "Episode:    300\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     250.75\n",
      "    Step:   255162\n",
      "    Q value:    0.16175560653209686\n",
      "    Loss:   0.00033622607588768005\n",
      "    Look-up table:\n",
      "[[0.12966754 0.1380726  0.12790065 0.12819259 0.13999772 0.12944785]\n",
      " [0.12966754 0.1380726  0.12790065 0.12819259 0.13999772 0.12944785]\n",
      " [0.12966754 0.1380726  0.12790065 0.12819259 0.13999772 0.12944785]\n",
      " ...\n",
      " [0.14890201 0.16667825 0.12739044 0.15782258 0.14532432 0.12905657]\n",
      " [0.1489346  0.16666666 0.12740196 0.15723628 0.14529331 0.12907924]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    310\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     252.25\n",
      "    Step:   263752\n",
      "    Q value:    0.14490261673927307\n",
      "    Loss:   4.164983329246752e-05\n",
      "    Look-up table:\n",
      "[[0.13226846 0.15090376 0.13183342 0.13205026 0.13284448 0.1320374 ]\n",
      " [0.13226782 0.15101683 0.13183388 0.13205029 0.13284412 0.13203762]\n",
      " [0.13226782 0.15101683 0.13183388 0.13205029 0.13284412 0.13203762]\n",
      " ...\n",
      " [0.13246439 0.14515303 0.1320941  0.13219804 0.14536086 0.13215749]\n",
      " [0.13246439 0.14515303 0.1320941  0.13219804 0.14536086 0.13215749]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    320\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     221.25\n",
      "    Step:   271888\n",
      "    Q value:    0.1615176498889923\n",
      "    Loss:   0.4063083529472351\n",
      "    Look-up table:\n",
      "[[0.14116518 0.16732047 0.14572537 0.14083479 0.14214803 0.14348982]\n",
      " [0.14116518 0.16732047 0.14572537 0.14083479 0.14214803 0.14348982]\n",
      " [0.14116518 0.16732047 0.14572537 0.14083479 0.14214803 0.14348982]\n",
      " ...\n",
      " [0.14370756 0.16190398 0.14567316 0.14301245 0.14335991 0.14470963]\n",
      " [0.14370756 0.16190398 0.14567316 0.14301245 0.14335991 0.14470963]\n",
      " [0.14370756 0.16190398 0.14567316 0.14301245 0.14335991 0.14470963]]\n",
      "Episode:    330\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     223.25\n",
      "    Step:   280084\n",
      "    Q value:    0.14104807376861572\n",
      "    Loss:   0.4065091013908386\n",
      "    Look-up table:\n",
      "[[0.13679035 0.14912347 0.13511039 0.13646021 0.13580379 0.13002492]\n",
      " [0.13677487 0.14899404 0.13510191 0.13645886 0.13580035 0.13002481]\n",
      " [0.13677487 0.14899404 0.13510191 0.13645886 0.13580035 0.13002481]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.13365076 0.14164707 0.13354783 0.1344268  0.13533196 0.13022238]\n",
      " [0.13365076 0.14164707 0.13354783 0.1344268  0.13533196 0.13022238]]\n",
      "Episode:    340\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     239.75\n",
      "    Step:   288706\n",
      "    Q value:    0.16180196404457092\n",
      "    Loss:   0.5101831555366516\n",
      "    Look-up table:\n",
      "[[0.14417301 0.15697671 0.14424051 0.14284627 0.14225253 0.1442503 ]\n",
      " [0.14417301 0.15697671 0.14424051 0.14284627 0.14225253 0.1442503 ]\n",
      " [0.14417505 0.1569463  0.14424215 0.1428505  0.14225645 0.144252  ]\n",
      " ...\n",
      " [0.14444485 0.16339593 0.14447176 0.14365529 0.143355   0.14450137]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    350\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     222.5\n",
      "    Step:   297117\n",
      "    Q value:    0.1383097916841507\n",
      "    Loss:   1.686353061813861e-05\n",
      "    Look-up table:\n",
      "[[0.13323373 0.15149406 0.13347602 0.13372093 0.13954255 0.13335031]\n",
      " [0.13323373 0.15149406 0.13347602 0.13372093 0.13954255 0.13335031]\n",
      " [0.13323371 0.15135728 0.13347359 0.13371749 0.13980527 0.13334727]\n",
      " ...\n",
      " [0.13338335 0.13985039 0.13327788 0.13334459 0.14095478 0.13321775]\n",
      " [0.13338335 0.13985039 0.13327788 0.13334459 0.14095478 0.13321775]\n",
      " [0.13338317 0.13999008 0.13327855 0.13334516 0.14109546 0.13321939]]\n",
      "Episode:    360\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     183.0\n",
      "    Step:   306319\n",
      "    Q value:    0.1640404909849167\n",
      "    Loss:   0.00017922883853316307\n",
      "    Look-up table:\n",
      "[[0.144932   0.1519655  0.13693386 0.16286194 0.15870687 0.13435403]\n",
      " [0.14454801 0.15150297 0.13603273 0.16323335 0.15833163 0.13426755]\n",
      " [0.14454801 0.15150297 0.13603273 0.16323335 0.15833163 0.13426755]\n",
      " ...\n",
      " [0.14485395 0.14673162 0.14551854 0.14418472 0.16453707 0.14383759]\n",
      " [0.14485395 0.14673162 0.14551854 0.14418472 0.16453707 0.14383759]\n",
      " [0.14485395 0.14673162 0.14551854 0.14418472 0.16453707 0.14383759]]\n",
      "Episode:    370\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     218.25\n",
      "    Step:   314864\n",
      "    Q value:    0.15708261728286743\n",
      "    Loss:   4.156012058258057\n",
      "    Look-up table:\n",
      "[[0.14832173 0.14804174 0.14836006 0.14832446 0.17864691 0.14835986]\n",
      " [0.14832173 0.14804174 0.14836006 0.14832446 0.17864691 0.14835986]\n",
      " [0.14832199 0.14804307 0.14836006 0.14832453 0.17885669 0.14835986]\n",
      " ...\n",
      " [0.14786392 0.16261771 0.14142691 0.14810163 0.15819293 0.14798762]\n",
      " [0.14786392 0.16261771 0.14142691 0.14810163 0.15819293 0.14798762]\n",
      " [0.14786392 0.16261771 0.14142691 0.14810163 0.15819293 0.14798762]]\n",
      "Episode:    380\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     253.75\n",
      "    Step:   322574\n",
      "    Q value:    0.17780065536499023\n",
      "    Loss:   0.9158580303192139\n",
      "    Look-up table:\n",
      "[[0.15272982 0.14892238 0.15016183 0.15079974 0.17659898 0.14457235]\n",
      " [0.15272982 0.14892238 0.15016183 0.15079974 0.17659898 0.14457235]\n",
      " [0.15301198 0.14893655 0.15016738 0.15083432 0.17704375 0.14458689]\n",
      " ...\n",
      " [0.16154584 0.15116271 0.16258289 0.15477687 0.18167447 0.14701466]\n",
      " [0.16149531 0.1511773  0.16261961 0.15478873 0.18188682 0.147025  ]\n",
      " [0.16149531 0.1511773  0.16261961 0.15478873 0.18188682 0.147025  ]]\n",
      "Episode:    390\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     270.0\n",
      "    Step:   332769\n",
      "    Q value:    0.1745878905057907\n",
      "    Loss:   1.4912766346242279e-05\n",
      "    Look-up table:\n",
      "[[0.16097301 0.1679876  0.16721644 0.17435396 0.19486874 0.16125956]\n",
      " [0.16097301 0.1679876  0.16721644 0.17435396 0.19486874 0.16125956]\n",
      " [0.16097301 0.1679876  0.16721644 0.17435396 0.19486874 0.16125956]\n",
      " ...\n",
      " [0.17384699 0.1686231  0.16771095 0.1694032  0.17964448 0.16104996]\n",
      " [0.17384699 0.1686231  0.16771095 0.1694032  0.17964448 0.16104996]\n",
      " [0.17353404 0.16871776 0.16778499 0.16943    0.17965402 0.16115884]]\n",
      "Episode:    400\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     268.25\n",
      "    Step:   344246\n",
      "    Q value:    0.17046134173870087\n",
      "    Loss:   4.233937943354249e-05\n",
      "    Look-up table:\n",
      "[[0.15899713 0.16001236 0.15881981 0.1595394  0.18694428 0.16222833]\n",
      " [0.15899713 0.16001236 0.15881981 0.1595394  0.18694428 0.16222833]\n",
      " [0.15899713 0.16001236 0.15881981 0.1595394  0.18694428 0.16222833]\n",
      " ...\n",
      " [0.16096333 0.16123915 0.16869664 0.16091058 0.17053807 0.16145141]\n",
      " [0.16096571 0.16123967 0.16873467 0.16091211 0.17041673 0.16145121]\n",
      " [0.16096571 0.16123967 0.16873467 0.16091211 0.17041673 0.16145121]]\n",
      "Episode:    410\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     277.25\n",
      "    Step:   353772\n",
      "    Q value:    0.18209712207317352\n",
      "    Loss:   4.457755088806152\n",
      "    Look-up table:\n",
      "[[0.16748756 0.16748789 0.16628242 0.16746198 0.19273046 0.16733897]\n",
      " [0.16748756 0.16748789 0.16628242 0.16746198 0.19273046 0.16733897]\n",
      " [0.16748756 0.16748789 0.16628242 0.16746198 0.19273046 0.16733897]\n",
      " ...\n",
      " [0.16303942 0.15872052 0.16523021 0.16588704 0.18426219 0.16695786]\n",
      " [0.16303942 0.15872052 0.16523021 0.16588704 0.18426219 0.16695786]\n",
      " [0.16303942 0.15872052 0.16523021 0.16588704 0.18426219 0.16695786]]\n",
      "Episode:    420\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     304.5\n",
      "    Step:   363202\n",
      "    Q value:    0.16722142696380615\n",
      "    Loss:   0.000499419984407723\n",
      "    Look-up table:\n",
      "[[0.1878531  0.18374908 0.19657408 0.19345039 0.20559025 0.19352859]\n",
      " [0.1878531  0.18374908 0.19657408 0.19345039 0.20559025 0.19352859]\n",
      " [0.18782374 0.18303463 0.19648838 0.19333456 0.20487545 0.19351257]\n",
      " ...\n",
      " [0.14986065 0.1543344  0.14974333 0.16335046 0.16012479 0.17868185]\n",
      " [0.14981343 0.15427345 0.14971346 0.16424134 0.15994978 0.17904694]\n",
      " [0.14981343 0.15427345 0.14971346 0.16424134 0.15994978 0.17904694]]\n",
      "Episode:    430\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     295.5\n",
      "    Step:   372835\n",
      "    Q value:    0.1991860717535019\n",
      "    Loss:   0.5100364685058594\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [0.19735217 0.21540663 0.19644485 0.19694334 0.19245085 0.20232439]\n",
      " [0.19735217 0.21540663 0.19644485 0.19694334 0.19245085 0.20232439]\n",
      " ...\n",
      " [0.20091467 0.1949697  0.18918543 0.18541823 0.19186844 0.20984648]\n",
      " [0.20091467 0.1949697  0.18918543 0.18541823 0.19186844 0.20984648]\n",
      " [0.20091467 0.1949697  0.18918543 0.18541823 0.19186844 0.20984648]]\n",
      "Episode:    440\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     234.25\n",
      "    Step:   380997\n",
      "    Q value:    0.1909562051296234\n",
      "    Loss:   0.0003331907500978559\n",
      "    Look-up table:\n",
      "[[0.16672085 0.17938554 0.16774341 0.1705173  0.17567858 0.17150132]\n",
      " [0.16672085 0.17938554 0.16774341 0.1705173  0.17567858 0.17150132]\n",
      " [0.16672336 0.17935653 0.16774145 0.17058422 0.17564593 0.17149664]\n",
      " ...\n",
      " [0.17556356 0.19711404 0.16583575 0.16868374 0.16987088 0.17025413]\n",
      " [0.17556356 0.19711404 0.16583575 0.16868374 0.16987088 0.17025413]\n",
      " [0.17495905 0.19655374 0.16584516 0.16868261 0.16986935 0.17025273]]\n",
      "Episode:    450\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     217.75\n",
      "    Step:   390211\n",
      "    Q value:    0.1765083521604538\n",
      "    Loss:   0.00016641567344777286\n",
      "    Look-up table:\n",
      "[[0.15630642 0.1568407  0.15626302 0.16543566 0.15732247 0.17265645]\n",
      " [0.15630642 0.1568407  0.15626302 0.16543566 0.15732247 0.17265645]\n",
      " [0.15630585 0.15684015 0.15626298 0.16537997 0.15732202 0.17194331]\n",
      " ...\n",
      " [0.15711483 0.15682681 0.15674604 0.16358745 0.15896663 0.1792495 ]\n",
      " [0.15711483 0.15682681 0.15674604 0.16358745 0.15896663 0.1792495 ]\n",
      " [0.15711483 0.15682681 0.15674604 0.16358745 0.15896663 0.1792495 ]]\n",
      "Episode:    460\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     238.5\n",
      "    Step:   398881\n",
      "    Q value:    0.16358450055122375\n",
      "    Loss:   2.252370904898271e-05\n",
      "    Look-up table:\n",
      "[[0.13821806 0.15359218 0.1506927  0.15094431 0.15146175 0.1539906 ]\n",
      " [0.13821806 0.15359218 0.1506927  0.15094431 0.15146175 0.1539906 ]\n",
      " [0.13834657 0.1539757  0.15091445 0.15055916 0.15143926 0.15394351]\n",
      " ...\n",
      " [0.15779205 0.1669637  0.15829483 0.15842521 0.15246879 0.16059439]\n",
      " [0.15779205 0.1669637  0.15829483 0.15842521 0.15246879 0.16059439]\n",
      " [0.1578207  0.16709514 0.15829784 0.15842506 0.15247825 0.16056813]]\n",
      "Episode:    470\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     245.25\n",
      "    Step:   408450\n",
      "    Q value:    0.15855686366558075\n",
      "    Loss:   0.6035358309745789\n",
      "    Look-up table:\n",
      "[[0.145733   0.14727919 0.1457174  0.14573057 0.13329774 0.16398305]\n",
      " [0.145733   0.14727919 0.1457174  0.14573057 0.13329774 0.16398305]\n",
      " [0.145733   0.14727919 0.1457174  0.14573057 0.13329774 0.16398305]\n",
      " ...\n",
      " [0.14429872 0.14701149 0.14419846 0.14476733 0.16048533 0.15869088]\n",
      " [0.14426877 0.14700562 0.14408919 0.14472985 0.15943471 0.15907617]\n",
      " [0.14426877 0.14700562 0.14408919 0.14472985 0.15943471 0.15907617]]\n",
      "Episode:    480\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     250.0\n",
      "    Step:   418930\n",
      "    Q value:    0.17411601543426514\n",
      "    Loss:   0.30185967683792114\n",
      "    Look-up table:\n",
      "[[0.15036629 0.14821602 0.15142712 0.14883131 0.15493847 0.1522489 ]\n",
      " [0.15036629 0.14821602 0.15142712 0.14883131 0.15493847 0.1522489 ]\n",
      " [0.15035185 0.14822052 0.15141995 0.14883149 0.15486869 0.15215814]\n",
      " ...\n",
      " [0.1493907  0.14859848 0.15030546 0.14887266 0.17522547 0.14947465]\n",
      " [0.14938879 0.14859991 0.15030292 0.14887284 0.17592704 0.1494745 ]\n",
      " [0.14938879 0.14859991 0.15030292 0.14887284 0.17592704 0.1494745 ]]\n",
      "Episode:    490\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     262.75\n",
      "    Step:   427823\n",
      "    Q value:    0.15811970829963684\n",
      "    Loss:   1.2118139238737058e-05\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.15597889 0.16956806 0.15545782 0.15252908 0.15785067 0.15536031]\n",
      " ...\n",
      " [0.15459037 0.16131149 0.15012777 0.15208282 0.15669596 0.15396625]\n",
      " [0.15459037 0.16131149 0.15012777 0.15208282 0.15669596 0.15396625]\n",
      " [0.15459037 0.16131149 0.15012777 0.15208282 0.15669596 0.15396625]]\n",
      "Episode:    500\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     269.75\n",
      "    Step:   436215\n",
      "    Q value:    0.17558062076568604\n",
      "    Loss:   0.00017817493062466383\n",
      "    Look-up table:\n",
      "[[0.15429749 0.18053469 0.15436269 0.1546112  0.15330502 0.15428919]\n",
      " [0.15430179 0.18038924 0.15437061 0.15462056 0.15331416 0.15430054]\n",
      " [0.15430179 0.18038924 0.15437061 0.15462056 0.15331416 0.15430054]\n",
      " ...\n",
      " [0.1566378  0.17658135 0.15632503 0.15623768 0.15462004 0.15563796]\n",
      " [0.1566378  0.17658135 0.15632503 0.15623768 0.15462004 0.15563796]\n",
      " [0.1566378  0.17658135 0.15632503 0.15623768 0.15462004 0.15563796]]\n",
      "Episode:    510\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     261.0\n",
      "    Step:   446068\n",
      "    Q value:    0.15705327689647675\n",
      "    Loss:   0.29128357768058777\n",
      "    Look-up table:\n",
      "[[0.14721304 0.16307853 0.14729466 0.14718024 0.15377004 0.14720054]\n",
      " [0.14721219 0.16319019 0.14729151 0.14717823 0.15376472 0.14719804]\n",
      " [0.14721219 0.16319019 0.14729151 0.14717823 0.15376472 0.14719804]\n",
      " ...\n",
      " [0.14709015 0.15737155 0.14704376 0.14698668 0.15247858 0.14699177]\n",
      " [0.14709015 0.15737155 0.14704376 0.14698668 0.15247858 0.14699177]\n",
      " [0.14709015 0.15737155 0.14704376 0.14698668 0.15247858 0.14699177]]\n",
      "Episode:    520\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     223.75\n",
      "    Step:   453946\n",
      "    Q value:    0.1755811870098114\n",
      "    Loss:   0.00036191902472637594\n",
      "    Look-up table:\n",
      "[[0.14920846 0.14369525 0.14597952 0.14849664 0.17511469 0.15644617]\n",
      " [0.14920846 0.14369525 0.14597952 0.14849664 0.17511469 0.15644617]\n",
      " [0.14920846 0.14369525 0.14597952 0.14849664 0.17511469 0.15644617]\n",
      " ...\n",
      " [0.14919531 0.14441654 0.14664766 0.14869036 0.17663598 0.15344551]\n",
      " [0.14919527 0.14442164 0.14665306 0.14869121 0.17625646 0.15344054]\n",
      " [0.14919527 0.14442164 0.14665306 0.14869121 0.17625646 0.15344054]]\n",
      "Episode:    530\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     198.75\n",
      "    Step:   461783\n",
      "    Q value:    0.1576232761144638\n",
      "    Loss:   0.00011654805712169036\n",
      "    Look-up table:\n",
      "[[0.14875852 0.14762405 0.1643087  0.14618081 0.16085379 0.17767902]\n",
      " [0.14875852 0.14762405 0.1643087  0.14618081 0.16085379 0.17767902]\n",
      " [0.14875852 0.14762405 0.1643087  0.14618081 0.16085379 0.17767902]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.14739829 0.14641477 0.15156761 0.14464615 0.15439445 0.15872154]]\n",
      "Episode:    540\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     211.75\n",
      "    Step:   470315\n",
      "    Q value:    0.165496826171875\n",
      "    Loss:   0.00012921866436954588\n",
      "    Look-up table:\n",
      "[[0.15123181 0.16999018 0.15151548 0.14979446 0.15423241 0.14991085]\n",
      " [0.15123181 0.16999018 0.15151548 0.14979446 0.15423241 0.14991085]\n",
      " [0.15123181 0.16999018 0.15151548 0.14979446 0.15423241 0.14991085]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.15221269 0.16521317 0.15397584 0.15138319 0.17769185 0.15120533]\n",
      " [0.15221269 0.16521317 0.15397584 0.15138319 0.17769185 0.15120533]]\n",
      "Episode:    550\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     235.25\n",
      "    Step:   480226\n",
      "    Q value:    0.1725798100233078\n",
      "    Loss:   1.3108731508255005\n",
      "    Look-up table:\n",
      "[[0.16138837 0.17511199 0.15987103 0.16118756 0.18335111 0.17390299]\n",
      " [0.16138837 0.17511199 0.15987103 0.16118756 0.18335111 0.17390299]\n",
      " [0.16145654 0.17483224 0.15988886 0.16119227 0.18353882 0.17363256]\n",
      " ...\n",
      " [0.17532112 0.16560927 0.1610063  0.16187519 0.17298128 0.16249941]\n",
      " [0.17902778 0.16560096 0.16095039 0.16187015 0.17325133 0.16248782]\n",
      " [0.17902778 0.16560096 0.16095039 0.16187015 0.17325133 0.16248782]]\n",
      "Episode:    560\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     259.0\n",
      "    Step:   490306\n",
      "    Q value:    0.16941648721694946\n",
      "    Loss:   0.9158580303192139\n",
      "    Look-up table:\n",
      "[[0.15757288 0.17553456 0.15760347 0.15646034 0.15743625 0.15759122]\n",
      " [0.15757288 0.17553456 0.15760347 0.15646034 0.15743625 0.15759122]\n",
      " [0.15757294 0.17541853 0.15760347 0.15646154 0.15743649 0.15759122]\n",
      " ...\n",
      " [0.16115917 0.17517108 0.16452052 0.15791307 0.15831132 0.15359089]\n",
      " [0.16103977 0.17511614 0.16417904 0.15788357 0.15829873 0.15338473]\n",
      " [0.16103977 0.17511614 0.16417904 0.15788357 0.15829873 0.15338473]]\n",
      "Episode:    570\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     247.25\n",
      "    Step:   498911\n",
      "    Q value:    0.17567595839500427\n",
      "    Loss:   0.0006234801257960498\n",
      "    Look-up table:\n",
      "[[0.14201969 0.14404166 0.14036362 0.14151512 0.15840831 0.14036298]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.14201969 0.14404166 0.14036362 0.14151512 0.15840831 0.14036298]\n",
      " ...\n",
      " [0.141286   0.14372234 0.14036362 0.14092739 0.1750938  0.1487394 ]\n",
      " [0.141286   0.14372234 0.14036362 0.14092739 0.1750938  0.1487394 ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    580\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     222.25\n",
      "    Step:   506873\n",
      "    Q value:    0.17254512012004852\n",
      "    Loss:   0.0935361385345459\n",
      "    Look-up table:\n",
      "[[0.15983443 0.18718979 0.15795146 0.1687354  0.18101205 0.15784535]\n",
      " [0.15983443 0.18718979 0.15795146 0.1687354  0.18101205 0.15784535]\n",
      " [0.15978998 0.18727462 0.15631503 0.16766521 0.18070205 0.15783095]\n",
      " ...\n",
      " [0.15387018 0.17786299 0.16288607 0.15408874 0.17533864 0.15410708]\n",
      " [0.15387018 0.17786299 0.16288607 0.15408874 0.17533864 0.15410708]\n",
      " [0.15384816 0.17749155 0.16190758 0.15406631 0.17531653 0.15410474]]\n",
      "Episode:    590\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     233.0\n",
      "    Step:   516003\n",
      "    Q value:    0.18939876556396484\n",
      "    Loss:   0.5101903080940247\n",
      "    Look-up table:\n",
      "[[0.1677267  0.16791421 0.16773835 0.1706585  0.18104015 0.17121918]\n",
      " [0.1677267  0.16791421 0.16773835 0.1706585  0.18104015 0.17121918]\n",
      " [0.16773573 0.1678852  0.16772056 0.17051843 0.18132223 0.17120533]\n",
      " ...\n",
      " [0.16822661 0.1678936  0.17080799 0.17187622 0.18983392 0.17179747]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.16822661 0.1678936  0.17080799 0.17187622 0.18983392 0.17179747]]\n",
      "Episode:    600\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     254.75\n",
      "    Step:   524894\n",
      "    Q value:    0.17655371129512787\n",
      "    Loss:   0.0002072112838504836\n",
      "    Look-up table:\n",
      "[[0.15641494 0.15687613 0.15944938 0.15618826 0.16458796 0.1749061 ]\n",
      " [0.15641412 0.15686592 0.15962476 0.15618844 0.16457692 0.17485785]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [0.15631658 0.15625282 0.16360945 0.15619364 0.16263938 0.17655371]\n",
      " [0.15631615 0.1562527  0.16357562 0.15619366 0.16263773 0.17619862]\n",
      " [0.15631615 0.1562527  0.16357562 0.15619366 0.16263773 0.17619862]]\n",
      "Episode:    610\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     234.75\n",
      "    Step:   534839\n",
      "    Q value:    0.17908327281475067\n",
      "    Loss:   0.5101903080940247\n",
      "    Look-up table:\n",
      "[[0.15547971 0.15711787 0.15688041 0.15650068 0.16792881 0.17852904]\n",
      " [0.15547971 0.15711787 0.15688041 0.15650068 0.16792881 0.17852904]\n",
      " [0.15548137 0.15712468 0.15688823 0.15650441 0.16789116 0.17856592]\n",
      " ...\n",
      " [0.15617456 0.15762289 0.1575582  0.1574077  0.16305146 0.17950879]\n",
      " [0.15617456 0.15762289 0.1575582  0.1574077  0.16305146 0.17950879]\n",
      " [0.15617456 0.15762289 0.1575582  0.1574077  0.16305146 0.17950879]]\n",
      "Episode:    620\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     219.25\n",
      "    Step:   544638\n",
      "    Q value:    0.1566145122051239\n",
      "    Loss:   4.839986650040373e-05\n",
      "    Look-up table:\n",
      "[[0.15207155 0.15143862 0.1580663  0.15235159 0.17124803 0.17660341]\n",
      " [0.15207155 0.15143862 0.1580663  0.15235159 0.17124803 0.17660341]\n",
      " [0.15207155 0.15143862 0.1580663  0.15235159 0.17124803 0.17660341]\n",
      " ...\n",
      " [0.15192217 0.15231514 0.15492572 0.15420243 0.15819252 0.15267521]\n",
      " [0.15189019 0.15226685 0.15483081 0.15416676 0.15799747 0.15257713]\n",
      " [0.15189019 0.15226685 0.15483081 0.15416676 0.15799747 0.15257713]]\n",
      "Episode:    630\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     239.5\n",
      "    Step:   555050\n",
      "    Q value:    0.17394989728927612\n",
      "    Loss:   0.29120177030563354\n",
      "    Look-up table:\n",
      "[[0.16126187 0.15253834 0.15315732 0.15016887 0.17186266 0.15398394]\n",
      " [0.16126187 0.15253834 0.15315732 0.15016887 0.17186266 0.15398394]\n",
      " [0.16126187 0.15253834 0.15315732 0.15016887 0.17186266 0.15398394]\n",
      " ...\n",
      " [0.15902017 0.15388079 0.15424207 0.15272132 0.17471074 0.1545268 ]\n",
      " [0.15902036 0.15389614 0.15425403 0.15273026 0.17466393 0.154539  ]\n",
      " [0.15902036 0.15389614 0.15425403 0.15273026 0.17466393 0.154539  ]]\n",
      "Episode:    640\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     234.25\n",
      "    Step:   563300\n",
      "    Q value:    0.15659752488136292\n",
      "    Loss:   0.0007731704972684383\n",
      "    Look-up table:\n",
      "[[0.14973471 0.14571694 0.14141047 0.1488584  0.14495036 0.14897698]\n",
      " [0.14973471 0.14571694 0.14141047 0.1488584  0.14495036 0.14897698]\n",
      " [0.15024658 0.14571075 0.1414046  0.14913005 0.14493583 0.14908603]\n",
      " ...\n",
      " [0.15803446 0.15709051 0.14299797 0.14647856 0.14431615 0.1565107 ]\n",
      " [0.15803446 0.15709051 0.14299797 0.14647856 0.14431615 0.1565107 ]\n",
      " [0.15803446 0.15709051 0.14299797 0.14647856 0.14431615 0.1565107 ]]\n",
      "Episode:    650\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     242.75\n",
      "    Step:   572739\n",
      "    Q value:    0.16453513503074646\n",
      "    Loss:   0.6143717765808105\n",
      "    Look-up table:\n",
      "[[0.14757225 0.14890423 0.15185231 0.15420865 0.17173539 0.17622216]\n",
      " [0.14757574 0.14890562 0.15183046 0.15420271 0.17183706 0.17612296]\n",
      " [0.14757574 0.14890562 0.15183046 0.15420271 0.17183706 0.17612296]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.1497288  0.15012188 0.15008055 0.1523339  0.15820916 0.16531165]\n",
      " [0.1497288  0.15012188 0.15008055 0.1523339  0.15820916 0.16531165]]\n",
      "Episode:    660\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     254.75\n",
      "    Step:   581165\n",
      "    Q value:    0.18085965514183044\n",
      "    Loss:   0.1974421739578247\n",
      "    Look-up table:\n",
      "[[0.18399027 0.17248897 0.18268164 0.17018317 0.1755031  0.18265854]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.18399027 0.17248897 0.18268164 0.17018317 0.1755031  0.18265854]\n",
      " ...\n",
      " [0.16788486 0.17103994 0.17237583 0.16929375 0.19869721 0.17279564]\n",
      " [0.16788486 0.17103994 0.17237583 0.16929375 0.19869721 0.17279564]\n",
      " [0.1679178  0.1710318  0.17249395 0.16929366 0.19893241 0.17279541]]\n",
      "Episode:    670\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     227.25\n",
      "    Step:   590313\n",
      "    Q value:    0.18694159388542175\n",
      "    Loss:   6.174793088575825e-05\n",
      "    Look-up table:\n",
      "[[0.18442412 0.17196068 0.16617537 0.17707372 0.18791008 0.20840287]\n",
      " [0.18442412 0.17196068 0.16617537 0.17707372 0.18791008 0.20840287]\n",
      " [0.18442412 0.17196068 0.16617537 0.17707372 0.18791008 0.20840287]\n",
      " ...\n",
      " [0.18149763 0.17584445 0.16910143 0.17684028 0.18520141 0.18779959]\n",
      " [0.18149763 0.17584445 0.16910143 0.17684028 0.18520141 0.18779959]\n",
      " [0.18147534 0.17584588 0.16912474 0.17683816 0.18520474 0.18766363]]\n",
      "Episode:    680\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     221.0\n",
      "    Step:   600396\n",
      "    Q value:    0.1698521375656128\n",
      "    Loss:   0.00013960804790258408\n",
      "    Look-up table:\n",
      "[[0.16672726 0.18581109 0.16327795 0.17730673 0.16513534 0.16472702]\n",
      " [0.16672726 0.18581109 0.16327795 0.17730673 0.16513534 0.16472702]\n",
      " [0.16674358 0.18607993 0.16330659 0.17821673 0.16514486 0.16473927]\n",
      " ...\n",
      " [0.16306973 0.17171679 0.16110638 0.16764428 0.1635195  0.16261071]\n",
      " [0.16306973 0.17171679 0.16110638 0.16764428 0.1635195  0.16261071]\n",
      " [0.16306973 0.17171679 0.16110638 0.16764428 0.1635195  0.16261071]]\n",
      "Episode:    690\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     238.5\n",
      "    Step:   609705\n",
      "    Q value:    0.15634402632713318\n",
      "    Loss:   0.09358742088079453\n",
      "    Look-up table:\n",
      "[[0.16853069 0.16651377 0.16887461 0.21071914 0.16948314 0.17111896]\n",
      " [0.16853069 0.16651377 0.16887461 0.21071914 0.16948314 0.17111896]\n",
      " [0.16853069 0.16651377 0.16887461 0.21071914 0.16948314 0.17111896]\n",
      " ...\n",
      " [0.14641516 0.15588683 0.14842257 0.14547999 0.15722352 0.15581128]\n",
      " [0.14641516 0.15588683 0.14842257 0.14547999 0.15722352 0.15581128]\n",
      " [0.14641111 0.15587239 0.14841233 0.14547798 0.15706313 0.15637794]]\n",
      "Episode:    700\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     237.5\n",
      "    Step:   617862\n",
      "    Q value:    0.14367173612117767\n",
      "    Loss:   0.3017628788948059\n",
      "    Look-up table:\n",
      "[[0.15495402 0.14215511 0.15283874 0.14664763 0.18155468 0.14510131]\n",
      " [0.15495402 0.14215511 0.15283874 0.14664763 0.18155468 0.14510131]\n",
      " [0.15495402 0.14215511 0.15283874 0.14664763 0.18155468 0.14510131]\n",
      " ...\n",
      " [0.14950565 0.14364538 0.14818794 0.14059444 0.14268722 0.14496933]\n",
      " [0.14965616 0.14362794 0.1481428  0.1402974  0.14239377 0.14493696]\n",
      " [0.14965616 0.14362794 0.1481428  0.1402974  0.14239377 0.14493696]]\n",
      "Episode:    710\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     266.75\n",
      "    Step:   628985\n",
      "    Q value:    0.17431768774986267\n",
      "    Loss:   0.00012013605737593025\n",
      "    Look-up table:\n",
      "[[0.14863087 0.17644791 0.15251736 0.15764867 0.19838184 0.14553295]\n",
      " [0.1486696  0.17615095 0.15255426 0.15778363 0.19862106 0.14555079]\n",
      " [0.1486696  0.17615095 0.15255426 0.15778363 0.19862106 0.14555079]\n",
      " ...\n",
      " [0.15310977 0.16358785 0.15803738 0.15871011 0.1811032  0.14712854]\n",
      " [0.15310977 0.16358785 0.15803738 0.15871011 0.1811032  0.14712854]\n",
      " [0.15311974 0.1635647  0.15812114 0.15871952 0.18111967 0.14713947]]\n",
      "Episode:    720\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     312.25\n",
      "    Step:   636954\n",
      "    Q value:    0.17400144040584564\n",
      "    Loss:   0.00011333565635140985\n",
      "    Look-up table:\n",
      "[[0.18311664 0.17567953 0.18747371 0.17790166 0.22020301 0.17388345]\n",
      " [0.18311664 0.17567953 0.18747371 0.17790166 0.22020301 0.17388345]\n",
      " [0.18314713 0.17570435 0.18747318 0.17792042 0.21963982 0.17393595]\n",
      " ...\n",
      " [0.16984002 0.17856754 0.16015552 0.16520247 0.17746772 0.17584154]\n",
      " [0.16973363 0.17916313 0.16016738 0.16489403 0.17776473 0.17580581]\n",
      " [0.16973363 0.17916313 0.16016738 0.16489403 0.17776473 0.17580581]]\n",
      "Episode:    730\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     288.5\n",
      "    Step:   645120\n",
      "    Q value:    0.18889765441417694\n",
      "    Loss:   0.811994194984436\n",
      "    Look-up table:\n",
      "[[0.15603532 0.16104078 0.15517835 0.16476709 0.17359842 0.15560885]\n",
      " [0.15603481 0.16103788 0.15528175 0.16420612 0.17401533 0.15561256]\n",
      " [0.15603481 0.16103788 0.15528175 0.16420612 0.17401533 0.15561256]\n",
      " ...\n",
      " [0.15768844 0.16075052 0.16745272 0.17161946 0.19289386 0.15915345]\n",
      " [0.15768844 0.16075052 0.16745272 0.17161946 0.19289386 0.15915345]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    740\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     271.5\n",
      "    Step:   654438\n",
      "    Q value:    0.18311616778373718\n",
      "    Loss:   0.09350975602865219\n",
      "    Look-up table:\n",
      "[[0.17260937 0.18737862 0.16749547 0.17365471 0.18094228 0.17422716]\n",
      " [0.17260937 0.18737862 0.16749547 0.17365471 0.18094228 0.17422716]\n",
      " [0.17260937 0.18737862 0.16749547 0.17365471 0.18094228 0.17422716]\n",
      " ...\n",
      " [0.16328143 0.1850564  0.17378518 0.16555797 0.16396759 0.16620123]\n",
      " [0.16324621 0.18461342 0.17372324 0.16552937 0.16395535 0.16617306]\n",
      " [0.16324621 0.18461342 0.17372324 0.16552937 0.16395535 0.16617306]]\n",
      "Episode:    750\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     272.0\n",
      "    Step:   663288\n",
      "    Q value:    0.1833839863538742\n",
      "    Loss:   0.6143905520439148\n",
      "    Look-up table:\n",
      "[[0.15594985 0.15364793 0.15858319 0.15313028 0.17921592 0.15490521]\n",
      " [0.15594985 0.15364793 0.15858319 0.15313028 0.17921592 0.15490521]\n",
      " [0.15594985 0.15364793 0.15858319 0.15313028 0.17921592 0.15490521]\n",
      " ...\n",
      " [0.15341918 0.15355712 0.15665548 0.15283543 0.18530665 0.15370917]\n",
      " [0.15341918 0.15355712 0.15665548 0.15283543 0.18530665 0.15370917]\n",
      " [0.15341918 0.15355712 0.15665548 0.15283543 0.18530665 0.15370917]]\n",
      "Episode:    760\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     276.75\n",
      "    Step:   671357\n",
      "    Q value:    0.16867545247077942\n",
      "    Loss:   0.00018386798910796642\n",
      "    Look-up table:\n",
      "[[0.17209125 0.19046177 0.16842204 0.17584968 0.19204965 0.18814699]\n",
      " [0.17209125 0.19046177 0.16842204 0.17584968 0.19204965 0.18814699]\n",
      " [0.17211713 0.19035071 0.16855597 0.17620039 0.19236885 0.18803611]\n",
      " ...\n",
      " [0.16561419 0.16327335 0.15817875 0.15332595 0.16187993 0.17399549]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.16554722 0.16308467 0.15810959 0.15323421 0.16175286 0.17394209]]\n",
      "Episode:    770\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     234.5\n",
      "    Step:   679669\n",
      "    Q value:    0.16980478167533875\n",
      "    Loss:   0.0001228332257596776\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [0.15563953 0.15550782 0.15584485 0.15586233 0.17771848 0.17541632]\n",
      " [0.15563953 0.15550782 0.15584485 0.15586233 0.17771848 0.17541632]\n",
      " ...\n",
      " [0.15577924 0.15563808 0.15584148 0.15583692 0.17566678 0.16261777]\n",
      " [0.15577924 0.15563808 0.15584148 0.15583692 0.17566678 0.16261777]\n",
      " [0.1557797  0.15563881 0.15584147 0.15583692 0.17535058 0.16259046]]\n",
      "Episode:    780\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     202.0\n",
      "    Step:   688695\n",
      "    Q value:    0.15534159541130066\n",
      "    Loss:   0.00019768704078160226\n",
      "    Look-up table:\n",
      "[[0.14471287 0.1561504  0.14700472 0.14102392 0.1492122  0.16626655]\n",
      " [0.14454161 0.15596357 0.14686783 0.14100993 0.14920652 0.165749  ]\n",
      " [0.14454161 0.15596357 0.14686783 0.14100993 0.14920652 0.165749  ]\n",
      " ...\n",
      " [0.135691   0.13802189 0.14006847 0.13906366 0.14634398 0.15555283]\n",
      " [0.135691   0.13802189 0.14006847 0.13906366 0.14634398 0.15555283]\n",
      " [0.135691   0.13802189 0.14006847 0.13906366 0.14634398 0.15555283]]\n",
      "Episode:    790\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     232.5\n",
      "    Step:   698315\n",
      "    Q value:    0.16470766067504883\n",
      "    Loss:   0.00012706496636383235\n",
      "    Look-up table:\n",
      "[[0.16371097 0.14512944 0.14693215 0.14797068 0.14725593 0.16652882]\n",
      " [0.16451651 0.14513789 0.14693961 0.14798787 0.14726102 0.16643487]\n",
      " [0.16451651 0.14513789 0.14693961 0.14798787 0.14726102 0.16643487]\n",
      " ...\n",
      " [0.14945176 0.14673842 0.14799105 0.14846154 0.14802462 0.16604273]\n",
      " [0.14945176 0.14673842 0.14799105 0.14846154 0.14802462 0.16604273]\n",
      " [0.14945176 0.14673842 0.14799105 0.14846154 0.14802462 0.16604273]]\n",
      "Episode:    800\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     237.25\n",
      "    Step:   707318\n",
      "    Q value:    0.1656343638896942\n",
      "    Loss:   0.00010585860582068563\n",
      "    Look-up table:\n",
      "[[0.15391526 0.15251939 0.16611437 0.14519963 0.14472753 0.16652989]\n",
      " [0.15391526 0.15251939 0.16611437 0.14519963 0.14472753 0.16652989]\n",
      " [0.15391526 0.15251939 0.16611437 0.14519963 0.14472753 0.16652989]\n",
      " ...\n",
      " [0.15336083 0.15516624 0.152358   0.15324248 0.14841971 0.17003195]\n",
      " [0.15336022 0.15512863 0.15238352 0.1532423  0.14842245 0.17016155]\n",
      " [0.15336022 0.15512863 0.15238352 0.1532423  0.14842245 0.17016155]]\n",
      "Episode:    810\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     256.75\n",
      "    Step:   717010\n",
      "    Q value:    0.16943006217479706\n",
      "    Loss:   0.19763973355293274\n",
      "    Look-up table:\n",
      "[[0.14684558 0.16638458 0.16494067 0.14983347 0.1503884  0.16942751]\n",
      " [0.14684558 0.16638458 0.16494067 0.14983347 0.1503884  0.16942751]\n",
      " [0.14684558 0.16638458 0.16494067 0.14983347 0.1503884  0.16942751]\n",
      " ...\n",
      " [0.14520133 0.15156956 0.1631231  0.14557336 0.14528242 0.17340778]\n",
      " [0.14520134 0.15156727 0.16279671 0.14556953 0.14528215 0.17347968]\n",
      " [0.14520134 0.15156727 0.16279671 0.14556953 0.14528215 0.17347968]]\n",
      "Episode:    820\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     257.75\n",
      "    Step:   726378\n",
      "    Q value:    0.15664052963256836\n",
      "    Loss:   1.3917890100856312e-05\n",
      "    Look-up table:\n",
      "[[0.15162022 0.15019175 0.1505734  0.15410449 0.15254258 0.17636423]\n",
      " [0.15162022 0.15019175 0.1505734  0.15410449 0.15254258 0.17636423]\n",
      " [0.15162022 0.15019175 0.1505734  0.15410449 0.15254258 0.17636423]\n",
      " ...\n",
      " [0.15046492 0.14785165 0.15403746 0.14178838 0.15165196 0.16124512]\n",
      " [0.15077136 0.14786005 0.1545202  0.14211619 0.15214738 0.16157614]\n",
      " [0.15077136 0.14786005 0.1545202  0.14211619 0.15214738 0.16157614]]\n",
      "Episode:    830\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     244.25\n",
      "    Step:   735239\n",
      "    Q value:    0.1964091658592224\n",
      "    Loss:   0.00019271334167569876\n",
      "    Look-up table:\n",
      "[[0.15841939 0.15877457 0.17195728 0.15883714 0.18158367 0.15954037]\n",
      " [0.15841939 0.15877457 0.17195728 0.15883714 0.18158367 0.15954037]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [0.19217214 0.19658896 0.17079869 0.17623904 0.19642042 0.16010985]\n",
      " [0.19217214 0.19658896 0.17079869 0.17623904 0.19642042 0.16010985]\n",
      " [0.19217214 0.19658896 0.17079869 0.17623904 0.19642042 0.16010985]]\n",
      "Episode:    840\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     244.25\n",
      "    Step:   743669\n",
      "    Q value:    0.1772007942199707\n",
      "    Loss:   5.5794451327528805e-05\n",
      "    Look-up table:\n",
      "[[0.17203702 0.17242941 0.17630805 0.15959002 0.17074993 0.18888743]\n",
      " [0.17203702 0.17242941 0.17630805 0.15959002 0.17074993 0.18888743]\n",
      " [0.17203702 0.17242941 0.17630805 0.15959002 0.17074993 0.18888743]\n",
      " ...\n",
      " [0.16922924 0.17625591 0.16972579 0.16473098 0.18289587 0.18281333]\n",
      " [0.16922924 0.17625591 0.16972579 0.16473098 0.18289587 0.18281333]\n",
      " [0.16891359 0.17519215 0.16971461 0.16521721 0.18288603 0.18261364]]\n",
      "Episode:    850\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     323.0\n",
      "    Step:   755850\n",
      "    Q value:    0.17923006415367126\n",
      "    Loss:   0.0003531230613589287\n",
      "    Look-up table:\n",
      "[[0.15583874 0.16627882 0.15390541 0.15358341 0.15428986 0.17573601]\n",
      " [0.15583874 0.16627882 0.15390541 0.15358341 0.15428986 0.17573601]\n",
      " [0.15583874 0.16627882 0.15390541 0.15358341 0.15428986 0.17573601]\n",
      " ...\n",
      " [0.15432113 0.18488072 0.15414245 0.15369108 0.1541733  0.16082832]\n",
      " [0.15433282 0.18453896 0.15414777 0.15369295 0.15417446 0.16085051]\n",
      " [0.15433282 0.18453896 0.15414777 0.15369295 0.15417446 0.16085051]]\n",
      "Episode:    860\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     334.5\n",
      "    Step:   765578\n",
      "    Q value:    0.1623360961675644\n",
      "    Loss:   0.29133525490760803\n",
      "    Look-up table:\n",
      "[[0.15766823 0.15610187 0.15602799 0.1852318  0.15782501 0.1714983 ]\n",
      " [0.15766823 0.15610187 0.15602799 0.1852318  0.15782501 0.1714983 ]\n",
      " [0.15766823 0.15609147 0.15568437 0.18570903 0.15782149 0.17083868]\n",
      " ...\n",
      " [0.15275781 0.15566529 0.15278731 0.15949488 0.15711637 0.16439207]\n",
      " [0.152766   0.15566272 0.15278901 0.15976825 0.157104   0.16439086]\n",
      " [0.152766   0.15566272 0.15278901 0.15976825 0.157104   0.16439086]]\n",
      "Episode:    870\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     236.0\n",
      "    Step:   774121\n",
      "    Q value:    0.17167888581752777\n",
      "    Loss:   0.00011086844460805878\n",
      "    Look-up table:\n",
      "[[0.1483144  0.16518021 0.1486872  0.16774337 0.1633143  0.16242035]\n",
      " [0.1483144  0.16518021 0.1486872  0.16774337 0.1633143  0.16242035]\n",
      " [0.1483144  0.16518021 0.1486872  0.16774337 0.1633143  0.16242035]\n",
      " ...\n",
      " [0.14858936 0.17311758 0.15253729 0.15408242 0.17362349 0.1610622 ]\n",
      " [0.14858936 0.17311758 0.15253729 0.15408242 0.17362349 0.1610622 ]\n",
      " [0.14859341 0.17356004 0.15264994 0.15412124 0.17362452 0.16106032]]\n",
      "Episode:    880\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     231.5\n",
      "    Step:   781354\n",
      "    Q value:    0.19062209129333496\n",
      "    Loss:   0.30186909437179565\n",
      "    Look-up table:\n",
      "[[0.17418815 0.16742513 0.17936398 0.17107037 0.20676917 0.19743419]\n",
      " [0.17418815 0.16742513 0.17936398 0.17107037 0.20676917 0.19743419]\n",
      " [0.17418815 0.16742513 0.17936398 0.17107037 0.20676917 0.19743419]\n",
      " ...\n",
      " [0.17505813 0.16934896 0.16784614 0.17301358 0.19072358 0.19272953]\n",
      " [0.17511626 0.16934592 0.16787852 0.17299867 0.19099893 0.19254364]\n",
      " [0.17511626 0.16934592 0.16787852 0.17299867 0.19099893 0.19254364]]\n",
      "Episode:    890\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     240.75\n",
      "    Step:   789106\n",
      "    Q value:    0.1873794049024582\n",
      "    Loss:   6.817496796429623e-06\n",
      "    Look-up table:\n",
      "[[0.16873705 0.1702569  0.1682346  0.16809632 0.18357722 0.18349496]\n",
      " [0.16887043 0.17027128 0.16927646 0.16814229 0.18358652 0.18376793]\n",
      " [0.16887043 0.17027128 0.16927646 0.16814229 0.18358652 0.18376793]\n",
      " ...\n",
      " [0.17111304 0.17088105 0.18312348 0.17307349 0.19015366 0.18615076]\n",
      " [0.17117915 0.1709106  0.18311518 0.17314744 0.19046697 0.18641047]\n",
      " [0.17117915 0.1709106  0.18311518 0.17314744 0.19046697 0.18641047]]\n",
      "Episode:    900\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     227.75\n",
      "    Step:   797754\n",
      "    Q value:    0.17052964866161346\n",
      "    Loss:   0.29096299409866333\n",
      "    Look-up table:\n",
      "[[0.15638177 0.15396018 0.16258253 0.15018749 0.15816154 0.16702144]\n",
      " [0.15638177 0.15396018 0.16258253 0.15018749 0.15816154 0.16702144]\n",
      " [0.15638177 0.15396018 0.16258253 0.15018749 0.15816154 0.16702144]\n",
      " ...\n",
      " [0.15546806 0.15520783 0.16058378 0.15343387 0.15772378 0.17611742]\n",
      " [0.15546982 0.15521327 0.16060257 0.15344928 0.1577232  0.17668428]\n",
      " [0.15546982 0.15521327 0.16060257 0.15344928 0.1577232  0.17668428]]\n",
      "Episode:    910\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     212.0\n",
      "    Step:   806542\n",
      "    Q value:    0.17980389297008514\n",
      "    Loss:   0.707756757736206\n",
      "    Look-up table:\n",
      "[[0.16393308 0.16298415 0.15838243 0.1626544  0.15750638 0.18562011]\n",
      " [0.16393308 0.16298415 0.15838243 0.1626544  0.15750638 0.18562011]\n",
      " [0.16393308 0.16298415 0.15838243 0.1626544  0.15750638 0.18562011]\n",
      " ...\n",
      " [0.16393769 0.16394505 0.15935785 0.16388631 0.15887734 0.18086375]\n",
      " [0.16393769 0.16394526 0.15936457 0.16388685 0.15888292 0.18090117]\n",
      " [0.16393769 0.16394526 0.15936457 0.16388685 0.15888292 0.18090117]]\n",
      "Episode:    920\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     211.25\n",
      "    Step:   815575\n",
      "    Q value:    0.17131900787353516\n",
      "    Loss:   5.0168673624284565e-06\n",
      "    Look-up table:\n",
      "[[0.1791174  0.16796806 0.16928738 0.17483386 0.16359165 0.17987375]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.17873085 0.16796011 0.16926914 0.17525193 0.16356604 0.17998008]\n",
      " ...\n",
      " [0.1700044  0.16787376 0.16833404 0.16685754 0.16513504 0.17289205]\n",
      " [0.1700044  0.16787376 0.16833404 0.16685754 0.16513504 0.17289205]\n",
      " [0.1700044  0.16787376 0.16833404 0.16685754 0.16513504 0.17289205]]\n",
      "Episode:    930\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     221.0\n",
      "    Step:   823788\n",
      "    Q value:    0.17728126049041748\n",
      "    Loss:   0.8824104070663452\n",
      "    Look-up table:\n",
      "[[0.15476653 0.17305753 0.14927143 0.15548106 0.17171453 0.1613306 ]\n",
      " [0.15476653 0.17305753 0.14927143 0.15548106 0.17171453 0.1613306 ]\n",
      " [0.15476653 0.17305753 0.14927143 0.15548106 0.17171453 0.1613306 ]\n",
      " ...\n",
      " [0.15015253 0.16343302 0.14897951 0.15291527 0.17899625 0.15865892]\n",
      " [0.15015253 0.16343302 0.14897951 0.15291527 0.17899625 0.15865892]\n",
      " [0.15015253 0.16343302 0.14897951 0.15291527 0.17899625 0.15865892]]\n",
      "Episode:    940\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     238.5\n",
      "    Step:   832029\n",
      "    Q value:    0.17810295522212982\n",
      "    Loss:   0.6144721508026123\n",
      "    Look-up table:\n",
      "[[0.16303279 0.15805066 0.16425052 0.16434443 0.18479735 0.15377052]\n",
      " [0.16303279 0.15805066 0.16425052 0.16434443 0.18479735 0.15377052]\n",
      " [0.16303279 0.15805066 0.16425052 0.16434443 0.18479735 0.15377052]\n",
      " ...\n",
      " [0.16156167 0.15927961 0.19246015 0.16369322 0.17673685 0.15488786]\n",
      " [0.16156167 0.15927961 0.19246015 0.16369322 0.17673685 0.15488786]\n",
      " [0.16145326 0.15925553 0.19203916 0.16361384 0.17609315 0.15488683]]\n",
      "Episode:    950\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     242.5\n",
      "    Step:   839926\n",
      "    Q value:    0.1875145435333252\n",
      "    Loss:   0.00026306830113753676\n",
      "    Look-up table:\n",
      "[[0.17415385 0.16439614 0.1653116  0.16584423 0.19010775 0.16523814]\n",
      " [0.17415385 0.16439614 0.1653116  0.16584423 0.19010775 0.16523814]\n",
      " [0.17415385 0.16439614 0.1653116  0.16584423 0.19010775 0.16523814]\n",
      " ...\n",
      " [0.16700287 0.16523845 0.17839254 0.16658513 0.19173408 0.16595878]\n",
      " [0.16699418 0.16524237 0.17852028 0.16658573 0.19122027 0.16596331]\n",
      " [0.16699418 0.16524237 0.17852028 0.16658573 0.19122027 0.16596331]]\n",
      "Episode:    960\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     250.25\n",
      "    Step:   849309\n",
      "    Q value:    0.1796044558286667\n",
      "    Loss:   0.614380955696106\n",
      "    Look-up table:\n",
      "[[0.17179008 0.16855119 0.16840352 0.16795465 0.17430572 0.18284889]\n",
      " [0.17179008 0.16855119 0.16840352 0.16795465 0.17430572 0.18284889]\n",
      " [0.17179008 0.16855119 0.16840352 0.16795465 0.17430572 0.18284889]\n",
      " ...\n",
      " [0.1701989  0.16650659 0.16796622 0.16622187 0.17252246 0.18017985]\n",
      " [0.1701989  0.16650659 0.16796622 0.16622187 0.17252246 0.18017985]\n",
      " [0.17018476 0.16650373 0.16796416 0.16621879 0.17251939 0.1803505 ]]\n",
      "Episode:    970\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     315.5\n",
      "    Step:   860787\n",
      "    Q value:    0.190656840801239\n",
      "    Loss:   0.00018980882305186242\n",
      "    Look-up table:\n",
      "[[0.16205326 0.16272157 0.19892454 0.16143243 0.19204521 0.1817078 ]\n",
      " [0.16205326 0.16272157 0.19892454 0.16143243 0.19204521 0.1817078 ]\n",
      " [0.16217299 0.16273694 0.19964147 0.16145068 0.19208319 0.181857  ]\n",
      " ...\n",
      " [0.17124335 0.16524652 0.18449931 0.16529155 0.1967272  0.18675411]\n",
      " [0.17124335 0.16524652 0.18449931 0.16529155 0.1967272  0.18675411]\n",
      " [0.17124335 0.16524652 0.18449931 0.16529155 0.1967272  0.18675411]]\n",
      "Episode:    980\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     283.25\n",
      "    Step:   869331\n",
      "    Q value:    0.16562384366989136\n",
      "    Loss:   0.00011579471174627542\n",
      "    Look-up table:\n",
      "[[0.15069145 0.16736364 0.15026252 0.15046203 0.15070112 0.15013094]\n",
      " [0.15069145 0.16736364 0.15026252 0.15046203 0.15070112 0.15013094]\n",
      " [0.15069196 0.16772607 0.15026389 0.15046282 0.15070191 0.1501337 ]\n",
      " ...\n",
      " [0.15089948 0.16696337 0.15051918 0.15062597 0.15081014 0.15064628]\n",
      " [0.15089948 0.16696337 0.15051918 0.15062597 0.15081014 0.15064628]\n",
      " [0.15089948 0.16696337 0.15051918 0.15062597 0.15081014 0.15064628]]\n",
      "Episode:    990\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     272.25\n",
      "    Step:   879385\n",
      "    Q value:    0.1749768853187561\n",
      "    Loss:   0.00011798994819400832\n",
      "    Look-up table:\n",
      "[[0.15938501 0.17993884 0.15888661 0.15886366 0.16033775 0.15975253]\n",
      " [0.15938501 0.17993884 0.15888661 0.15886366 0.16033775 0.15975253]\n",
      " [0.15938863 0.18000308 0.15888861 0.15886535 0.16033539 0.15975265]\n",
      " ...\n",
      " [0.15959893 0.17529392 0.15921848 0.15921907 0.16007641 0.15975992]\n",
      " [0.15959893 0.17529392 0.15921848 0.15921907 0.16007641 0.15975992]\n",
      " [0.1595995  0.17494434 0.15922002 0.1592207  0.16007496 0.15975995]]\n",
      "Episode:    1000\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.05\n",
      "    Rolling avg. 20 reward:     286.5\n",
      "    Step:   888778\n",
      "    Q value:    0.16101723909378052\n",
      "    Loss:   0.0002536563843023032\n",
      "    Look-up table:\n",
      "[[0.15197664 0.16142577 0.15199307 0.15198955 0.15990093 0.15348342]\n",
      " [0.15197664 0.16142577 0.15199307 0.15198955 0.15990093 0.15348342]\n",
      " [0.15196103 0.16186464 0.15197298 0.15191673 0.15964848 0.15346524]\n",
      " ...\n",
      " [0.14895293 0.16127393 0.14751545 0.17068972 0.15218082 0.14824447]\n",
      " [0.14891516 0.16062303 0.14750142 0.1730631  0.15218697 0.14822449]\n",
      " [0.14891516 0.16062303 0.14750142 0.1730631  0.15218697 0.14822449]]\n",
      "Training finished at 1000 episodes!\n",
      "    Final epsilon:  0.05\n",
      "    Final Rolling avg. 20 reward:   286.5\n",
      "    Final look-up table\n",
      "[[0.15197664 0.16142577 0.15199307 0.15198955 0.15990093 0.15348342]\n",
      " [0.15197664 0.16142577 0.15199307 0.15198955 0.15990093 0.15348342]\n",
      " [0.15196103 0.16186464 0.15197298 0.15191673 0.15964848 0.15346524]\n",
      " ...\n",
      " [0.14895293 0.16127393 0.14751545 0.17068972 0.15218082 0.14824447]\n",
      " [0.14891516 0.16062303 0.14750142 0.1730631  0.15218697 0.14822449]\n",
      " [0.14891516 0.16062303 0.14750142 0.1730631  0.15218697 0.14822449]]\n",
      "\u001B[32m[I 2022-06-07 05:29:07,184]\u001B[0m Trial 2 finished with value: 286.5 and parameters: {'exploration_rate_decay': 0.999975, 'exploration_rate_min': 0.05, 'batch_size': 48, 'gamma': 0.93, 'lr': 0.0009000000000000001, 'learn_every': 4, 'sync_every': 5000}. Best is trial 2 with value: 286.5.\u001B[0m\n",
      "Current Params:\n",
      "    exploration_rate_decay: 0.999975\n",
      "    exploration_rate_min: 0.15000000000000002\n",
      "    batch_size: 32\n",
      "    gamma: 0.9\n",
      "    lr: 0.00030000000000000003\n",
      "    learn_every: 2\n",
      "    sync_every: 10000\n",
      "\n",
      "Episode:    10\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8155010662695109\n",
      "    Rolling avg. 20 reward:     224.0\n",
      "    Step:   8158\n",
      "    Q value:    None\n",
      "    Loss:   0\n",
      "    Look-up table:\n",
      "[[ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 2.34848000e-02 -3.18940058e-02 -2.36053485e-04  5.47846109e-02\n",
      "  -1.65958563e-03 -5.52737806e-03]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " ...\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]]\n",
      "Episode:    20\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.6853643237763708\n",
      "    Rolling avg. 20 reward:     206.0\n",
      "    Step:   15112\n",
      "    Q value:    0.0003886343911290169\n",
      "    Loss:   0.0012895823456346989\n",
      "    Look-up table:\n",
      "[[ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.18917425 -0.02839603 -0.01006581  0.03391916  0.01429413  0.02627145]\n",
      " [-0.18985309 -0.02932719 -0.00933401  0.03550729  0.01365699  0.02576415]]\n",
      "Episode:    30\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.5799828125068412\n",
      "    Rolling avg. 20 reward:     163.25\n",
      "    Step:   21790\n",
      "    Q value:    0.03160983696579933\n",
      "    Loss:   0.5863341689109802\n",
      "    Look-up table:\n",
      "[[ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.00721737  0.01162508  0.00256534  0.02683502  0.03586183  0.01202323]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    40\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.47889007156780694\n",
      "    Rolling avg. 20 reward:     177.25\n",
      "    Step:   29451\n",
      "    Q value:    0.034938640892505646\n",
      "    Loss:   0.00257376441732049\n",
      "    Look-up table:\n",
      "[[-0.08540644  0.22036402 -0.0606029   0.03010434 -0.01970631  0.01708512]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.01121681 -0.05750721  0.01922915 -0.03990186 -0.00416774  0.01122468]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    50\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.4026202890188527\n",
      "    Rolling avg. 20 reward:     188.5\n",
      "    Step:   36390\n",
      "    Q value:    0.024811450392007828\n",
      "    Loss:   0.001110014971345663\n",
      "    Look-up table:\n",
      "[[ 1.59895420e-03  2.55138949e-02  5.20902574e-02  5.40637150e-02\n",
      "  -3.80194224e-02  8.27760622e-03]\n",
      " [ 7.11026788e-03  2.13727951e-02  4.79034334e-02  5.32958247e-02\n",
      "  -3.87579612e-02  8.67080688e-03]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " ...\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [-2.25774944e-04 -1.67287774e-02 -5.15778661e-02 -1.70809776e-03\n",
      "  -4.03775349e-02  1.74660236e-02]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]]\n",
      "Episode:    60\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.33465213710853087\n",
      "    Rolling avg. 20 reward:     155.5\n",
      "    Step:   43786\n",
      "    Q value:    0.03829260915517807\n",
      "    Loss:   0.0018583281198516488\n",
      "    Look-up table:\n",
      "[[ 0.03994557  0.04938421  0.06560735  0.05429108 -0.00419669  0.0107355 ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.03064552  0.03105391  0.05063991  0.02688956 -0.01098656  0.00513938]\n",
      " ...\n",
      " [ 0.17238131  0.02414619  0.04877381  0.02647305  0.0173931   0.09776367]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.13131088  0.02179815  0.05931393  0.02580755  0.01541475  0.06974497]]\n",
      "Episode:    70\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.274489804558809\n",
      "    Rolling avg. 20 reward:     162.75\n",
      "    Step:   51713\n",
      "    Q value:    0.09311668574810028\n",
      "    Loss:   0.0017484085401520133\n",
      "    Look-up table:\n",
      "[[-3.03162709e-02 -1.69626325e-02  1.65876821e-02 -3.44948992e-02\n",
      "   1.55254453e-02  4.29280028e-02]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [-4.50301841e-02 -3.44065875e-02  7.30471313e-03 -4.65836078e-02\n",
      "  -4.26061451e-04  2.22711265e-02]\n",
      " ...\n",
      " [ 1.86044753e-01  1.51701346e-01  5.76252490e-02  1.07742891e-01\n",
      "   1.46270335e-01  1.78728327e-01]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.87774360e-01  1.52904183e-01  5.16829491e-02  8.59526172e-02\n",
      "   1.36017159e-01  1.65243879e-01]]\n",
      "Episode:    80\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.23298802777381367\n",
      "    Rolling avg. 20 reward:     164.75\n",
      "    Step:   58270\n",
      "    Q value:    0.052785709500312805\n",
      "    Loss:   0.001778587931767106\n",
      "    Look-up table:\n",
      "[[ 0.03155285  0.01223087  0.0014912  -0.01390582 -0.04211125 -0.00744271]\n",
      " [ 0.01397051  0.00061458 -0.00279062 -0.02362366 -0.04329345 -0.01713423]\n",
      " [ 0.00427228 -0.00692795 -0.00679908 -0.0300685  -0.03573284 -0.02524455]\n",
      " ...\n",
      " [ 0.03831306 -0.09916517  0.01905981  0.06447411  0.05930858 -0.14206544]\n",
      " [ 0.04364453 -0.1050248   0.02080138  0.05876251  0.08571502 -0.12964603]\n",
      " [ 0.03765907 -0.12658817  0.01971554  0.04900555  0.07512089 -0.11238433]]\n",
      "Episode:    90\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.19638164468171537\n",
      "    Rolling avg. 20 reward:     137.5\n",
      "    Step:   65107\n",
      "    Q value:    0.010024070739746094\n",
      "    Loss:   0.004538374952971935\n",
      "    Look-up table:\n",
      "[[ 1.51340663e-03  2.17153206e-02 -2.29254365e-05  2.99305469e-02\n",
      "  -5.85112721e-03  1.30289644e-02]\n",
      " [-1.30165890e-02  2.64193863e-03 -8.87177885e-04  1.95034817e-02\n",
      "   8.77375156e-03 -3.58635187e-03]\n",
      " [-1.80992410e-02 -1.20832026e-03  2.39211321e-03  2.21231207e-02\n",
      "   2.10728534e-02 -3.28341126e-03]\n",
      " ...\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [-1.17052421e-02  1.86078623e-02 -1.73344463e-03  4.29703817e-02\n",
      "   7.79469907e-02 -6.54889643e-03]]\n",
      "Episode:    100\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.16180752507423551\n",
      "    Rolling avg. 20 reward:     156.0\n",
      "    Step:   72853\n",
      "    Q value:    0.1874619871377945\n",
      "    Loss:   0.47040891647338867\n",
      "    Look-up table:\n",
      "[[-0.00249586  0.06471709 -0.09539808 -0.04884983 -0.01861329  0.02726198]\n",
      " [ 0.00874206  0.0482721  -0.10044266 -0.04902714  0.00342744 -0.00262963]\n",
      " [ 0.01063444  0.03945194 -0.09184714 -0.04602075  0.04118622 -0.00191382]\n",
      " ...\n",
      " [ 0.27543849  0.08920637 -0.16151568 -0.06006575  0.06984381  0.63087046]\n",
      " [ 0.2732355   0.09722848 -0.15752378 -0.05525859  0.06661609  0.62358558]\n",
      " [ 0.21268526  0.03671228 -0.21047413 -0.07649525  0.04937032  0.62265575]]\n",
      "Episode:    110\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     177.25\n",
      "    Step:   79979\n",
      "    Q value:    0.1679440140724182\n",
      "    Loss:   0.0061183348298072815\n",
      "    Look-up table:\n",
      "[[-1.77921876e-02  5.56806475e-03 -4.78218198e-02  1.01531968e-02\n",
      "  -6.18202612e-02 -3.72492522e-03]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [-2.88532078e-02 -2.28494406e-04 -9.43159014e-02 -1.54460445e-02\n",
      "  -1.05027132e-01 -3.52991968e-02]\n",
      " ...\n",
      " [ 5.77474177e-01  5.75740278e-01  7.38123834e-01  1.62972212e-01\n",
      "   1.08994853e+00  3.00526768e-01]\n",
      " [ 5.75399518e-01  5.77590108e-01  7.38762081e-01  1.59828424e-01\n",
      "   1.09111071e+00  2.98127592e-01]\n",
      " [ 5.22036254e-01  4.92917776e-01  6.38255596e-01  7.51617700e-02\n",
      "   8.14287961e-01  1.86645627e-01]]\n",
      "Episode:    120\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     135.75\n",
      "    Step:   86544\n",
      "    Q value:    0.11797921359539032\n",
      "    Loss:   0.004238440655171871\n",
      "    Look-up table:\n",
      "[[-8.66158977e-02 -5.97774833e-02 -2.90633738e-02  2.10538059e-02\n",
      "   7.21155107e-03 -1.78447366e-03]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [-7.18124136e-02 -5.84016442e-02 -1.24953687e-04 -2.35999227e-02\n",
      "   2.56316140e-02 -4.30258587e-02]\n",
      " ...\n",
      " [ 9.20010060e-02  1.33293867e-02  6.18417114e-02 -8.63614455e-02\n",
      "  -1.38047650e-01 -8.68518949e-02]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [-8.98835361e-02 -1.59449816e-01 -1.19831704e-01 -1.36476740e-01\n",
      "  -3.26579094e-01 -1.28120422e-01]]\n",
      "Episode:    130\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     131.5\n",
      "    Step:   93518\n",
      "    Q value:    0.163561150431633\n",
      "    Loss:   0.011800559237599373\n",
      "    Look-up table:\n",
      "[[ 0.03941546  0.00887175 -0.04008033  0.05239268  0.00658435  0.06235976]\n",
      " [ 0.05505229 -0.02589875 -0.02196635  0.01404604  0.05882006  0.01873064]\n",
      " [ 0.06162626 -0.01630747 -0.02892707 -0.00188983  0.05470598  0.0125074 ]\n",
      " ...\n",
      " [ 0.08434079 -0.19121671 -0.12359335 -0.26127732 -0.32540536 -0.14791763]\n",
      " [ 0.07182875 -0.18972766 -0.13329312 -0.25717497 -0.3208569  -0.14067447]\n",
      " [-0.00153987 -0.07162715 -0.19424233 -0.19874205 -0.29565829 -0.09393051]]\n",
      "Episode:    140\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     138.25\n",
      "    Step:   100715\n",
      "    Q value:    0.13867057859897614\n",
      "    Loss:   0.002624872839078307\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.06075865 0.00124752 0.10841152 0.06739478 0.07745531 0.04344027]\n",
      " ...\n",
      " [0.39781034 0.28573081 0.49198091 0.39197245 0.42540377 0.40474218]\n",
      " [0.39588708 0.27993456 0.46577936 0.38310492 0.42535132 0.38891467]\n",
      " [0.29555231 0.25875932 0.32409436 0.32028574 0.39825624 0.30676043]]\n",
      "Episode:    150\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     159.25\n",
      "    Step:   108645\n",
      "    Q value:    0.22008132934570312\n",
      "    Loss:   0.012416239827871323\n",
      "    Look-up table:\n",
      "[[-0.03484835  0.01174195  0.02988297  0.01085493  0.03188029  0.02315864]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.03374676  0.00646174  0.0634574   0.01351951  0.03346014  0.02356251]\n",
      " ...\n",
      " [-0.00790828  0.01119889  0.05350319  0.00738218  0.05188045  0.0419999 ]\n",
      " [ 0.00390859  0.02246669  0.07065027  0.00729656  0.06142166  0.06367159]\n",
      " [-0.05201292 -0.023011    0.01623912  0.00156648  0.02864242 -0.00872998]]\n",
      "Episode:    160\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     173.0\n",
      "    Step:   116508\n",
      "    Q value:    0.0343276709318161\n",
      "    Loss:   0.010702954605221748\n",
      "    Look-up table:\n",
      "[[0.03413606 0.03237727 0.0495736  0.05386612 0.02967183 0.037287  ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.02875566 0.01924011 0.04627703 0.05047293 0.02136865 0.03322938]\n",
      " ...\n",
      " [0.1721279  0.16727206 0.09989581 0.15910365 0.15848064 0.12486482]\n",
      " [0.16607006 0.16568603 0.11858997 0.15637922 0.16343461 0.13395509]\n",
      " [0.14660849 0.15788575 0.15966578 0.14724854 0.16415207 0.15230784]]\n",
      "Episode:    170\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     180.0\n",
      "    Step:   124520\n",
      "    Q value:    0.06119641289114952\n",
      "    Loss:   0.0014552917564287782\n",
      "    Look-up table:\n",
      "[[ 0.05617616  0.07733148 -0.00329556  0.04971462  0.08580714  0.06375992]\n",
      " [ 0.06646511  0.08573538  0.00683568  0.05756277  0.0938881   0.07307255]\n",
      " [ 0.06022695  0.08048156 -0.00035009  0.05195576  0.08906063  0.06714049]\n",
      " ...\n",
      " [ 0.00925767  0.04291651  0.03892477  0.03983712  0.00291222  0.01877424]\n",
      " [ 0.00448114  0.03819522  0.03617823  0.03602436 -0.00249901  0.01396242]\n",
      " [-0.07045478 -0.03024939 -0.01805937 -0.01661664 -0.07662049 -0.06230739]]\n",
      "Episode:    180\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     190.5\n",
      "    Step:   131811\n",
      "    Q value:    0.13925868272781372\n",
      "    Loss:   0.0012337001971900463\n",
      "    Look-up table:\n",
      "[[ 0.03516588  0.05006635  0.02730763 -0.00236079  0.03962305  0.03651839]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.04569793  0.06290972  0.03672069  0.01145694  0.05096617  0.04807466]\n",
      " ...\n",
      " [-0.11316189 -0.16064057 -0.12408727 -0.16071552 -0.11977011 -0.15466464]\n",
      " [-0.10672459 -0.15256676 -0.11788458 -0.15311092 -0.11284071 -0.14691126]\n",
      " [-0.13018262 -0.18312106 -0.14164987 -0.18302569 -0.13897899 -0.17624563]]\n",
      "Episode:    190\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     203.0\n",
      "    Step:   141224\n",
      "    Q value:    0.25252583622932434\n",
      "    Loss:   0.14040622115135193\n",
      "    Look-up table:\n",
      "[[0.03465229 0.06237188 0.03098938 0.04850513 0.05283746 0.03967208]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.02179241 0.05133551 0.02007931 0.03417882 0.03926322 0.02799767]\n",
      " ...\n",
      " [0.14751267 0.1378797  0.13704225 0.14881566 0.16125658 0.14101586]\n",
      " [0.14771557 0.13822576 0.13696888 0.14900991 0.16096789 0.13908896]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    200\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     227.25\n",
      "    Step:   148903\n",
      "    Q value:    0.09953026473522186\n",
      "    Loss:   0.000853596196975559\n",
      "    Look-up table:\n",
      "[[ 7.85297155e-03 -4.69148159e-04  2.55808830e-02  1.45257711e-02\n",
      "   6.62010908e-03  2.19277143e-02]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " ...\n",
      " [ 5.69699407e-02  4.71770167e-02  5.43537736e-02  5.79230785e-02\n",
      "   3.91110480e-02  5.00970185e-02]\n",
      " [ 5.73876500e-02  4.76264358e-02  5.47495484e-02  5.84170818e-02\n",
      "   3.95480692e-02  5.05194962e-02]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]]\n",
      "Episode:    210\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     214.0\n",
      "    Step:   157286\n",
      "    Q value:    0.06792009621858597\n",
      "    Loss:   0.001459085033275187\n",
      "    Look-up table:\n",
      "[[ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.00988066  0.01324382  0.00340068 -0.06723896  0.00553197  0.00305575]\n",
      " ...\n",
      " [ 0.12143797  0.10055542  0.1236237   0.04843268  0.10816246  0.10771859]\n",
      " [ 0.11936358  0.0977242   0.11974403  0.0433642   0.10500517  0.10527486]\n",
      " [ 0.07148054  0.03950238  0.07168457 -0.03991064  0.0557107   0.05534524]]\n",
      "Episode:    220\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     182.25\n",
      "    Step:   164351\n",
      "    Q value:    0.09357400983572006\n",
      "    Loss:   0.0007177478400990367\n",
      "    Look-up table:\n",
      "[[ 0.02910358 -0.0072166   0.02002555 -0.01672342  0.00457063  0.02007172]\n",
      " [ 0.03210703 -0.00297651  0.02397332 -0.01118344  0.00827548  0.02659723]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.10777637  0.09529415  0.08974436  0.072736    0.08151624  0.08943221]\n",
      " [ 0.08124849  0.06409791  0.06542873  0.03440455  0.05483472  0.06628123]]\n",
      "Episode:    230\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     194.0\n",
      "    Step:   173633\n",
      "    Q value:    0.08708193898200989\n",
      "    Loss:   0.2951217591762543\n",
      "    Look-up table:\n",
      "[[ 0.03526637 -0.0499348  -0.00296715  0.02385202  0.02098531  0.02194244]\n",
      " [ 0.02759171 -0.06065691 -0.01167938  0.01494348  0.01290667  0.01490161]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 0.1362474   0.18289739  0.14574906  0.14918169  0.15691131  0.12451622]\n",
      " [ 0.13171291  0.17733914  0.14106509  0.14412174  0.15236324  0.11999533]\n",
      " [ 0.11213008  0.15404099  0.12004873  0.12173495  0.13242465  0.09969178]]\n",
      "Episode:    240\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     217.5\n",
      "    Step:   181979\n",
      "    Q value:    0.2221972644329071\n",
      "    Loss:   1.5207935571670532\n",
      "    Look-up table:\n",
      "[[ 0.06505597  0.02917939  0.06974408  0.07420558  0.07005706  0.0782325 ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.02900845 -0.02094477  0.03516439  0.03354979  0.03084478  0.0471532 ]\n",
      " ...\n",
      " [ 0.05590945  0.05308533  0.0795238   0.08945483  0.08031052  0.07948402]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.03769654  0.03411949  0.06210813  0.07237935  0.06208152  0.06427839]]\n",
      "Episode:    250\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     217.0\n",
      "    Step:   190910\n",
      "    Q value:    0.12376797199249268\n",
      "    Loss:   0.0011500560212880373\n",
      "    Look-up table:\n",
      "[[ 0.03953516  0.02533239  0.07318676  0.03621951  0.04537404  0.04723158]\n",
      " [ 0.02498209  0.00713629  0.05884349  0.02113238  0.03022969  0.03370848]\n",
      " [ 0.00879273 -0.01260036  0.04201841  0.00436983  0.0150736   0.01886454]\n",
      " ...\n",
      " [ 0.06898466  0.058909    0.08873588  0.07181889  0.08708316  0.05303288]\n",
      " [ 0.06715989  0.05652082  0.08749467  0.06878674  0.08169532  0.04921404]\n",
      " [ 0.04888558  0.03379571  0.06831533  0.05009091  0.06278872  0.03124967]]\n",
      "Episode:    260\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     193.0\n",
      "    Step:   199146\n",
      "    Q value:    0.05620143190026283\n",
      "    Loss:   0.0011144849704578519\n",
      "    Look-up table:\n",
      "[[ 2.38519013e-02  4.04262543e-03 -6.04152679e-03  3.80991697e-02\n",
      "   1.90718770e-02  4.82112169e-04]\n",
      " [ 8.22904706e-03 -1.44119263e-02 -2.70366669e-02  1.98916197e-02\n",
      "   9.34898853e-04 -1.61199272e-02]\n",
      " [ 1.23323500e-02 -9.38653946e-03 -2.13586092e-02  2.22189426e-02\n",
      "   6.84225559e-03 -1.03585422e-02]\n",
      " ...\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 9.74320769e-02  1.05148613e-01  1.04749739e-01  1.05618775e-01\n",
      "   1.15203559e-01  8.77974033e-02]\n",
      " [ 4.28640246e-02  4.29213643e-02  3.37010026e-02  3.70138288e-02\n",
      "   5.41982055e-02  3.17392349e-02]]\n",
      "Episode:    270\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     140.0\n",
      "    Step:   207771\n",
      "    Q value:    0.136085644364357\n",
      "    Loss:   0.13023641705513\n",
      "    Look-up table:\n",
      "[[0.0314247  0.02343994 0.02042931 0.0013994  0.00675058 0.05474475]\n",
      " [0.03449053 0.02692014 0.02413505 0.00521266 0.01016259 0.05720082]\n",
      " [0.04852021 0.0434128  0.04319632 0.02366209 0.02627939 0.0683645 ]\n",
      " ...\n",
      " [0.18140817 0.22545803 0.20390373 0.20292503 0.18509912 0.183281  ]\n",
      " [0.18315482 0.22741926 0.20609528 0.20503789 0.18699026 0.18473083]\n",
      " [0.09173626 0.1244567  0.09216458 0.094836   0.08839226 0.109083  ]]\n",
      "Episode:    280\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     112.25\n",
      "    Step:   215407\n",
      "    Q value:    0.20664680004119873\n",
      "    Loss:   0.0017101563280448318\n",
      "    Look-up table:\n",
      "[[ 0.00495005 -0.01591241 -0.05143428 -0.02486181 -0.02641284  0.00436479]\n",
      " [ 0.00928092 -0.01054084 -0.04544759 -0.01945806 -0.02124155  0.00833088]\n",
      " [ 0.01477295 -0.0035696  -0.03878063 -0.01264876 -0.01468807  0.01335138]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.280581    0.30669445  0.31239164  0.31684411  0.2973991   0.23678967]\n",
      " [ 0.11720365  0.09458572  0.07718378  0.11021906  0.1029076   0.08371902]]\n",
      "Episode:    290\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     140.5\n",
      "    Step:   223138\n",
      "    Q value:    0.1943735033273697\n",
      "    Loss:   0.1357795149087906\n",
      "    Look-up table:\n",
      "[[ 0.02478957 -0.03037435 -0.05409849  0.02455235 -0.00031465  0.07579434]\n",
      " [ 0.02478957 -0.03037435 -0.05409849  0.02455235 -0.00031465  0.07579434]\n",
      " [ 0.02939302 -0.02754295 -0.05202234  0.02503717  0.00251293  0.07758492]\n",
      " ...\n",
      " [ 0.01653242 -0.03099203 -0.0088591  -0.00464654  0.01450354  0.04313594]\n",
      " [ 0.01211458 -0.03773344 -0.01358175 -0.01139361  0.0096845   0.03844857]\n",
      " [-0.06182927 -0.13779485 -0.10544848 -0.10517722 -0.07072884 -0.02653384]]\n",
      "Episode:    300\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     183.25\n",
      "    Step:   231447\n",
      "    Q value:    0.16147707402706146\n",
      "    Loss:   0.0010614576749503613\n",
      "    Look-up table:\n",
      "[[ 2.25998759e-02  3.41725349e-03  1.24703050e-02 -2.36241221e-02\n",
      "   2.75963545e-02  2.59835720e-02]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 2.76657343e-02  8.20326805e-03  1.77304745e-02 -1.82565451e-02\n",
      "   3.18126082e-02  3.06424499e-02]\n",
      " ...\n",
      " [ 1.03396297e-01  1.09393299e-01  1.10732675e-01  5.82593679e-02\n",
      "   1.22493982e-01  1.44414306e-01]\n",
      " [ 1.03793740e-01  1.09928310e-01  1.11236215e-01  5.89135885e-02\n",
      "   1.22913361e-01  1.44779086e-01]\n",
      " [ 8.31723213e-04 -2.91143656e-02 -1.89425945e-02 -1.11023962e-01\n",
      "   1.38731003e-02  4.84928489e-02]]\n",
      "Episode:    310\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     192.5\n",
      "    Step:   239957\n",
      "    Q value:    0.1791585385799408\n",
      "    Loss:   0.0026710317470133305\n",
      "    Look-up table:\n",
      "[[ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.06505299 -0.00630069  0.00778931 -0.09816343  0.01041681  0.04242104]\n",
      " [ 0.0671097  -0.00506079  0.01112998 -0.09574157  0.01196307  0.04318231]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.39084631  0.45781207  0.47033155  0.49525571  0.40578634  0.39581931]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    320\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     204.5\n",
      "    Step:   249502\n",
      "    Q value:    0.19905635714530945\n",
      "    Loss:   0.002747653052210808\n",
      "    Look-up table:\n",
      "[[ 4.25032973e-02 -1.78001523e-02  2.34869123e-02 -1.05833650e-01\n",
      "   3.47887874e-02  5.90296984e-02]\n",
      " [ 2.72732973e-02 -4.07992601e-02  4.19616699e-05 -1.33926988e-01\n",
      "   1.85191035e-02  4.26815748e-02]\n",
      " [ 2.38486528e-02 -4.55523729e-02 -4.49419022e-03 -1.39564633e-01\n",
      "   1.48841739e-02  3.91634703e-02]\n",
      " ...\n",
      " [ 3.12912047e-01  3.65656793e-01  3.67115974e-01  3.47562790e-01\n",
      "   3.13222826e-01  3.09979618e-01]\n",
      " [ 3.26721668e-01  3.86188209e-01  3.86687458e-01  3.70383143e-01\n",
      "   3.28171670e-01  3.25290620e-01]\n",
      " [ 8.43712091e-02  5.01224399e-02  4.67421412e-02 -2.92102098e-02\n",
      "   6.65447116e-02  5.61470389e-02]]\n",
      "Episode:    330\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     203.75\n",
      "    Step:   258339\n",
      "    Q value:    0.1491875946521759\n",
      "    Loss:   0.0022844034247100353\n",
      "    Look-up table:\n",
      "[[ 0.06460536  0.03216892  0.01799881 -0.01849699  0.0538004   0.04472035]\n",
      " [ 0.05479985  0.01776946  0.0032357  -0.03590131  0.04336876  0.03522891]\n",
      " [ 0.05061132  0.01198256 -0.00266945 -0.0428822   0.03895897  0.03037661]\n",
      " ...\n",
      " [ 0.13724029  0.1304903   0.1502164   0.0885067   0.1294837   0.1503557 ]\n",
      " [ 0.13940322  0.13351727  0.15310985  0.09223938  0.13174582  0.1528219 ]\n",
      " [-0.02715588 -0.0996024  -0.06975925 -0.19587481 -0.04170299 -0.03631979]]\n",
      "Episode:    340\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     196.25\n",
      "    Step:   266251\n",
      "    Q value:    0.1614658236503601\n",
      "    Loss:   0.006139599718153477\n",
      "    Look-up table:\n",
      "[[ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.02010095 -0.01009035 -0.01443374 -0.09571171  0.00274682  0.02018356]\n",
      " ...\n",
      " [ 0.19411355  0.17304075  0.16594428  0.07431138  0.15720868  0.17094648]\n",
      " [ 0.18345004  0.15684164  0.15095919  0.05216897  0.14488721  0.15771902]\n",
      " [ 0.03333503 -0.07199776 -0.06197375 -0.26233733 -0.03020293 -0.03024125]]\n",
      "Episode:    350\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     187.25\n",
      "    Step:   274097\n",
      "    Q value:    0.2483154535293579\n",
      "    Loss:   0.005600824020802975\n",
      "    Look-up table:\n",
      "[[ 0.06712711  0.08026993  0.06290579 -0.02781534  0.08571589  0.13300568]\n",
      " [ 0.0606454   0.07254982  0.05470979 -0.04039538  0.07773745  0.12622589]\n",
      " [ 0.05288631  0.06254768  0.04490221 -0.05560458  0.06963503  0.11808342]\n",
      " ...\n",
      " [ 0.2348547   0.19213831  0.25481367  0.16800177  0.21903926  0.2158007 ]\n",
      " [ 0.23847103  0.19728816  0.25941706  0.17594397  0.2229932   0.22019523]\n",
      " [ 0.11065817  0.0163554   0.09713531 -0.10089529  0.08462006  0.0663628 ]]\n",
      "Episode:    360\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     170.75\n",
      "    Step:   281732\n",
      "    Q value:    0.2125164270401001\n",
      "    Loss:   0.002894891193136573\n",
      "    Look-up table:\n",
      "[[ 0.08084482  0.03156459  0.04632699 -0.12640095  0.05420363  0.0393877 ]\n",
      " [ 0.05738604  0.00316823  0.01734567 -0.17726123  0.0298022   0.01246804]\n",
      " [ 0.02219689 -0.03999746 -0.02492023 -0.25148189 -0.00665152 -0.02675802]\n",
      " ...\n",
      " [ 0.08596087  0.10992265  0.10902178 -0.04819572  0.11143935  0.12295586]\n",
      " [ 0.08930129  0.11239076  0.11151063 -0.04261553  0.11301076  0.12574238]\n",
      " [-0.04543573 -0.04368186 -0.04267943 -0.32320559 -0.02020228 -0.01293904]]\n",
      "Episode:    370\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     191.75\n",
      "    Step:   290686\n",
      "    Q value:    0.19755709171295166\n",
      "    Loss:   0.004024291876703501\n",
      "    Look-up table:\n",
      "[[ 0.06136745 -0.0037818   0.02768862 -0.21525085  0.05166972 -0.00660974]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.00961924 -0.07409537 -0.03499758 -0.33596456 -0.00710088 -0.06750709]\n",
      " ...\n",
      " [ 0.19100207  0.2205596   0.21491373  0.1750735   0.23952073  0.18376958]\n",
      " [ 0.21072227  0.24410558  0.23735976  0.21585834  0.26127338  0.20614827]\n",
      " [ 0.02655536  0.01817989  0.02690029 -0.17389023  0.07282352  0.00675309]]\n",
      "Episode:    380\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     198.25\n",
      "    Step:   299020\n",
      "    Q value:    0.237745463848114\n",
      "    Loss:   0.013813065364956856\n",
      "    Look-up table:\n",
      "[[ 0.06856394  0.05221045  0.05362225 -0.19659781  0.0920732   0.07665515]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 0.09182531  0.11801183  0.10132229 -0.06992662  0.08779836  0.08041286]\n",
      " [ 0.08905709  0.11401916  0.098122   -0.07603872  0.08472431  0.0774473 ]\n",
      " [-0.18996704 -0.22822738 -0.22394717 -0.69288957 -0.23234856 -0.22482884]]\n",
      "Episode:    390\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     138.0\n",
      "    Step:   305733\n",
      "    Q value:    0.17399674654006958\n",
      "    Loss:   0.005371232982724905\n",
      "    Look-up table:\n",
      "[[ 0.06202382  0.02310145  0.04760444 -0.11767113  0.02672899  0.07575083]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.0315727  -0.01743507  0.01190281 -0.18520331 -0.01159585  0.04552341]\n",
      " ...\n",
      " [ 0.36112708  0.42049336  0.40115809  0.55530334  0.39320111  0.38604105]\n",
      " [ 0.36358374  0.42363596  0.40386677  0.56066394  0.3961184   0.38859785]\n",
      " [ 0.2324025   0.25517654  0.25859165  0.2721014   0.23968852  0.25262392]]\n",
      "Episode:    400\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     135.75\n",
      "    Step:   313381\n",
      "    Q value:    0.21428035199642181\n",
      "    Loss:   0.0037567047402262688\n",
      "    Look-up table:\n",
      "[[ 0.07011306  0.03325558  0.05465555 -0.16048813  0.06513131  0.07205784]\n",
      " [ 0.06089389  0.02226734  0.04478216 -0.17939377  0.05499089  0.06257832]\n",
      " [ 0.07992291  0.04583931  0.06523192 -0.14023077  0.07910252  0.08294737]\n",
      " ...\n",
      " [ 0.29399955  0.32678485  0.31106329  0.36254799  0.31399083  0.30849934]\n",
      " [ 0.29199684  0.32444882  0.30894041  0.35856831  0.31177497  0.30642223]\n",
      " [ 0.11911833  0.12348306  0.12567103  0.01353407  0.12192774  0.12720299]]\n",
      "Episode:    410\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     169.0\n",
      "    Step:   321241\n",
      "    Q value:    0.35574930906295776\n",
      "    Loss:   0.7632967829704285\n",
      "    Look-up table:\n",
      "[[ 0.13820612  0.12222469  0.13464594 -0.1753397   0.06383777  0.09750271]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.07569528  0.04854798  0.06784558 -0.31360877 -0.01061463  0.03065586]\n",
      " ...\n",
      " [ 0.28407526  0.34133434  0.30221748  0.21090078  0.29586935  0.31307268]\n",
      " [ 0.28222418  0.33912563  0.30021191  0.20687532  0.29373217  0.31110859]\n",
      " [ 0.11987424  0.14253914  0.12174404 -0.14977932  0.10191941  0.13632095]]\n",
      "Episode:    420\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     155.0\n",
      "    Step:   328755\n",
      "    Q value:    0.5738406777381897\n",
      "    Loss:   0.9395275115966797\n",
      "    Look-up table:\n",
      "[[ 0.20427668  0.19167876  0.2024833   0.02226567  0.15529943  0.19631171]\n",
      " [ 0.17427599  0.15508914  0.17002928 -0.04049277  0.11838269  0.16404462]\n",
      " [ 0.19572616  0.18044508  0.19246221  0.00434041  0.14630044  0.1863457 ]\n",
      " ...\n",
      " [ 0.3309257   0.3154074   0.25027013  0.2921102   0.32228255  0.30818844]\n",
      " [ 0.33643603  0.32235539  0.25682759  0.30373168  0.32902455  0.3143425 ]\n",
      " [ 0.02018213 -0.07707191 -0.11838412 -0.36113262 -0.05583477 -0.03783453]]\n",
      "Episode:    430\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     161.0\n",
      "    Step:   337599\n",
      "    Q value:    0.2479272484779358\n",
      "    Loss:   0.003347376361489296\n",
      "    Look-up table:\n",
      "[[ 0.08060741  0.09013498  0.07747471 -0.15830278  0.06898236  0.07837796]\n",
      " [ 0.08242929  0.0893805   0.07676136 -0.15962338  0.06905866  0.07936633]\n",
      " [ 0.08807695  0.0960238   0.08313859 -0.14782166  0.07594228  0.08557618]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.51258039  0.5363977   0.54186392  0.69858003  0.56980145  0.52157772]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    440\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     174.75\n",
      "    Step:   344922\n",
      "    Q value:    0.39304935932159424\n",
      "    Loss:   0.00573453214019537\n",
      "    Look-up table:\n",
      "[[ 1.33589029e-01  1.01741672e-01  1.38266563e-01 -3.24602842e-01\n",
      "   9.37386751e-02  4.39922810e-02]\n",
      " [ 1.61809921e-01  1.34107351e-01  1.67510748e-01 -2.63527155e-01\n",
      "   1.25919461e-01  7.59987831e-02]\n",
      " [ 1.79620743e-01  1.55942202e-01  1.87796831e-01 -2.22374201e-01\n",
      "   1.48210645e-01  9.75847244e-02]\n",
      " ...\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 2.43450522e-01  2.29081273e-01  2.57668018e-01  8.70156288e-03\n",
      "   2.12478280e-01  2.18738079e-01]\n",
      " [ 7.38700628e-02  2.25688219e-02  6.44459724e-02 -3.62151861e-01\n",
      "  -2.95996666e-04  2.30879784e-02]]\n",
      "Episode:    450\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     135.25\n",
      "    Step:   351063\n",
      "    Q value:    0.22631283104419708\n",
      "    Loss:   0.003917249850928783\n",
      "    Look-up table:\n",
      "[[ 0.19564044  0.15552008  0.15603817  0.07708025  0.134408    0.15895748]\n",
      " [ 0.22304142  0.19039023  0.18996418  0.13267946  0.16971874  0.19160366]\n",
      " [ 0.22160876  0.18805087  0.18841422  0.12983418  0.17046738  0.19166028]\n",
      " ...\n",
      " [ 0.19372046  0.21867943  0.21030426  0.07560372  0.18456864  0.20258212]\n",
      " [ 0.20492136  0.23228359  0.22359943  0.09831452  0.19846463  0.21549106]\n",
      " [-0.00100374 -0.02146089 -0.02626479 -0.32687211 -0.06265223 -0.0252676 ]]\n",
      "Episode:    460\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     134.5\n",
      "    Step:   358941\n",
      "    Q value:    0.4494103193283081\n",
      "    Loss:   0.3883872628211975\n",
      "    Look-up table:\n",
      "[[ 0.13521087  0.09029984  0.11181569 -0.24985456  0.13261068  0.11342502]\n",
      " [ 0.11382186  0.06298852  0.08524251 -0.29647779  0.10557401  0.08819079]\n",
      " [ 0.09948349  0.04799724  0.06977451 -0.32548118  0.08890581  0.07436621]\n",
      " ...\n",
      " [ 0.10835981  0.04965138  0.03134799 -0.20531011  0.04591644  0.07147181]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.04248405 -0.14678073 -0.16468728 -0.52188778 -0.15601802 -0.11057484]]\n",
      "Episode:    470\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     161.25\n",
      "    Step:   366577\n",
      "    Q value:    0.3440116047859192\n",
      "    Loss:   0.016213180497288704\n",
      "    Look-up table:\n",
      "[[0.10985601 0.12734485 0.11636996 0.10573983 0.08506548 0.11949313]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.08704376 0.10001016 0.09180284 0.0736351  0.05717742 0.09533763]\n",
      " ...\n",
      " [0.91865218 1.23510718 1.0597235  1.49478698 1.15168464 1.10728896]\n",
      " [0.92223883 1.23891187 1.06431365 1.50227332 1.15653515 1.11123419]\n",
      " [0.66781366 0.85742074 0.74433053 0.85491967 0.80169761 0.78029001]]\n",
      "Episode:    480\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     170.0\n",
      "    Step:   374685\n",
      "    Q value:    1.1791374683380127\n",
      "    Loss:   0.7556827068328857\n",
      "    Look-up table:\n",
      "[[ 0.07581949  0.03884065  0.08022034  0.02616501  0.06901133  0.01842225]\n",
      " [ 0.0602423   0.02754939  0.07081139  0.04602003  0.0588901   0.00229895]\n",
      " [ 0.04008496  0.00682771  0.04816687  0.01107979  0.0351665  -0.02063274]\n",
      " ...\n",
      " [ 0.50017691  0.59670043  0.55556571  0.56794882  0.5752095   0.61153913]\n",
      " [ 0.50378823  0.6027593   0.56210518  0.58407259  0.58248532  0.61624014]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    490\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     189.0\n",
      "    Step:   382964\n",
      "    Q value:    0.22936439514160156\n",
      "    Loss:   0.2983187139034271\n",
      "    Look-up table:\n",
      "[[ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.10325968 -0.11255336 -0.07356691 -0.19233751 -0.09637547 -0.09181082]\n",
      " [-0.10064495 -0.11808658 -0.08556151 -0.25569081 -0.10792851 -0.09718835]\n",
      " ...\n",
      " [ 0.33896601  0.3525629   0.32778275  0.17347693  0.33507037  0.38932335]\n",
      " [ 0.33184898  0.34019196  0.31181741  0.14070559  0.32075679  0.38020122]\n",
      " [-0.58581889 -0.8952893  -1.04066646 -2.38524389 -1.06829989 -0.82866728]]\n",
      "Episode:    500\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     163.75\n",
      "    Step:   389972\n",
      "    Q value:    0.2571696639060974\n",
      "    Loss:   0.011286713182926178\n",
      "    Look-up table:\n",
      "[[-0.06438076 -0.04468358 -0.01358938 -0.04084039 -0.03567922  0.02201259]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.11690009 -0.10411453 -0.07055211 -0.11478853 -0.09976065 -0.03324604]\n",
      " ...\n",
      " [ 0.45397925  0.40841484  0.42601383  0.15601444  0.39505196  0.41991568]\n",
      " [ 0.44293195  0.39284039  0.40763807  0.13273215  0.37809443  0.40418518]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    510\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     137.0\n",
      "    Step:   397148\n",
      "    Q value:    0.26069527864456177\n",
      "    Loss:   0.0023167221806943417\n",
      "    Look-up table:\n",
      "[[-7.80855417e-02 -4.18293476e-02 -4.03635502e-02 -6.30793571e-02\n",
      "  -9.75012779e-04 -5.11379242e-02]\n",
      " [-1.13521695e-01 -8.15249681e-02 -7.87751675e-02 -1.12278223e-01\n",
      "  -4.21787500e-02 -9.13095474e-02]\n",
      " [-1.17973089e-01 -8.45242739e-02 -8.02689791e-02 -1.02293730e-01\n",
      "  -4.26338911e-02 -9.27546024e-02]\n",
      " ...\n",
      " [-6.67202473e-02 -1.22553110e-01 -7.41541386e-02 -2.24873066e-01\n",
      "  -1.65051699e-01 -1.16484761e-01]\n",
      " [-6.28528595e-02 -1.13205791e-01 -6.70640469e-02 -2.02580214e-01\n",
      "  -1.58096194e-01 -1.09727144e-01]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]]\n",
      "Episode:    520\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     146.25\n",
      "    Step:   404729\n",
      "    Q value:    0.5027461647987366\n",
      "    Loss:   0.010354572907090187\n",
      "    Look-up table:\n",
      "[[-0.01451313 -0.02086258 -0.00288987 -0.12404418 -0.05412292 -0.00199568]\n",
      " [-0.06688249 -0.07216024 -0.05112886 -0.14859748 -0.10618949 -0.04273999]\n",
      " [-0.07253766 -0.07160378 -0.05238235 -0.1130743  -0.1026206  -0.03569067]\n",
      " ...\n",
      " [ 0.32844687  0.33103979  0.31208372  0.14186502  0.30880201  0.27855825]\n",
      " [ 0.33298254  0.33647954  0.31779814  0.15046334  0.31503522  0.28429174]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    530\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     142.5\n",
      "    Step:   411869\n",
      "    Q value:    0.18999354541301727\n",
      "    Loss:   0.014132391661405563\n",
      "    Look-up table:\n",
      "[[-0.13812804 -0.13779867 -0.1334511   0.06827855  0.03195298 -0.10256398]\n",
      " [-0.17823994 -0.19276595 -0.19710648 -0.03847241 -0.04448307 -0.16636503]\n",
      " [-0.15545297 -0.16393673 -0.16521728  0.00044799 -0.01400208 -0.13816309]\n",
      " ...\n",
      " [ 0.14004517  0.23418212  0.28762448  0.37882066  0.36895049  0.2642746 ]\n",
      " [ 0.1417228   0.23831999  0.29292691  0.39123654  0.37685502  0.26996279]\n",
      " [-0.2073586  -0.17780554 -0.15068579 -0.29437256 -0.11864495 -0.18526387]]\n",
      "Episode:    540\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     138.0\n",
      "    Step:   418768\n",
      "    Q value:    0.17407412827014923\n",
      "    Loss:   0.008058376610279083\n",
      "    Look-up table:\n",
      "[[-0.25104272 -0.10878801 -0.03671563 -0.07140207 -0.07155907 -0.01252711]\n",
      " [-0.2786721  -0.14298141 -0.08313072 -0.16749835 -0.12781799 -0.06044579]\n",
      " [-0.27417958 -0.14066708 -0.0843904  -0.17717862 -0.1309613  -0.06127989]\n",
      " ...\n",
      " [-0.21574926 -0.23577082 -0.31000733 -0.84043407 -0.47517157 -0.34562802]\n",
      " [-0.21153104 -0.22636497 -0.29538739 -0.80439639 -0.45577323 -0.32793629]\n",
      " [-0.45445049 -0.45735157 -0.50363135 -1.02112365 -0.67592847 -0.54768765]]\n",
      "Episode:    550\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     173.75\n",
      "    Step:   426774\n",
      "    Q value:    0.4642380475997925\n",
      "    Loss:   0.1705051064491272\n",
      "    Look-up table:\n",
      "[[-0.03536868 -0.00394404 -0.07343674 -0.1548667  -0.09623921 -0.01279724]\n",
      " [-0.09031367 -0.03311229 -0.08378291 -0.12084961 -0.11558878 -0.04391575]\n",
      " [-0.09472346 -0.02927518 -0.07319331 -0.09523392 -0.10655558 -0.03904438]\n",
      " ...\n",
      " [ 0.10707092  0.1570034   0.15724444  0.03165054  0.2016027   0.14417505]\n",
      " [ 0.12303364  0.16659451  0.17179215  0.0339694   0.21693611  0.15397453]\n",
      " [-0.25369608 -0.33246505 -0.49869764 -0.90101528 -0.44308043 -0.37415612]]\n",
      "Episode:    560\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     185.25\n",
      "    Step:   433734\n",
      "    Q value:    0.3735770583152771\n",
      "    Loss:   0.28990909457206726\n",
      "    Look-up table:\n",
      "[[-0.07878995 -0.03121305 -0.01532674 -0.16754246  0.03568208  0.06227243]\n",
      " [-0.1341939  -0.07194209 -0.04414606 -0.1791625   0.00797677  0.03159904]\n",
      " [-0.13417244 -0.06406891 -0.02682257 -0.14516497  0.02468944  0.04576969]\n",
      " ...\n",
      " [ 0.36078     0.41471934  0.52243733  0.45903587  0.46659148  0.46510673]\n",
      " [ 0.38129008  0.43455625  0.53997588  0.47902203  0.48473477  0.48346782]\n",
      " [-0.03019631 -0.12370896 -0.15843379 -0.56223345 -0.2422595  -0.17125261]]\n",
      "Episode:    570\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     155.25\n",
      "    Step:   441454\n",
      "    Q value:    0.43010884523391724\n",
      "    Loss:   0.03715215623378754\n",
      "    Look-up table:\n",
      "[[-0.00128484 -0.04824853 -0.1073854  -0.44156003 -0.09653497 -0.10659027]\n",
      " [-0.02071154 -0.06051767 -0.11240876 -0.40675688 -0.0883683  -0.11250508]\n",
      " [-0.02148116 -0.05754769 -0.1067698  -0.38658571 -0.07894742 -0.10740185]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.2828232   0.41296494  0.541188    0.98897076  0.65656316  0.48773146]\n",
      " [ 0.07102859  0.12331975  0.19328523  0.40001392  0.26169336  0.16121411]]\n",
      "Episode:    580\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     133.0\n",
      "    Step:   447747\n",
      "    Q value:    0.3697581887245178\n",
      "    Loss:   0.33394667506217957\n",
      "    Look-up table:\n",
      "[[-0.06113994 -0.0763787   0.08480334 -0.00269222  0.02382922  0.03393447]\n",
      " [-0.11018348 -0.13156176  0.02866077 -0.07698917 -0.03636217 -0.02210343]\n",
      " [-0.11932206 -0.14665282  0.01149774 -0.11234212 -0.05765283 -0.04095697]\n",
      " ...\n",
      " [ 0.82263899  0.86527073  0.86909926  0.71988225  0.85146487  0.83447063]\n",
      " [ 0.81237745  0.85303509  0.85418379  0.69623113  0.83550036  0.81997478]\n",
      " [ 0.29206038  0.14841592 -0.00323176 -0.74760509 -0.00793743  0.03846598]]\n",
      "Episode:    590\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     166.75\n",
      "    Step:   456314\n",
      "    Q value:    1.214055061340332\n",
      "    Loss:   0.418870747089386\n",
      "    Look-up table:\n",
      "[[-0.03848183 -0.14280224 -0.16458023 -0.31075263 -0.19836092 -0.15825367]\n",
      " [-0.01659298 -0.12301934 -0.14162982 -0.2526505  -0.1734246  -0.13118863]\n",
      " [-0.01128328 -0.11811554 -0.13542271 -0.23941755 -0.16651165 -0.12427926]\n",
      " ...\n",
      " [ 0.26405048  0.24315357  0.21904051  0.15413165  0.25970185  0.24749279]\n",
      " [ 0.24172044  0.22003245  0.18877327  0.1168375   0.22664499  0.22080767]\n",
      " [-0.15928054 -0.23452687 -0.33685386 -0.55538845 -0.29211569 -0.26018751]]\n",
      "Episode:    600\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     201.5\n",
      "    Step:   464637\n",
      "    Q value:    0.44933420419692993\n",
      "    Loss:   0.726283073425293\n",
      "    Look-up table:\n",
      "[[ 0.0725081   0.13589358  0.06356692 -0.06181216  0.02223706  0.12674153]\n",
      " [ 0.11423302  0.17985189  0.11293244  0.00504708  0.08047307  0.17623878]\n",
      " [ 0.10692978  0.17192781  0.10384679 -0.00665545  0.07098019  0.16802764]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.32892287  0.06457829 -0.01201081 -0.24716973  0.05929184  0.03168881]]\n",
      "Episode:    610\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     216.0\n",
      "    Step:   473883\n",
      "    Q value:    0.6081070899963379\n",
      "    Loss:   0.007604627870023251\n",
      "    Look-up table:\n",
      "[[ 0.15965939  0.12473536  0.05835664 -0.05759645  0.15421605  0.10257876]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.15258288  0.11795533  0.04900193 -0.06905627  0.14400351  0.09408975]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.27853405  0.32840228  0.30201995  0.16971588  0.23067319  0.29497242]]\n",
      "Episode:    620\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     188.0\n",
      "    Step:   480726\n",
      "    Q value:    0.515997052192688\n",
      "    Loss:   0.005671539343893528\n",
      "    Look-up table:\n",
      "[[ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.17239022  0.13066268  0.07105672 -0.12902236  0.13614249  0.10747278]\n",
      " [ 0.16516554  0.12526107  0.06189799 -0.14022756  0.13000226  0.10148287]\n",
      " ...\n",
      " [ 0.38834083  0.41667163  0.40132082  0.32200289  0.38905978  0.40716219]\n",
      " [ 0.37120891  0.39756179  0.37937498  0.29452729  0.36396217  0.38728464]\n",
      " [ 0.03420711  0.02201819 -0.0522294  -0.24569488 -0.08484268 -0.02552664]]\n",
      "Episode:    630\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     163.0\n",
      "    Step:   488904\n",
      "    Q value:    0.4922266900539398\n",
      "    Loss:   0.006496616173535585\n",
      "    Look-up table:\n",
      "[[0.20897877 0.16235137 0.11305058 0.06231856 0.12712407 0.12883556]\n",
      " [0.19747365 0.14896178 0.09798729 0.04455256 0.11151528 0.11406982]\n",
      " [0.18043327 0.13352501 0.08058548 0.02409649 0.09340894 0.09407675]\n",
      " ...\n",
      " [0.27565169 0.29061139 0.23754394 0.15882349 0.21721303 0.29259861]\n",
      " [0.27239621 0.28408527 0.2317034  0.1530664  0.20964551 0.28560889]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    640\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     166.75\n",
      "    Step:   496292\n",
      "    Q value:    0.4267233908176422\n",
      "    Loss:   0.009829537943005562\n",
      "    Look-up table:\n",
      "[[ 0.15939879  0.16416049  0.08791578 -0.02361941  0.08348417  0.09038019]\n",
      " [ 0.13660884  0.13889194  0.05931318 -0.0576179   0.05332422  0.06215048]\n",
      " [ 0.12624562  0.13044369  0.04667366 -0.06945324  0.04451084  0.05106294]\n",
      " ...\n",
      " [ 0.2791642   0.21432519  0.23142648  0.1057322   0.198457    0.20180762]\n",
      " [ 0.2936182   0.23207676  0.24767065  0.12388086  0.21595407  0.21551096]\n",
      " [ 0.21221066  0.1372968   0.14546156 -0.00038099  0.10529923  0.11298907]]\n",
      "Episode:    650\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     157.75\n",
      "    Step:   504539\n",
      "    Q value:    0.5164380073547363\n",
      "    Loss:   0.004866529256105423\n",
      "    Look-up table:\n",
      "[[ 0.10496521  0.06492579  0.0258112  -0.10119963 -0.06310964  0.08179605]\n",
      " [ 0.14254951  0.10691607  0.07077217 -0.04859495 -0.01204038  0.12525499]\n",
      " [ 0.14256847  0.10553336  0.06939995 -0.0498538  -0.01343775  0.12523711]\n",
      " ...\n",
      " [ 0.28671443  0.26267326  0.23326683  0.18629575  0.18011975  0.24684811]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.01808167 -0.03768086 -0.08907747 -0.18153477 -0.18519306 -0.07394171]]\n",
      "Episode:    660\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     192.75\n",
      "    Step:   515131\n",
      "    Q value:    0.43183082342147827\n",
      "    Loss:   0.004384366795420647\n",
      "    Look-up table:\n",
      "[[ 0.22175729  0.20570445  0.16114175  0.11854053  0.06819153  0.12810659]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.25319767  0.23403955  0.19482458  0.15173984  0.10694337  0.16247201]\n",
      " ...\n",
      " [ 0.41742134  0.37485504  0.38678324  0.3600235   0.36296916  0.3960731 ]\n",
      " [ 0.41852856  0.376091    0.38815463  0.36146927  0.36444163  0.3973825 ]\n",
      " [ 0.01917398 -0.07279813 -0.10680544 -0.16189957 -0.16858482 -0.07665789]]\n",
      "Episode:    670\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     202.5\n",
      "    Step:   523588\n",
      "    Q value:    0.49330440163612366\n",
      "    Loss:   1.527288556098938\n",
      "    Look-up table:\n",
      "[[ 0.28375149  0.24162519  0.25436592  0.21417689  0.21821332  0.25876558]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.28498101  0.24452317  0.25999999  0.21655345  0.22558165  0.25956023]\n",
      " ...\n",
      " [ 0.09395492  0.06840432  0.06400466  0.02837992 -0.0819757   0.0871284 ]\n",
      " [ 0.10026586  0.07244408  0.06851673  0.03300142 -0.07929564  0.09266353]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    680\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     166.75\n",
      "    Step:   531587\n",
      "    Q value:    0.5018103122711182\n",
      "    Loss:   0.002007397823035717\n",
      "    Look-up table:\n",
      "[[0.22724771 0.20790541 0.13765407 0.1676991  0.06487656 0.17899609]\n",
      " [0.2395978  0.22128546 0.15352321 0.18254781 0.08236694 0.1931963 ]\n",
      " [0.24082458 0.22258902 0.15511823 0.18284929 0.08293247 0.19457972]\n",
      " ...\n",
      " [1.1237067  1.19702959 1.30049992 1.25499487 1.35437489 1.21272814]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.62638831 0.66768646 0.66926932 0.66779149 0.65909338 0.64392889]]\n",
      "Episode:    690\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     176.0\n",
      "    Step:   540603\n",
      "    Q value:    0.5177162885665894\n",
      "    Loss:   0.005658075213432312\n",
      "    Look-up table:\n",
      "[[ 0.20333385  0.18030691  0.13477302  0.155797    0.0928998   0.18461525]\n",
      " [ 0.20996249  0.18903911  0.14602613  0.16653943  0.10396385  0.19477892]\n",
      " [ 0.20211756  0.18035305  0.13591528  0.15697217  0.09288597  0.18577242]\n",
      " ...\n",
      " [ 0.13192189  0.06072319  0.08302975  0.0605278   0.04165745  0.08430898]\n",
      " [ 0.1476804   0.07865608  0.10291958  0.07986832  0.063344    0.10259664]\n",
      " [-0.01250863 -0.10661995 -0.10393834 -0.11861801 -0.16080642 -0.08509564]]\n",
      "Episode:    700\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     233.75\n",
      "    Step:   550643\n",
      "    Q value:    0.38460099697113037\n",
      "    Loss:   0.12373003363609314\n",
      "    Look-up table:\n",
      "[[ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 8.08542967e-02  4.89578247e-02 -3.47235203e-02  4.07197475e-02\n",
      "  -3.74774933e-02 -9.80483294e-02]\n",
      " [ 1.03340149e-01  8.00672770e-02 -1.23977661e-05  6.27903938e-02\n",
      "  -9.80496407e-03 -5.05849123e-02]\n",
      " ...\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 3.64050150e-01  4.31347847e-01  4.13863420e-01  3.66766334e-01\n",
      "   3.37629318e-01  4.77311134e-01]\n",
      " [ 2.33186483e-02  3.50468159e-02 -2.47986317e-02 -2.85122395e-02\n",
      "  -1.29606247e-01  1.01161003e-02]]\n",
      "Episode:    710\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     198.25\n",
      "    Step:   558348\n",
      "    Q value:    0.3531399071216583\n",
      "    Loss:   0.01283598504960537\n",
      "    Look-up table:\n",
      "[[ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.08775866  0.03454757 -0.00480247  0.04194999 -0.09741044 -0.01272702]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.06634867  0.09810269  0.03999376  0.02934384 -0.1658864   0.07680106]\n",
      " [-0.33216274 -0.38351858 -0.47340775 -0.45125151 -0.76975226 -0.52494359]]\n",
      "Episode:    720\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     178.0\n",
      "    Step:   568154\n",
      "    Q value:    0.286649614572525\n",
      "    Loss:   0.01902824454009533\n",
      "    Look-up table:\n",
      "[[-9.86349583e-02 -2.22553015e-02 -9.06846523e-02 -2.60572433e-01\n",
      "  -2.56024837e-01 -1.03383780e-01]\n",
      " [-9.61141586e-02  8.74626637e-03 -7.48317242e-02 -2.49786139e-01\n",
      "  -2.15282440e-01 -2.71756649e-02]\n",
      " [-8.41484070e-02  3.23746204e-02 -5.28059006e-02 -2.26164103e-01\n",
      "  -1.87359810e-01  1.84345245e-03]\n",
      " ...\n",
      " [ 2.48578787e-02  1.40844941e-01 -1.47586107e-01 -2.50537395e-02\n",
      "  -2.13389397e-02  7.87746906e-02]\n",
      " [ 3.81237268e-02  1.62521243e-01 -1.38486624e-01 -2.74038315e-03\n",
      "  -3.66449356e-04  1.05349064e-01]\n",
      " [-1.65345907e-01 -2.55418420e-01 -5.23402452e-01 -3.21532249e-01\n",
      "  -5.63467979e-01 -6.33515835e-01]]\n",
      "Episode:    730\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     197.5\n",
      "    Step:   575625\n",
      "    Q value:    0.2994651198387146\n",
      "    Loss:   0.004629757255315781\n",
      "    Look-up table:\n",
      "[[ 0.07771206  0.0679251  -0.05777097  0.00695825  0.0873754   0.05745792]\n",
      " [ 0.05553949  0.07134783 -0.0369575  -0.01548529  0.10490179  0.10913944]\n",
      " [ 0.09075069  0.10599208  0.01082277  0.02537656  0.1482358   0.14306688]\n",
      " ...\n",
      " [ 0.28506255  0.37083662  0.18886137  0.29469466  0.3348937   0.31249547]\n",
      " [ 0.27269745  0.36563718  0.20086133  0.27638507  0.33137846  0.3142066 ]\n",
      " [-0.28224027 -0.67168212 -0.81507611 -0.58336496 -1.02935147 -1.54679036]]\n",
      "Episode:    740\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     136.5\n",
      "    Step:   581753\n",
      "    Q value:    0.5520095825195312\n",
      "    Loss:   0.07604466378688812\n",
      "    Look-up table:\n",
      "[[ 0.04053807  0.05944085 -0.03381443  0.0280993   0.0109899   0.00699067]\n",
      " [ 0.07071614  0.07524371 -0.0070281   0.05925417  0.02571416 -0.00970483]\n",
      " [ 0.10234284  0.12344337  0.03817606  0.10370755  0.08519864  0.06267333]\n",
      " ...\n",
      " [ 1.59430408  1.70223463  1.82340181  1.69181919  1.55991268  1.21926236]\n",
      " [ 1.6351974   1.75680494  1.8583113   1.72279835  1.61062109  1.28783607]\n",
      " [ 1.1613059   1.02041399  1.19863892  1.03572857  0.67013931  0.12855566]]\n",
      "Episode:    750\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     127.0\n",
      "    Step:   589846\n",
      "    Q value:    0.9387613534927368\n",
      "    Loss:   0.02275139093399048\n",
      "    Look-up table:\n",
      "[[-0.07020795 -0.07008696 -0.01458216 -0.08357906 -0.19503903 -0.22104144]\n",
      " [-0.01307762 -0.0128839   0.0524044  -0.01639795 -0.13692594 -0.17633748]\n",
      " [ 0.03733456  0.03241777  0.11287093  0.04409528 -0.10510564 -0.16011357]\n",
      " ...\n",
      " [ 0.19180238  0.27069283  0.2143929   0.15059662  0.2124629   0.23578095]\n",
      " [ 0.19740331  0.26167655  0.21899176  0.15447664  0.2045238   0.21149826]\n",
      " [-0.16645992 -0.23425341 -0.2513063  -0.32227039 -0.44145179 -0.56970119]]\n",
      "Episode:    760\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     145.5\n",
      "    Step:   597073\n",
      "    Q value:    0.28156203031539917\n",
      "    Loss:   0.01492580957710743\n",
      "    Look-up table:\n",
      "[[-0.18640316 -0.22474718 -0.23400998 -0.1995163  -0.27692819 -0.20047212]\n",
      " [-0.17216384 -0.21020055 -0.21820736 -0.18330359 -0.26104522 -0.18866849]\n",
      " [-0.13329077 -0.16795254 -0.17513633 -0.13557076 -0.21267629 -0.14592218]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.18566322  0.21710885  0.24043143  0.25272989  0.21711755  0.06040239]\n",
      " [-0.32328582 -0.37092161 -0.36336541 -0.36219096 -0.52444911 -0.73249674]]\n",
      "Episode:    770\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     142.0\n",
      "    Step:   604476\n",
      "    Q value:    0.22647307813167572\n",
      "    Loss:   0.8024648427963257\n",
      "    Look-up table:\n",
      "[[ 6.05635643e-02 -3.29213142e-02 -1.05857849e-04  3.87947559e-02\n",
      "  -8.35161209e-02 -2.17128992e-01]\n",
      " [ 5.11125326e-02 -3.23524475e-02 -9.56940651e-03  3.26313972e-02\n",
      "  -7.98199177e-02 -2.02116966e-01]\n",
      " [ 4.35920954e-02 -7.33852386e-03 -7.14540482e-04  3.84495258e-02\n",
      "  -4.21173573e-02 -1.32935524e-01]\n",
      " ...\n",
      " [-2.11210608e-01 -1.19205713e-01 -1.76226377e-01 -1.95042133e-01\n",
      "  -1.75735235e-01 -1.60050392e-01]\n",
      " [-2.05095887e-01 -1.18116379e-01 -1.74471140e-01 -1.89485788e-01\n",
      "  -1.68681622e-01 -1.49590015e-01]\n",
      " [-3.96677136e-01 -3.30862045e-01 -3.97559404e-01 -4.16706800e-01\n",
      "  -4.16245937e-01 -3.85555744e-01]]\n",
      "Episode:    780\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     171.5\n",
      "    Step:   612958\n",
      "    Q value:    0.1894414722919464\n",
      "    Loss:   0.023560218513011932\n",
      "    Look-up table:\n",
      "[[ 8.51035118e-04 -1.38294697e-02 -5.93259335e-02 -6.45246506e-02\n",
      "  -1.55454874e-01 -1.37566566e-01]\n",
      " [-1.27327442e-02 -3.50375175e-02 -7.99376965e-02 -7.98287392e-02\n",
      "  -1.80786848e-01 -1.75804615e-01]\n",
      " [-1.87280178e-02 -3.89113426e-02 -8.52019787e-02 -8.52246284e-02\n",
      "  -1.85089827e-01 -1.75495625e-01]\n",
      " ...\n",
      " [ 1.84100866e-02 -9.36338902e-02 -8.01217556e-02 -5.32958508e-02\n",
      "  -8.70232582e-02 -3.92830610e-01]\n",
      " [ 2.76753902e-02 -9.20453072e-02 -7.88345337e-02 -4.16812897e-02\n",
      "  -8.42022896e-02 -3.96937847e-01]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]]\n",
      "Episode:    790\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     163.25\n",
      "    Step:   619743\n",
      "    Q value:    0.3653622269630432\n",
      "    Loss:   0.028261668980121613\n",
      "    Look-up table:\n",
      "[[ 0.01069617  0.06877303  0.04486752  0.04060054  0.09322572  0.05486107]\n",
      " [ 0.0143348   0.07970524  0.05345368  0.04847574  0.10353279  0.07432342]\n",
      " [-0.00943315  0.0414381   0.0151093   0.01239872  0.06004906  0.010185  ]\n",
      " ...\n",
      " [ 0.5021323   0.58689046  0.48255992  0.52228189  0.5812366   0.50511885]\n",
      " [ 0.51279986  0.60423684  0.50061393  0.5389812   0.60186267  0.53555822]\n",
      " [ 0.32498109  0.30330253  0.18442535  0.24614     0.24455953  0.00697732]]\n",
      "Episode:    800\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     159.75\n",
      "    Step:   627296\n",
      "    Q value:    0.38251590728759766\n",
      "    Loss:   0.3084694743156433\n",
      "    Look-up table:\n",
      "[[-0.05046618 -0.02468967  0.04267001  0.00721478  0.11403155 -0.12856817]\n",
      " [-0.05953586 -0.06008625  0.00530601 -0.01885581  0.06789017 -0.21137714]\n",
      " [-0.10334444 -0.09494996 -0.02286363 -0.05294204  0.04336548 -0.2603786 ]\n",
      " ...\n",
      " [ 1.00332022  0.86945152  0.94126701  1.06339431  0.91512942  0.32631898]\n",
      " [ 1.00302362  0.87389374  0.940696    1.06701827  0.91811013  0.33676219]\n",
      " [ 0.57576442  0.25074053  0.2972002   0.50951934  0.23925805 -0.64322782]]\n",
      "Episode:    810\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     163.75\n",
      "    Step:   634508\n",
      "    Q value:    0.32655102014541626\n",
      "    Loss:   0.05467631295323372\n",
      "    Look-up table:\n",
      "[[ 0.03607202  0.08991385 -0.01157045  0.05639315  0.04392385 -0.04942155]\n",
      " [ 0.00360966  0.07402182 -0.03425765  0.02991772  0.02703238 -0.03600025]\n",
      " [-0.00384963  0.06601191 -0.04289746  0.02151442  0.01833773 -0.04466534]\n",
      " ...\n",
      " [ 0.76439404  0.78021884  0.77432632  0.84829867  0.78674078  0.61977339]\n",
      " [ 0.76216066  0.77788556  0.76622796  0.84391212  0.77752233  0.61762881]\n",
      " [-0.18986404 -0.88877559 -0.70900297 -0.57331204 -0.99437022 -2.59040928]]\n",
      "Episode:    820\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     149.5\n",
      "    Step:   641392\n",
      "    Q value:    0.6803948283195496\n",
      "    Loss:   0.1379789561033249\n",
      "    Look-up table:\n",
      "[[ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.04195142 -0.05968213 -0.10571432 -0.11754489 -0.12011814 -0.15821838]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 0.18605375  0.23609161  0.24045372  0.18906808  0.21900558  0.154217  ]\n",
      " [ 0.17865682  0.23078203  0.23742461  0.18316984  0.21922755  0.16414332]\n",
      " [ 0.035532    0.02106714  0.04043651 -0.00479746 -0.00430036 -0.15806508]]\n",
      "Episode:    830\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     160.0\n",
      "    Step:   649110\n",
      "    Q value:    0.6996977925300598\n",
      "    Loss:   0.09432046860456467\n",
      "    Look-up table:\n",
      "[[-0.11283779 -0.14424253 -0.11634421 -0.09266162 -0.14964032 -0.14824796]\n",
      " [-0.16235471 -0.20335507 -0.17434478 -0.14934421 -0.21249127 -0.2147305 ]\n",
      " [-0.17260122 -0.21299314 -0.19189095 -0.16936016 -0.22143269 -0.20553207]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.37963581  0.40757143  0.42784262  0.34458566  0.44170809  0.26711285]\n",
      " [-0.5507412  -1.09992528 -0.87662411 -1.05131316 -1.0372839  -2.28098893]]\n",
      "Episode:    840\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     161.5\n",
      "    Step:   657119\n",
      "    Q value:    0.6096889972686768\n",
      "    Loss:   0.013078881427645683\n",
      "    Look-up table:\n",
      "[[ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.04742336 -0.00157762 -0.11992764 -0.12517405 -0.10086823 -0.09945774]\n",
      " [-0.0791502  -0.03219628 -0.1546948  -0.15988588 -0.13381195 -0.12547779]\n",
      " ...\n",
      " [ 1.26428425  1.32559609  1.23386836  1.09849489  1.03914428  0.96870351]\n",
      " [ 1.24234092  1.30140853  1.22112608  1.09538507  1.03805614  0.96990895]\n",
      " [ 0.38948536  0.09583759  0.20703816  0.16189003 -0.13124132 -0.60905766]]\n",
      "Episode:    850\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     171.5\n",
      "    Step:   665781\n",
      "    Q value:    0.3864626884460449\n",
      "    Loss:   0.012247378937900066\n",
      "    Look-up table:\n",
      "[[-0.10121703 -0.03855348 -0.12210584 -0.01311541 -0.0121088  -0.06256413]\n",
      " [-0.14392042 -0.08099961 -0.16129661 -0.05692005 -0.05978489 -0.12190294]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.71914411  0.6573807   0.6927352   0.6859194   0.61385071  0.41910458]\n",
      " [ 0.54593277  0.4584235   0.49280977  0.4838109   0.38440549  0.12681317]]\n",
      "Episode:    860\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     193.0\n",
      "    Step:   674779\n",
      "    Q value:    0.5647254586219788\n",
      "    Loss:   0.6052532196044922\n",
      "    Look-up table:\n",
      "[[-0.23109746 -0.28736115 -0.30154181 -0.36545014 -0.34612989 -0.38926244]\n",
      " [-0.23133183 -0.28900456 -0.30103707 -0.36412239 -0.34179473 -0.37608862]\n",
      " [-0.22795224 -0.27976918 -0.29312778 -0.35721302 -0.3263967  -0.3509059 ]\n",
      " ...\n",
      " [ 0.41968632  0.44148922  0.41951895  0.43011761  0.45771337  0.38192344]\n",
      " [ 0.4000268   0.43645787  0.414217    0.42850828  0.46942902  0.42969298]\n",
      " [ 0.38073802  0.34811425  0.34929371  0.38217354  0.31265926  0.14704752]]\n",
      "Episode:    870\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     220.5\n",
      "    Step:   683461\n",
      "    Q value:    0.3223606050014496\n",
      "    Loss:   0.026550233364105225\n",
      "    Look-up table:\n",
      "[[-0.19777918 -0.18006659 -0.35650086 -0.17480779 -0.21421862 -0.06348419]\n",
      " [-0.20853138 -0.19079876 -0.37333655 -0.19332719 -0.23432732 -0.09531069]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.1435492  -0.7320838  -0.60891294 -0.57449627 -1.00448561 -1.84319282]]\n",
      "Episode:    880\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     212.0\n",
      "    Step:   692010\n",
      "    Q value:    0.3195520341396332\n",
      "    Loss:   0.11453354358673096\n",
      "    Look-up table:\n",
      "[[-0.21339822 -0.17476392 -0.20233464 -0.20389438 -0.25084329 -0.22867894]\n",
      " [-0.22879887 -0.1943531  -0.2194519  -0.21650124 -0.27227092 -0.24635243]\n",
      " [-0.23531342 -0.20602608 -0.2296524  -0.22792625 -0.28694224 -0.26710439]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    890\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     151.5\n",
      "    Step:   698874\n",
      "    Q value:    0.4660370647907257\n",
      "    Loss:   0.15838415920734406\n",
      "    Look-up table:\n",
      "[[ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.22729158 -0.35863733 -0.28064537 -0.28849673 -0.32609916 -0.35808516]\n",
      " [-0.23884678 -0.37362695 -0.27961373 -0.29961681 -0.32248211 -0.36669278]\n",
      " ...\n",
      " [ 1.06974578  1.27235746  1.18380857  1.18917215  1.34364808  1.42251647]\n",
      " [ 1.06879091  1.27256823  1.18044829  1.18574071  1.34353161  1.42441607]\n",
      " [ 0.78621876  0.95428133  0.83611822  0.84371459  1.01035023  1.03062236]]\n",
      "Episode:    900\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     146.25\n",
      "    Step:   706214\n",
      "    Q value:    0.5249197483062744\n",
      "    Loss:   0.2681146264076233\n",
      "    Look-up table:\n",
      "[[ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.30859756 -0.22012615 -0.25633216 -0.3033371  -0.36400199 -0.28841138]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 0.06629157  0.15585232  0.08930206  0.11613822  0.12786579  0.15584421]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.39604521 -0.40952706 -0.50003743 -0.44830132 -0.54627562 -0.60775423]]\n",
      "Episode:    910\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     145.25\n",
      "    Step:   712355\n",
      "    Q value:    1.0322766304016113\n",
      "    Loss:   0.047566577792167664\n",
      "    Look-up table:\n",
      "[[-0.134197   -0.07709169 -0.05048323 -0.13264203 -0.1258955  -0.19555831]\n",
      " [-0.14978242 -0.08355474 -0.05907202 -0.14407468 -0.13034153 -0.19348407]\n",
      " [-0.13537264 -0.06558275 -0.04680586 -0.13321519 -0.11348271 -0.17034483]\n",
      " ...\n",
      " [ 0.83291328  0.69386351  0.59712923  0.70111489  0.71346438  0.52233803]\n",
      " [ 0.82747591  0.68914282  0.59186554  0.69596982  0.70936728  0.51822805]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    920\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     144.25\n",
      "    Step:   720738\n",
      "    Q value:    0.6984208226203918\n",
      "    Loss:   0.019428059458732605\n",
      "    Look-up table:\n",
      "[[-0.20647478 -0.26598644 -0.35171723 -0.21812701 -0.21420884 -0.16723323]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.24714518 -0.29079819 -0.387537   -0.2595489  -0.23654056 -0.17596865]\n",
      " ...\n",
      " [ 0.45732272  0.4510175   0.51391244  0.46758127  0.3942672   0.218894  ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.39407384  0.43002069  0.49497223  0.39415312  0.31949639  0.12807524]]\n",
      "Episode:    930\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     177.5\n",
      "    Step:   728291\n",
      "    Q value:    0.29315707087516785\n",
      "    Loss:   0.014439473859965801\n",
      "    Look-up table:\n",
      "[[-0.10271287 -0.14522171 -0.17282367 -0.18293309 -0.1338048  -0.27202249]\n",
      " [-0.12730193 -0.1595602  -0.19143653 -0.20009732 -0.14747381 -0.27970338]\n",
      " [-0.121562   -0.13893318 -0.17522287 -0.18455458 -0.13531184 -0.25963688]\n",
      " ...\n",
      " [ 0.24030876  0.28706384  0.31715631  0.32848072  0.2316637   0.09875536]\n",
      " [ 0.24085772  0.28974605  0.31919193  0.33088684  0.23446321  0.10269785]\n",
      " [ 0.25284719  0.24364877  0.28952384  0.29243684  0.18629789  0.02033043]]\n",
      "Episode:    940\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     198.0\n",
      "    Step:   736763\n",
      "    Q value:    0.3419492244720459\n",
      "    Loss:   0.024572327733039856\n",
      "    Look-up table:\n",
      "[[-0.00854754 -0.06297565 -0.11401796 -0.04198003 -0.06360435 -0.10192466]\n",
      " [-0.07811785 -0.10892868 -0.16944766 -0.08811855 -0.11369157 -0.12057877]\n",
      " [-0.07087612 -0.10459518 -0.16282535 -0.07841587 -0.09037805 -0.11268497]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.34440076  0.1942544   0.29302502  0.2215507   0.18086767  0.07321739]\n",
      " [ 0.10928738 -0.07700586  0.04020858 -0.0430069  -0.07177734 -0.19909954]]\n",
      "Episode:    950\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     162.25\n",
      "    Step:   743106\n",
      "    Q value:    0.47088921070098877\n",
      "    Loss:   0.01193240936845541\n",
      "    Look-up table:\n",
      "[[-0.0043695   0.07069969  0.02449441  0.05288982  0.03722167  0.06487942]\n",
      " [-0.08967042 -0.04468989 -0.07531285 -0.05324364 -0.07788038 -0.05158448]\n",
      " [-0.07918429 -0.03457737 -0.06494284 -0.04269385 -0.06713796 -0.04233861]\n",
      " ...\n",
      " [ 0.34721172  0.32247317  0.29579747  0.35482407  0.41461444  0.09912324]\n",
      " [ 0.35535777  0.32866955  0.30400932  0.36722159  0.42379045  0.10657573]\n",
      " [ 0.02899981 -0.00642467 -0.01669884  0.05386043  0.13383722 -0.23156476]]\n",
      "Episode:    960\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     147.25\n",
      "    Step:   751104\n",
      "    Q value:    0.23366740345954895\n",
      "    Loss:   0.004158042371273041\n",
      "    Look-up table:\n",
      "[[-7.71939754e-02 -9.52792168e-03  8.60929489e-04 -1.61798000e-02\n",
      "  -9.72325802e-02  1.28812790e-02]\n",
      " [-9.82370377e-02 -1.82445049e-02 -1.31566525e-02 -2.58915424e-02\n",
      "  -9.69688892e-02  7.19070435e-04]\n",
      " [-8.73341560e-02 -8.46457481e-03 -3.03220749e-03 -1.43785477e-02\n",
      "  -8.37368965e-02  7.81440735e-03]\n",
      " ...\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [-9.95767117e-02 -9.16736126e-02 -8.96582603e-02 -1.03993654e-01\n",
      "  -9.15989876e-02 -3.79002094e-02]\n",
      " [-2.96226501e-01 -3.35052729e-01 -3.22781563e-01 -3.38930130e-01\n",
      "  -3.14584494e-01 -3.02528620e-01]]\n",
      "Episode:    970\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     177.25\n",
      "    Step:   758789\n",
      "    Q value:    0.3156764507293701\n",
      "    Loss:   0.4617350399494171\n",
      "    Look-up table:\n",
      "[[-0.09709334 -0.10485363 -0.03559208  0.01069999 -0.00300837 -0.06424356]\n",
      " [-0.09459114 -0.09547782 -0.02395797  0.01782656  0.009161   -0.04251528]\n",
      " [-0.08664441 -0.09485626 -0.01889348  0.02044296  0.01401711 -0.04739118]\n",
      " ...\n",
      " [ 0.23414159  0.26107287  0.28674495  0.30407906  0.39026856  0.27400672]\n",
      " [ 0.22485626  0.25344133  0.27662694  0.29568267  0.37710977  0.26712716]\n",
      " [ 0.25243163  0.27259278  0.30481958  0.31774855  0.41453695  0.28318477]]\n",
      "Episode:    980\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     175.0\n",
      "    Step:   766448\n",
      "    Q value:    0.3706582188606262\n",
      "    Loss:   0.013830744661390781\n",
      "    Look-up table:\n",
      "[[-0.0782485  -0.11601424 -0.08856201 -0.16478014 -0.04404545 -0.28058815]\n",
      " [-0.06846523 -0.10436893 -0.07738566 -0.15318131 -0.03321552 -0.26716638]\n",
      " [-0.0713551  -0.10823846 -0.0812912  -0.1569612  -0.03912354 -0.27129817]\n",
      " ...\n",
      " [ 0.11159039  0.04232836  0.11047816  0.08386421  0.15752506 -0.00633454]\n",
      " [ 0.11672258  0.04963756  0.11645699  0.08871412  0.16301441  0.00726676]\n",
      " [-0.07485032 -0.14845538 -0.0707171  -0.11024189 -0.03303742 -0.1722014 ]]\n",
      "Episode:    990\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     170.0\n",
      "    Step:   773680\n",
      "    Q value:    0.3743828535079956\n",
      "    Loss:   0.005877440329641104\n",
      "    Look-up table:\n",
      "[[-0.04723692 -0.05727577 -0.07169151 -0.01014519 -0.08159947 -0.03244519]\n",
      " [-0.03204298 -0.05038261 -0.0599823   0.00307655 -0.06815648 -0.03312421]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 0.31364524  0.20797563  0.28882766  0.25324261  0.24087214  0.07469559]\n",
      " [ 0.30958796  0.20918036  0.2865603   0.25173473  0.24106193  0.07859945]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    1000\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.15000000000000002\n",
      "    Rolling avg. 20 reward:     190.75\n",
      "    Step:   781407\n",
      "    Q value:    0.30661940574645996\n",
      "    Loss:   0.016626307740807533\n",
      "    Look-up table:\n",
      "[[ 2.37131119e-03 -1.15425587e-02  9.06324387e-03 -4.47368622e-02\n",
      "   5.00202179e-04 -4.23839092e-02]\n",
      " [-2.09712982e-03 -2.49178410e-02  9.88245010e-04 -5.40392399e-02\n",
      "  -1.00238323e-02 -6.05087280e-02]\n",
      " [ 2.72221565e-02  4.02140617e-03  3.05852890e-02 -2.29258537e-02\n",
      "   2.04725266e-02 -3.24392319e-02]\n",
      " ...\n",
      " [ 5.92223167e-01  6.72462702e-01  5.88282347e-01  5.86517572e-01\n",
      "   5.97659111e-01  6.81346416e-01]\n",
      " [ 6.18780851e-01  6.79450512e-01  6.08152270e-01  6.07751369e-01\n",
      "   6.16089582e-01  6.78539276e-01]\n",
      " [ 5.18707514e-01  4.61378336e-01  4.15205359e-01  4.69481230e-01\n",
      "   4.07169461e-01  3.52506161e-01]]\n",
      "Training finished at 1000 episodes!\n",
      "    Final epsilon:  0.15000000000000002\n",
      "    Final Rolling avg. 20 reward:   190.75\n",
      "    Final look-up table\n",
      "[[ 2.37131119e-03 -1.15425587e-02  9.06324387e-03 -4.47368622e-02\n",
      "   5.00202179e-04 -4.23839092e-02]\n",
      " [-2.09712982e-03 -2.49178410e-02  9.88245010e-04 -5.40392399e-02\n",
      "  -1.00238323e-02 -6.05087280e-02]\n",
      " [ 2.72221565e-02  4.02140617e-03  3.05852890e-02 -2.29258537e-02\n",
      "   2.04725266e-02 -3.24392319e-02]\n",
      " ...\n",
      " [ 5.92223167e-01  6.72462702e-01  5.88282347e-01  5.86517572e-01\n",
      "   5.97659111e-01  6.81346416e-01]\n",
      " [ 6.18780851e-01  6.79450512e-01  6.08152270e-01  6.07751369e-01\n",
      "   6.16089582e-01  6.78539276e-01]\n",
      " [ 5.18707514e-01  4.61378336e-01  4.15205359e-01  4.69481230e-01\n",
      "   4.07169461e-01  3.52506161e-01]]\n",
      "\u001B[32m[I 2022-06-07 06:47:17,190]\u001B[0m Trial 3 finished with value: 190.75 and parameters: {'exploration_rate_decay': 0.999975, 'exploration_rate_min': 0.15000000000000002, 'batch_size': 32, 'gamma': 0.9, 'lr': 0.00030000000000000003, 'learn_every': 2, 'sync_every': 10000}. Best is trial 2 with value: 286.5.\u001B[0m\n",
      "Current Params:\n",
      "    exploration_rate_decay: 0.99999975\n",
      "    exploration_rate_min: 0.05\n",
      "    batch_size: 32\n",
      "    gamma: 0.92\n",
      "    lr: 0.0004\n",
      "    learn_every: 4\n",
      "    sync_every: 10000\n",
      "\n",
      "Episode:    10\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9982719945072365\n",
      "    Rolling avg. 20 reward:     111.5\n",
      "    Step:   6918\n",
      "    Q value:    None\n",
      "    Loss:   0\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    20\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9966294427020114\n",
      "    Rolling avg. 20 reward:     120.0\n",
      "    Step:   13505\n",
      "    Q value:    0.0101170614361763\n",
      "    Loss:   0.00014482589904218912\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    30\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9949639728880365\n",
      "    Rolling avg. 20 reward:     127.0\n",
      "    Step:   20195\n",
      "    Q value:    0.06768225133419037\n",
      "    Loss:   0.2953578531742096\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    40\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9934259533943222\n",
      "    Rolling avg. 20 reward:     120.75\n",
      "    Step:   26383\n",
      "    Q value:    0.039181143045425415\n",
      "    Loss:   0.1370207518339157\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    50\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9918578274977746\n",
      "    Rolling avg. 20 reward:     112.75\n",
      "    Step:   32702\n",
      "    Q value:    0.0786159485578537\n",
      "    Loss:   0.0024228019174188375\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    60\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9902231064136099\n",
      "    Rolling avg. 20 reward:     116.75\n",
      "    Step:   39300\n",
      "    Q value:    0.03183673694729805\n",
      "    Loss:   0.13985879719257355\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    70\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9881939928337489\n",
      "    Rolling avg. 20 reward:     179.75\n",
      "    Step:   47505\n",
      "    Q value:    0.0606483519077301\n",
      "    Loss:   0.00961649976670742\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    80\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9857330003221738\n",
      "    Rolling avg. 20 reward:     231.5\n",
      "    Step:   57479\n",
      "    Q value:    0.08847794681787491\n",
      "    Loss:   0.6111602783203125\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    90\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9836228360869673\n",
      "    Rolling avg. 20 reward:     221.75\n",
      "    Step:   66051\n",
      "    Q value:    0.08982355892658234\n",
      "    Loss:   0.0012109717354178429\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    100\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9820687113366271\n",
      "    Rolling avg. 20 reward:     166.75\n",
      "    Step:   72376\n",
      "    Q value:    0.22053104639053345\n",
      "    Loss:   0.009905356913805008\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    110\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9805565087145913\n",
      "    Rolling avg. 20 reward:     125.25\n",
      "    Step:   78540\n",
      "    Q value:    0.1976819932460785\n",
      "    Loss:   0.4546583294868469\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    120\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9790777198305217\n",
      "    Rolling avg. 20 reward:     134.25\n",
      "    Step:   84577\n",
      "    Q value:    0.16947557032108307\n",
      "    Loss:   0.0021722102537751198\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    130\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9773819586166733\n",
      "    Rolling avg. 20 reward:     145.75\n",
      "    Step:   91511\n",
      "    Q value:    0.11740446090698242\n",
      "    Loss:   0.0030040328856557608\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [0.01932931 0.01155812 0.04697023 0.03915506 0.0214522  0.02030298]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    140\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9755601080867048\n",
      "    Rolling avg. 20 reward:     156.0\n",
      "    Step:   98974\n",
      "    Q value:    0.16537997126579285\n",
      "    Loss:   0.7694681286811829\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    150\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9737314292708437\n",
      "    Rolling avg. 20 reward:     166.0\n",
      "    Step:   106479\n",
      "    Q value:    0.19228370487689972\n",
      "    Loss:   0.0016081559006124735\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.7610091  0.79791498 0.68772447 0.66972166 0.57655382 0.62146938]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    160\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9721613371891602\n",
      "    Rolling avg. 20 reward:     157.25\n",
      "    Step:   112934\n",
      "    Q value:    0.16731604933738708\n",
      "    Loss:   0.001976650208234787\n",
      "    Look-up table:\n",
      "[[ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.00535747  0.01384725 -0.00239772 -0.01690346  0.00101151 -0.00903259]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    170\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9704867747218993\n",
      "    Rolling avg. 20 reward:     154.0\n",
      "    Step:   119830\n",
      "    Q value:    0.18659326434135437\n",
      "    Loss:   0.005122628528624773\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    180\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9690110594074607\n",
      "    Rolling avg. 20 reward:     145.25\n",
      "    Step:   125917\n",
      "    Q value:    0.15950733423233032\n",
      "    Loss:   0.008053287863731384\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    190\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9677018415220234\n",
      "    Rolling avg. 20 reward:     113.5\n",
      "    Step:   131325\n",
      "    Q value:    0.31949383020401\n",
      "    Loss:   0.005710655823349953\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.40108067 0.36611098 0.34357673 0.36336109 0.43336272 0.40618652]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    200\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9659207337082644\n",
      "    Rolling avg. 20 reward:     140.75\n",
      "    Step:   138694\n",
      "    Q value:    0.18446186184883118\n",
      "    Loss:   0.0018360867397859693\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    210\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9641877378132311\n",
      "    Rolling avg. 20 reward:     169.0\n",
      "    Step:   145877\n",
      "    Q value:    0.20874133706092834\n",
      "    Loss:   0.018055371940135956\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.16736349 0.19246149 0.11932085 0.15419096 0.18494254 0.16490753]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    220\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9626053591400854\n",
      "    Rolling avg. 20 reward:     158.25\n",
      "    Step:   152447\n",
      "    Q value:    0.10110936313867569\n",
      "    Loss:   0.0011529966723173857\n",
      "    Look-up table:\n",
      "[[ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.04177096 -0.05048251  0.00203151 -0.08494669 -0.02368765  0.05823027]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    230\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9608864789886848\n",
      "    Rolling avg. 20 reward:     179.5\n",
      "    Step:   159596\n",
      "    Q value:    0.11620557308197021\n",
      "    Loss:   0.0029782976489514112\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    240\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9592433281017394\n",
      "    Rolling avg. 20 reward:     193.0\n",
      "    Step:   166442\n",
      "    Q value:    0.29759344458580017\n",
      "    Loss:   0.6078115701675415\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    250\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.957638658442781\n",
      "    Rolling avg. 20 reward:     162.75\n",
      "    Step:   173139\n",
      "    Q value:    0.2768571972846985\n",
      "    Loss:   0.004796423017978668\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    260\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9561184177948762\n",
      "    Rolling avg. 20 reward:     143.25\n",
      "    Step:   179494\n",
      "    Q value:    0.25276070833206177\n",
      "    Loss:   0.44594278931617737\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    270\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.954382727764462\n",
      "    Rolling avg. 20 reward:     149.0\n",
      "    Step:   186762\n",
      "    Q value:    0.33923208713531494\n",
      "    Loss:   0.00393745768815279\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    280\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9527075875299538\n",
      "    Rolling avg. 20 reward:     149.25\n",
      "    Step:   193789\n",
      "    Q value:    0.22030401229858398\n",
      "    Loss:   0.0007662641583010554\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    290\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9510684365731268\n",
      "    Rolling avg. 20 reward:     145.75\n",
      "    Step:   200677\n",
      "    Q value:    0.25873667001724243\n",
      "    Loss:   0.0013844744535163045\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    300\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9493186554336673\n",
      "    Rolling avg. 20 reward:     154.25\n",
      "    Step:   208043\n",
      "    Q value:    0.2589952349662781\n",
      "    Loss:   0.0013931503053754568\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    310\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9479237080627072\n",
      "    Rolling avg. 20 reward:     134.75\n",
      "    Step:   213925\n",
      "    Q value:    0.20453520119190216\n",
      "    Loss:   0.000920372549444437\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    320\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9461948516111269\n",
      "    Rolling avg. 20 reward:     123.25\n",
      "    Step:   221227\n",
      "    Q value:    0.20374110341072083\n",
      "    Loss:   0.606717050075531\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [0.10282961 0.08596113 0.0609799  0.14939043 0.04736999 0.10146528]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    330\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9447291492550735\n",
      "    Rolling avg. 20 reward:     136.75\n",
      "    Step:   227428\n",
      "    Q value:    0.22536566853523254\n",
      "    Loss:   0.29305174946784973\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    340\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9430718961306999\n",
      "    Rolling avg. 20 reward:     167.25\n",
      "    Step:   234451\n",
      "    Q value:    0.2375236451625824\n",
      "    Loss:   0.2921534478664398\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [0.28809196 0.34390038 0.3605355  0.36306322 0.31595674 0.32536376]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    350\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9413337677319091\n",
      "    Rolling avg. 20 reward:     193.0\n",
      "    Step:   241830\n",
      "    Q value:    0.2144233137369156\n",
      "    Loss:   0.11471736431121826\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [0.05925113 0.06304756 0.06577209 0.05130911 0.02775368 0.05491832]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    360\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9395450522894696\n",
      "    Rolling avg. 20 reward:     185.5\n",
      "    Step:   249438\n",
      "    Q value:    0.34086811542510986\n",
      "    Loss:   0.0020728008821606636\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    370\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.937914947849981\n",
      "    Rolling avg. 20 reward:     177.5\n",
      "    Step:   256384\n",
      "    Q value:    0.3105027675628662\n",
      "    Loss:   0.18167057633399963\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [0.3014217  0.33088773 0.30069917 0.31243998 0.28442082 0.29627472]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.21985731 0.22241423 0.18711273 0.22316687 0.17349434 0.1855218 ]]\n",
      "Episode:    380\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9362654350599707\n",
      "    Rolling avg. 20 reward:     145.5\n",
      "    Step:   263425\n",
      "    Q value:    0.32525038719177246\n",
      "    Loss:   0.13634830713272095\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    390\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9347571571108196\n",
      "    Rolling avg. 20 reward:     131.25\n",
      "    Step:   269874\n",
      "    Q value:    0.29434382915496826\n",
      "    Loss:   0.14976002275943756\n",
      "    Look-up table:\n",
      "[[ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 6.15231693e-02 -2.44021416e-04  1.01998895e-01  4.40458655e-02\n",
      "   2.90597975e-02  9.06646252e-03]\n",
      " ...\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]]\n",
      "Episode:    400\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9331166971148355\n",
      "    Rolling avg. 20 reward:     149.75\n",
      "    Step:   276900\n",
      "    Q value:    0.26909855008125305\n",
      "    Loss:   0.0018191682174801826\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    410\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9315405957161839\n",
      "    Rolling avg. 20 reward:     138.5\n",
      "    Step:   283662\n",
      "    Q value:    0.4084303081035614\n",
      "    Loss:   0.005300330929458141\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    420\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9299071755117745\n",
      "    Rolling avg. 20 reward:     141.0\n",
      "    Step:   290682\n",
      "    Q value:    0.3680720925331116\n",
      "    Loss:   0.007059252355247736\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    430\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9284035699698004\n",
      "    Rolling avg. 20 reward:     147.25\n",
      "    Step:   297155\n",
      "    Q value:    0.6300210952758789\n",
      "    Loss:   0.007573374547064304\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    440\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9266248299353984\n",
      "    Rolling avg. 20 reward:     162.5\n",
      "    Step:   304826\n",
      "    Q value:    0.3493666648864746\n",
      "    Loss:   0.009354779496788979\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    450\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9250178357592711\n",
      "    Rolling avg. 20 reward:     191.0\n",
      "    Step:   311769\n",
      "    Q value:    0.38447457551956177\n",
      "    Loss:   0.007484331727027893\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    460\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9231673407381084\n",
      "    Rolling avg. 20 reward:     198.75\n",
      "    Step:   319779\n",
      "    Q value:    0.32202720642089844\n",
      "    Loss:   0.005351055413484573\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [0.44870239 0.44731408 0.44524455 0.40199444 0.4047929  0.44471332]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    470\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9214845573003451\n",
      "    Rolling avg. 20 reward:     178.25\n",
      "    Step:   327077\n",
      "    Q value:    0.43288642168045044\n",
      "    Loss:   0.754550576210022\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    480\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9199945706396505\n",
      "    Rolling avg. 20 reward:     145.25\n",
      "    Step:   333550\n",
      "    Q value:    0.30025041103363037\n",
      "    Loss:   0.010893690399825573\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.32604197 0.31765234 0.32623169 0.33647144 0.32100281 0.33295754]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    490\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9183747376993353\n",
      "    Rolling avg. 20 reward:     152.25\n",
      "    Step:   340599\n",
      "    Q value:    0.4151063561439514\n",
      "    Loss:   0.0064387996681034565\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [0.11481792 0.07998186 0.02795267 0.04800302 0.11772257 0.09944454]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [0.255382   0.23933655 0.19825777 0.24511465 0.24603    0.25738463]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    500\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9170057733432122\n",
      "    Rolling avg. 20 reward:     137.75\n",
      "    Step:   346566\n",
      "    Q value:    0.25992804765701294\n",
      "    Loss:   0.7676720023155212\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    510\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9149498617375671\n",
      "    Rolling avg. 20 reward:     173.5\n",
      "    Step:   355544\n",
      "    Q value:    0.6403653621673584\n",
      "    Loss:   0.4563891291618347\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    520\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9134587946222555\n",
      "    Rolling avg. 20 reward:     187.25\n",
      "    Step:   362068\n",
      "    Q value:    0.28893542289733887\n",
      "    Loss:   0.004490306135267019\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.04317969 0.02932757 0.05120623 0.04548976 0.04814294 0.0322898 ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    530\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9120946498940389\n",
      "    Rolling avg. 20 reward:     145.5\n",
      "    Step:   368046\n",
      "    Q value:    0.4878373146057129\n",
      "    Loss:   0.003995268605649471\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    540\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9103025504006094\n",
      "    Rolling avg. 20 reward:     174.75\n",
      "    Step:   375913\n",
      "    Q value:    0.5083065032958984\n",
      "    Loss:   0.146365687251091\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.09262985 0.08489448 0.10513097 0.12200713 0.12419808 0.12591219]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    550\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9087565777028647\n",
      "    Rolling avg. 20 reward:     168.25\n",
      "    Step:   382712\n",
      "    Q value:    0.5565532445907593\n",
      "    Loss:   0.6047723889350891\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    560\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9071220601808422\n",
      "    Rolling avg. 20 reward:     166.0\n",
      "    Step:   389913\n",
      "    Q value:    0.4720213711261749\n",
      "    Loss:   0.0009824717417359352\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    570\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9058502601475971\n",
      "    Rolling avg. 20 reward:     141.5\n",
      "    Step:   395525\n",
      "    Q value:    0.3655489385128021\n",
      "    Loss:   0.06881393492221832\n",
      "    Look-up table:\n",
      "[[ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.07727808 -0.09411269 -0.11285269 -0.05666316 -0.05814737 -0.07764959]]\n",
      "Episode:    580\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9040498623692708\n",
      "    Rolling avg. 20 reward:     139.0\n",
      "    Step:   403483\n",
      "    Q value:    0.286993145942688\n",
      "    Loss:   0.2953157424926758\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [0.34584987 0.36726958 0.37313288 0.32372552 0.33010101 0.33242047]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    590\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9026070211418686\n",
      "    Rolling avg. 20 reward:     169.0\n",
      "    Step:   409872\n",
      "    Q value:    0.44999629259109497\n",
      "    Loss:   0.002411721972748637\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.09738505 0.10357833 0.09336233 0.13041973 0.10739559 0.12930083]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    600\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.9012471406730777\n",
      "    Rolling avg. 20 reward:     124.5\n",
      "    Step:   415903\n",
      "    Q value:    0.33546537160873413\n",
      "    Loss:   0.04367662966251373\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    610\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8996106114365499\n",
      "    Rolling avg. 20 reward:     142.0\n",
      "    Step:   423173\n",
      "    Q value:    0.49016961455345154\n",
      "    Loss:   0.004047835245728493\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [0.0811609  0.09774268 0.08371228 0.028458   0.09117645 0.08196217]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    620\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8976989485374894\n",
      "    Rolling avg. 20 reward:     198.5\n",
      "    Step:   431682\n",
      "    Q value:    0.3310883939266205\n",
      "    Loss:   0.9250588417053223\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [0.30708274 0.29404134 0.29403543 0.27908817 0.29266989 0.29312706]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    630\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8962104523674237\n",
      "    Rolling avg. 20 reward:     179.0\n",
      "    Step:   438320\n",
      "    Q value:    0.6554763317108154\n",
      "    Loss:   0.21800921857357025\n",
      "    Look-up table:\n",
      "[[ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.0147723  -0.0069859   0.11279023  0.00503016 -0.0122208  -0.0075444 ]]\n",
      "Episode:    640\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8945622701820363\n",
      "    Rolling avg. 20 reward:     150.0\n",
      "    Step:   445683\n",
      "    Q value:    0.3552483916282654\n",
      "    Loss:   0.0014429898001253605\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.11530423 0.04643393 0.07913798 0.09793717 0.06493777 0.03704536]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    650\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8929008235070157\n",
      "    Rolling avg. 20 reward:     180.0\n",
      "    Step:   453119\n",
      "    Q value:    0.3750684857368469\n",
      "    Loss:   0.9042047262191772\n",
      "    Look-up table:\n",
      "[[0.08313137 0.11115563 0.12706268 0.14986569 0.1125747  0.10343403]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    660\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8912032487821018\n",
      "    Rolling avg. 20 reward:     198.0\n",
      "    Step:   460731\n",
      "    Q value:    0.3602941334247589\n",
      "    Loss:   0.001980190398171544\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    670\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8897241887002357\n",
      "    Rolling avg. 20 reward:     164.0\n",
      "    Step:   467375\n",
      "    Q value:    0.5016768574714661\n",
      "    Loss:   0.025545455515384674\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.56397414 0.5972476  0.58623433 0.57463825 0.55946076 0.55237013]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    680\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.888431025386945\n",
      "    Rolling avg. 20 reward:     121.5\n",
      "    Step:   473193\n",
      "    Q value:    0.4338850975036621\n",
      "    Loss:   0.7448620200157166\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    690\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8868973637643573\n",
      "    Rolling avg. 20 reward:     113.5\n",
      "    Step:   480104\n",
      "    Q value:    0.5465660691261292\n",
      "    Loss:   0.00143897021189332\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    700\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8853510771984929\n",
      "    Rolling avg. 20 reward:     135.0\n",
      "    Step:   487084\n",
      "    Q value:    0.26361003518104553\n",
      "    Loss:   0.14099439978599548\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    710\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8837526921777668\n",
      "    Rolling avg. 20 reward:     169.0\n",
      "    Step:   494312\n",
      "    Q value:    0.31587526202201843\n",
      "    Loss:   0.0028770542703568935\n",
      "    Look-up table:\n",
      "[[0.11682081 0.06766313 0.09485298 0.05184829 0.12096101 0.08150494]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    720\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8824679874767002\n",
      "    Rolling avg. 20 reward:     148.75\n",
      "    Step:   500131\n",
      "    Q value:    0.45936283469200134\n",
      "    Loss:   0.22462612390518188\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    730\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8809137870731033\n",
      "    Rolling avg. 20 reward:     122.0\n",
      "    Step:   507182\n",
      "    Q value:    0.3611134886741638\n",
      "    Loss:   0.005771351978182793\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    740\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8794575200592339\n",
      "    Rolling avg. 20 reward:     131.75\n",
      "    Step:   513800\n",
      "    Q value:    0.2744385302066803\n",
      "    Loss:   0.6078372597694397\n",
      "    Look-up table:\n",
      "[[ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.01155972  0.06972778  0.07556963  0.03612995  0.10938221  0.11308444]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    750\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8778006455499904\n",
      "    Rolling avg. 20 reward:     146.25\n",
      "    Step:   521343\n",
      "    Q value:    0.4516799747943878\n",
      "    Loss:   0.002887079492211342\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.06288385 0.06109536 0.07885212 0.0660913  0.08324552 0.0618543 ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    760\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8763631084954637\n",
      "    Rolling avg. 20 reward:     168.0\n",
      "    Step:   527899\n",
      "    Q value:    0.3633914291858673\n",
      "    Loss:   0.005975802429020405\n",
      "    Look-up table:\n",
      "[[0.01495034 0.0391354  0.00826961 0.08506548 0.05840492 0.03480518]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [0.41993195 0.43785733 0.40950459 0.45782995 0.41435438 0.43300295]\n",
      " [0.42567378 0.44330084 0.41540039 0.46306762 0.42021054 0.43865484]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    770\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8748231592754814\n",
      "    Rolling avg. 20 reward:     172.25\n",
      "    Step:   534934\n",
      "    Q value:    0.2916613519191742\n",
      "    Loss:   0.0017457904759794474\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    780\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8730274616508785\n",
      "    Rolling avg. 20 reward:     180.5\n",
      "    Step:   543153\n",
      "    Q value:    0.2197103202342987\n",
      "    Loss:   0.0012695265468209982\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    790\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8714545932475115\n",
      "    Rolling avg. 20 reward:     165.25\n",
      "    Step:   550366\n",
      "    Q value:    0.38369351625442505\n",
      "    Loss:   0.6511794328689575\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [0.05694455 0.09423131 0.09025496 0.06777519 0.07657444 0.12450659]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [0.17645061 0.19892842 0.18290049 0.1849671  0.19493234 0.18945104]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    800\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8701225045579033\n",
      "    Rolling avg. 20 reward:     121.0\n",
      "    Step:   556485\n",
      "    Q value:    0.39111942052841187\n",
      "    Loss:   0.14347630739212036\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.1273036  0.17732048 0.13827044 0.15079433 0.15096194 0.15547359]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    810\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8684502152295268\n",
      "    Rolling avg. 20 reward:     134.5\n",
      "    Step:   564180\n",
      "    Q value:    0.33781981468200684\n",
      "    Loss:   0.020928053185343742\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    820\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8670910695686342\n",
      "    Rolling avg. 20 reward:     154.75\n",
      "    Step:   570445\n",
      "    Q value:    0.38981932401657104\n",
      "    Loss:   0.01780376210808754\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    830\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8654365060298896\n",
      "    Rolling avg. 20 reward:     168.75\n",
      "    Step:   578085\n",
      "    Q value:    0.381276398897171\n",
      "    Loss:   0.45219147205352783\n",
      "    Look-up table:\n",
      "[[ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.14183855  0.00109065 -0.0485692   0.02243358  0.16159272  0.13548565]]\n",
      "Episode:    840\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8638194358362492\n",
      "    Rolling avg. 20 reward:     188.5\n",
      "    Step:   585566\n",
      "    Q value:    0.38157498836517334\n",
      "    Loss:   0.9101072549819946\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    850\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8622226314244914\n",
      "    Rolling avg. 20 reward:     184.75\n",
      "    Step:   592967\n",
      "    Q value:    0.4488324820995331\n",
      "    Loss:   0.004582613706588745\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    860\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8609354324291352\n",
      "    Rolling avg. 20 reward:     156.5\n",
      "    Step:   598943\n",
      "    Q value:    0.38929563760757446\n",
      "    Loss:   0.0018945776391774416\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [0.12884903 0.09606171 0.10844839 0.11913776 0.09392428 0.13541251]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [0.41010225 0.38952488 0.40083736 0.37913877 0.39877528 0.39242369]\n",
      " [0.41184103 0.39142412 0.40246099 0.38073546 0.4005627  0.39418894]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    870\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8592717773418846\n",
      "    Rolling avg. 20 reward:     141.5\n",
      "    Step:   606680\n",
      "    Q value:    0.4887143671512604\n",
      "    Loss:   1.0617045164108276\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    880\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8580700674317628\n",
      "    Rolling avg. 20 reward:     130.0\n",
      "    Step:   612278\n",
      "    Q value:    0.32809412479400635\n",
      "    Loss:   0.0115378238260746\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    890\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8566442825998795\n",
      "    Rolling avg. 20 reward:     115.0\n",
      "    Step:   618930\n",
      "    Q value:    0.34928566217422485\n",
      "    Loss:   0.2968566119670868\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.03606868 0.08651495 0.04982066 0.05426383 0.0519172  0.09307456]\n",
      " ...\n",
      " [0.52388918 0.55551219 0.54245758 0.53920835 0.57945734 0.57241917]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.18944198 0.23923433 0.20179993 0.21779406 0.29576802 0.28460479]]\n",
      "Episode:    900\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.85533034216894\n",
      "    Rolling avg. 20 reward:     113.25\n",
      "    Step:   625070\n",
      "    Q value:    0.2117876410484314\n",
      "    Loss:   0.0014381043147295713\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [0.02867854 0.02443397 0.02893817 0.03441906 0.05193222 0.04929399]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    910\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8540487352853812\n",
      "    Rolling avg. 20 reward:     114.5\n",
      "    Step:   631068\n",
      "    Q value:    0.27803564071655273\n",
      "    Loss:   0.7593333125114441\n",
      "    Look-up table:\n",
      "[[ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.05468333 -0.04416895 -0.07661211 -0.00183499 -0.05395961 -0.02484858]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]]\n",
      "Episode:    920\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8527505012040303\n",
      "    Rolling avg. 20 reward:     142.25\n",
      "    Step:   637153\n",
      "    Q value:    0.352219820022583\n",
      "    Loss:   0.13357780873775482\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    930\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8513667581204171\n",
      "    Rolling avg. 20 reward:     155.5\n",
      "    Step:   643649\n",
      "    Q value:    0.42077895998954773\n",
      "    Loss:   0.010547291487455368\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    940\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8497343392766334\n",
      "    Rolling avg. 20 reward:     185.25\n",
      "    Step:   651326\n",
      "    Q value:    0.36864882707595825\n",
      "    Loss:   0.0032744831405580044\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    950\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.84801621608614\n",
      "    Rolling avg. 20 reward:     193.75\n",
      "    Step:   659422\n",
      "    Q value:    0.3898634910583496\n",
      "    Loss:   0.002572774887084961\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    960\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8466426951674472\n",
      "    Rolling avg. 20 reward:     155.75\n",
      "    Step:   665906\n",
      "    Q value:    0.35150712728500366\n",
      "    Loss:   0.35071635246276855\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    970\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8450825018515868\n",
      "    Rolling avg. 20 reward:     172.0\n",
      "    Step:   673284\n",
      "    Q value:    0.3161592185497284\n",
      "    Loss:   0.005167813040316105\n",
      "    Look-up table:\n",
      "[[ 0.09596372  0.05576885  0.0368191   0.1179235   0.07723999  0.05431676]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 0.07332301  0.04082143  0.02272761  0.09213948  0.05839586  0.04006457]\n",
      " ...\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.00549281  0.04432642 -0.03826356 -0.00180852  0.00736034 -0.01749802]]\n",
      "Episode:    980\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8436403327209924\n",
      "    Rolling avg. 20 reward:     186.0\n",
      "    Step:   680116\n",
      "    Q value:    0.15698017179965973\n",
      "    Loss:   0.6054015159606934\n",
      "    Look-up table:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "Episode:    990\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8419816809872692\n",
      "    Rolling avg. 20 reward:     194.25\n",
      "    Step:   687988\n",
      "    Q value:    0.4628961682319641\n",
      "    Loss:   0.05685175210237503\n",
      "    Look-up table:\n",
      "[[0.17846286 0.16165233 0.17111778 0.1604948  0.12742984 0.11061418]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Episode:    1000\n",
      "% of CUDA memory used:  5.382690133333334%\n",
      "    Epsilon:    0.8404094867019778\n",
      "    Rolling avg. 20 reward:     186.0\n",
      "    Step:   695464\n",
      "    Q value:    0.6519870758056641\n",
      "    Loss:   0.027631450444459915\n",
      "    Look-up table:\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.05681837 0.042593   0.00489104 0.04843378 0.0324204  0.03562236]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "Training finished at 1000 episodes!\n",
      "    Final epsilon:  0.8404094867019778\n",
      "    Final Rolling avg. 20 reward:   186.0\n",
      "    Final look-up table\n",
      "[[1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " ...\n",
      " [1.         1.         1.         1.         1.         1.        ]\n",
      " [0.05681837 0.042593   0.00489104 0.04843378 0.0324204  0.03562236]\n",
      " [1.         1.         1.         1.         1.         1.        ]]\n",
      "\u001B[32m[I 2022-06-07 07:25:49,214]\u001B[0m Trial 4 finished with value: 186.0 and parameters: {'exploration_rate_decay': 0.99999975, 'exploration_rate_min': 0.05, 'batch_size': 32, 'gamma': 0.92, 'lr': 0.0004, 'learn_every': 4, 'sync_every': 10000}. Best is trial 2 with value: 286.5.\u001B[0m\n",
      "Current Params:\n",
      "    exploration_rate_decay: 0.99999975\n",
      "    exploration_rate_min: 0.15000000000000002\n",
      "    batch_size: 16\n",
      "    gamma: 0.98\n",
      "    lr: 0.0008\n",
      "    learn_every: 2\n",
      "    sync_every: 10000\n",
      "\n",
      "\u001B[32m[I 2022-06-07 07:25:50,065]\u001B[0m Trial 5 pruned. \u001B[0m\n",
      "Current Params:\n",
      "    exploration_rate_decay: 0.99999975\n",
      "    exploration_rate_min: 0.15000000000000002\n",
      "    batch_size: 48\n",
      "    gamma: 0.9500000000000001\n",
      "    lr: 0.0009000000000000001\n",
      "    learn_every: 1\n",
      "    sync_every: 5000\n",
      "\n",
      "\u001B[32m[I 2022-06-07 07:25:50,688]\u001B[0m Trial 6 pruned. \u001B[0m\n",
      "Current Params:\n",
      "    exploration_rate_decay: 0.999975\n",
      "    exploration_rate_min: 0.15000000000000002\n",
      "    batch_size: 24\n",
      "    gamma: 0.93\n",
      "    lr: 0.0008\n",
      "    learn_every: 5\n",
      "    sync_every: 5000\n",
      "\n",
      "\u001B[32m[I 2022-06-07 07:25:51,515]\u001B[0m Trial 7 pruned. \u001B[0m\n",
      "Current Params:\n",
      "    exploration_rate_decay: 0.999975\n",
      "    exploration_rate_min: 0.1\n",
      "    batch_size: 64\n",
      "    gamma: 0.92\n",
      "    lr: 0.0001\n",
      "    learn_every: 3\n",
      "    sync_every: 15000\n",
      "\n",
      "\u001B[32m[I 2022-06-07 07:25:52,166]\u001B[0m Trial 8 pruned. \u001B[0m\n",
      "Current Params:\n",
      "    exploration_rate_decay: 0.999975\n",
      "    exploration_rate_min: 0.2\n",
      "    batch_size: 8\n",
      "    gamma: 0.92\n",
      "    lr: 0.0008\n",
      "    learn_every: 4\n",
      "    sync_every: 5000\n",
      "\n",
      "\u001B[32m[I 2022-06-07 07:25:53,169]\u001B[0m Trial 9 pruned. \u001B[0m\n",
      "Study statistics: \n",
      "  Number of finished trials:  10\n",
      "  Number of pruned trials:  5\n",
      "  Number of complete trials:  5\n",
      "Best trial:\n",
      "  Value:  286.5\n",
      "  Params: \n",
      "    exploration_rate_decay: 0.999975\n",
      "    exploration_rate_min: 0.05\n",
      "    batch_size: 48\n",
      "    gamma: 0.93\n",
      "    lr: 0.0009000000000000001\n",
      "    learn_every: 4\n",
      "    sync_every: 5000\n"
     ]
    }
   ],
   "source": [
    "evaluator = Optimizer()\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(evaluator.objective,n_trials=10,show_progress_bar=True)\n",
    "\n",
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[1;32mIn [12]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m best_agent \u001B[38;5;241m=\u001B[39m evaluator\u001B[38;5;241m.\u001B[39magent\n\u001B[1;32m----> 2\u001B[0m p\u001B[38;5;241m=\u001B[39m \u001B[43mbest_agent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave\u001B[49m()\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "best_agent = evaluator.agent\n",
    "p= best_agent.save()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}